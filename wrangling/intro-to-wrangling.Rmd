# (PART) Data Wrangling {-}


The datasets used in this book have been made available to you as R objects, specifically as data frames. The US murders data, the reported heights data, the Gapminder data, and the poll data are all examples. These datasets come included in the __dslabs__ package and we loaded them using the `data` function. Furthermore, we have made the data available in what is referred to as `tidy` form, a concept we define later in this chapter. The __tidyverse__ packages and functions assume that the data is `tidy` and this assumption is a big part of the reason these packages work so well together. 

However, very rarely in a data science project is data easily available as part of a package. We did quite a bit of work "behind the scenes" to get the original raw data into the _tidy_ tables you worked with. Much more typical is for the data to be in a file, a database, or extracted from a document, including web pages, tweets, or PDFs. In these cases, the first step is to import the data into R and, when using the __tidyverse__, tidy the data. This initial step in the data analysis process usually involves several, often complicated, steps to covert data from its raw form to the _tidy_ form that greatly facilitates the rest of the analysis. We refer to this process as `data wrangling`.

Here we cover several common steps of the data wrangling process including importing data into R from files, tidying data, string processing, html parsing, working with dates and times, and text mining. Rarely are all these wrangling steps necessary in a single analysis, but data scientists will likely face them all at some point. Some of the examples we use to demonstrate data wrangling techniques are based on the work we did to convert raw data into the tidy datasets provided by the __dslabs__ package and used in the book as examples.


