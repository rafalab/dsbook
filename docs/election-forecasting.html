<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Data Science</title>
  <meta name="description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Data Science" />
  
  <meta name="twitter:description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  

<meta name="author" content="Rafael A. Irizarry">


<meta name="date" content="2017-11-25">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="bayesian-statistics.html">
<link rel="next" href="association-tests.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#case-studies"><i class="fa fa-check"></i><b>1.1</b> Case Studies</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#who-will-find-this-book-useful"><i class="fa fa-check"></i><b>1.2</b> Who Will Find This Book Useful?</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#what-does-this-book-cover"><i class="fa fa-check"></i><b>1.3</b> What Does This Book Cover?</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#what-is-not-covered-by-this-book"><i class="fa fa-check"></i><b>1.4</b> What is Not Covered by This Book?</a></li>
</ul></li>
<li class="part"><span><b>I R Basics</b></span></li>
<li class="chapter" data-level="2" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="motivating-case-study.html"><a href="motivating-case-study.html"><i class="fa fa-check"></i><b>3</b> Motivating case study</a></li>
<li class="chapter" data-level="4" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>4</b> Getting Started</a><ul>
<li class="chapter" data-level="4.1" data-path="getting-started.html"><a href="getting-started.html#why-r"><i class="fa fa-check"></i><b>4.1</b> Why R?</a></li>
<li class="chapter" data-level="4.2" data-path="getting-started.html"><a href="getting-started.html#installing-r"><i class="fa fa-check"></i><b>4.2</b> Installing R</a></li>
<li class="chapter" data-level="4.3" data-path="getting-started.html"><a href="getting-started.html#the-r-console"><i class="fa fa-check"></i><b>4.3</b> The R console</a></li>
<li class="chapter" data-level="4.4" data-path="getting-started.html"><a href="getting-started.html#scripts"><i class="fa fa-check"></i><b>4.4</b> Scripts</a></li>
<li class="chapter" data-level="4.5" data-path="getting-started.html"><a href="getting-started.html#installing-rstudio"><i class="fa fa-check"></i><b>4.5</b> Installing RStudio</a></li>
<li class="chapter" data-level="4.6" data-path="getting-started.html"><a href="getting-started.html#the-r-ecosystem"><i class="fa fa-check"></i><b>4.6</b> The R ecosystem</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="the-very-basics.html"><a href="the-very-basics.html"><i class="fa fa-check"></i><b>5</b> The very basics</a><ul>
<li class="chapter" data-level="5.1" data-path="the-very-basics.html"><a href="the-very-basics.html#objects"><i class="fa fa-check"></i><b>5.1</b> Objects</a></li>
<li class="chapter" data-level="5.2" data-path="the-very-basics.html"><a href="the-very-basics.html#the-workspace"><i class="fa fa-check"></i><b>5.2</b> The workspace</a></li>
<li class="chapter" data-level="5.3" data-path="the-very-basics.html"><a href="the-very-basics.html#functions"><i class="fa fa-check"></i><b>5.3</b> Functions</a></li>
<li class="chapter" data-level="5.4" data-path="the-very-basics.html"><a href="the-very-basics.html#other-prebuilt-objects"><i class="fa fa-check"></i><b>5.4</b> Other prebuilt objects</a></li>
<li class="chapter" data-level="5.5" data-path="the-very-basics.html"><a href="the-very-basics.html#variable-names"><i class="fa fa-check"></i><b>5.5</b> Variable names</a></li>
<li class="chapter" data-level="5.6" data-path="the-very-basics.html"><a href="the-very-basics.html#saving-your-workspace"><i class="fa fa-check"></i><b>5.6</b> Saving your workspace</a></li>
<li class="chapter" data-level="5.7" data-path="the-very-basics.html"><a href="the-very-basics.html#scripts-1"><i class="fa fa-check"></i><b>5.7</b> Scripts</a></li>
<li class="chapter" data-level="5.8" data-path="the-very-basics.html"><a href="the-very-basics.html#comments"><i class="fa fa-check"></i><b>5.8</b> Comments</a></li>
<li class="chapter" data-level="" data-path="the-very-basics.html"><a href="the-very-basics.html#exercises"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-types.html"><a href="data-types.html"><i class="fa fa-check"></i><b>6</b> Data types</a><ul>
<li class="chapter" data-level="6.1" data-path="data-types.html"><a href="data-types.html#data-frames"><i class="fa fa-check"></i><b>6.1</b> Data frames</a></li>
<li class="chapter" data-level="6.2" data-path="data-types.html"><a href="data-types.html#examining-an-object"><i class="fa fa-check"></i><b>6.2</b> Examining an object</a></li>
<li class="chapter" data-level="6.3" data-path="data-types.html"><a href="data-types.html#the-accessor"><i class="fa fa-check"></i><b>6.3</b> The accessor</a></li>
<li class="chapter" data-level="6.4" data-path="data-types.html"><a href="data-types.html#vectors-numerics-characters-and-logical"><i class="fa fa-check"></i><b>6.4</b> Vectors: numerics, characters, and logical</a></li>
<li class="chapter" data-level="6.5" data-path="data-types.html"><a href="data-types.html#factors"><i class="fa fa-check"></i><b>6.5</b> Factors</a></li>
<li class="chapter" data-level="6.6" data-path="data-types.html"><a href="data-types.html#lists"><i class="fa fa-check"></i><b>6.6</b> Lists</a></li>
<li class="chapter" data-level="" data-path="data-types.html"><a href="data-types.html#exercises-1"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="vectors.html"><a href="vectors.html"><i class="fa fa-check"></i><b>7</b> Vectors</a><ul>
<li class="chapter" data-level="7.1" data-path="vectors.html"><a href="vectors.html#creating-vectors"><i class="fa fa-check"></i><b>7.1</b> Creating vectors</a></li>
<li class="chapter" data-level="7.2" data-path="vectors.html"><a href="vectors.html#names"><i class="fa fa-check"></i><b>7.2</b> Names</a></li>
<li class="chapter" data-level="7.3" data-path="vectors.html"><a href="vectors.html#sequences"><i class="fa fa-check"></i><b>7.3</b> Sequences</a></li>
<li class="chapter" data-level="7.4" data-path="vectors.html"><a href="vectors.html#subsetting"><i class="fa fa-check"></i><b>7.4</b> Subsetting</a></li>
<li class="chapter" data-level="7.5" data-path="vectors.html"><a href="vectors.html#coercion"><i class="fa fa-check"></i><b>7.5</b> Coercion</a></li>
<li class="chapter" data-level="7.6" data-path="vectors.html"><a href="vectors.html#not-availables-na"><i class="fa fa-check"></i><b>7.6</b> Not Availables (NA)</a></li>
<li class="chapter" data-level="" data-path="vectors.html"><a href="vectors.html#exercises-2"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="sorting.html"><a href="sorting.html"><i class="fa fa-check"></i><b>8</b> Sorting</a><ul>
<li class="chapter" data-level="8.1" data-path="sorting.html"><a href="sorting.html#sort"><i class="fa fa-check"></i><b>8.1</b> <code>sort</code></a></li>
<li class="chapter" data-level="8.2" data-path="sorting.html"><a href="sorting.html#order"><i class="fa fa-check"></i><b>8.2</b> <code>order</code></a></li>
<li class="chapter" data-level="8.3" data-path="sorting.html"><a href="sorting.html#max-and-which.max"><i class="fa fa-check"></i><b>8.3</b> <code>max</code> and <code>which.max</code></a></li>
<li class="chapter" data-level="8.4" data-path="sorting.html"><a href="sorting.html#rank"><i class="fa fa-check"></i><b>8.4</b> <code>rank</code></a></li>
<li class="chapter" data-level="8.5" data-path="sorting.html"><a href="sorting.html#beware-of-recycling"><i class="fa fa-check"></i><b>8.5</b> Beware of recycling</a></li>
<li class="chapter" data-level="" data-path="sorting.html"><a href="sorting.html#exercise"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="vector-arithmetics.html"><a href="vector-arithmetics.html"><i class="fa fa-check"></i><b>9</b> Vector arithmetics</a><ul>
<li class="chapter" data-level="9.1" data-path="vector-arithmetics.html"><a href="vector-arithmetics.html#rescaling"><i class="fa fa-check"></i><b>9.1</b> Rescaling</a></li>
<li class="chapter" data-level="9.2" data-path="vector-arithmetics.html"><a href="vector-arithmetics.html#two-vectors"><i class="fa fa-check"></i><b>9.2</b> Two vectors</a></li>
<li class="chapter" data-level="" data-path="vector-arithmetics.html"><a href="vector-arithmetics.html#exercises-3"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="indexing.html"><a href="indexing.html"><i class="fa fa-check"></i><b>10</b> Indexing</a><ul>
<li class="chapter" data-level="10.1" data-path="indexing.html"><a href="indexing.html#subsetting-with-logicals"><i class="fa fa-check"></i><b>10.1</b> Subsetting with logicals</a></li>
<li class="chapter" data-level="10.2" data-path="indexing.html"><a href="indexing.html#logical-operators"><i class="fa fa-check"></i><b>10.2</b> Logical operators</a></li>
<li class="chapter" data-level="10.3" data-path="indexing.html"><a href="indexing.html#which"><i class="fa fa-check"></i><b>10.3</b> <code>which</code></a></li>
<li class="chapter" data-level="10.4" data-path="indexing.html"><a href="indexing.html#match"><i class="fa fa-check"></i><b>10.4</b> <code>match</code></a></li>
<li class="chapter" data-level="10.5" data-path="indexing.html"><a href="indexing.html#in"><i class="fa fa-check"></i><b>10.5</b> <code>%in%</code></a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#exercises-4"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="basic-data-wrangling.html"><a href="basic-data-wrangling.html"><i class="fa fa-check"></i><b>11</b> Basic data wrangling</a><ul>
<li class="chapter" data-level="11.1" data-path="basic-data-wrangling.html"><a href="basic-data-wrangling.html#adding-a-column-with-mutate"><i class="fa fa-check"></i><b>11.1</b> Adding a column with <code>mutate</code></a></li>
<li class="chapter" data-level="11.2" data-path="basic-data-wrangling.html"><a href="basic-data-wrangling.html#subsetting-with-filter"><i class="fa fa-check"></i><b>11.2</b> Subsetting with <code>filter</code></a></li>
<li class="chapter" data-level="11.3" data-path="basic-data-wrangling.html"><a href="basic-data-wrangling.html#selecting-columns-with-select"><i class="fa fa-check"></i><b>11.3</b> Selecting columns with <code>select</code></a></li>
<li class="chapter" data-level="11.4" data-path="basic-data-wrangling.html"><a href="basic-data-wrangling.html#the-pipe"><i class="fa fa-check"></i><b>11.4</b> The pipe: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="11.5" data-path="basic-data-wrangling.html"><a href="basic-data-wrangling.html#creating-a-data-frame"><i class="fa fa-check"></i><b>11.5</b> Creating a data frame</a></li>
<li class="chapter" data-level="" data-path="basic-data-wrangling.html"><a href="basic-data-wrangling.html#exercises-5"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="basic-plots.html"><a href="basic-plots.html"><i class="fa fa-check"></i><b>12</b> Basic plots</a><ul>
<li class="chapter" data-level="12.1" data-path="basic-plots.html"><a href="basic-plots.html#scatterplots"><i class="fa fa-check"></i><b>12.1</b> Scatterplots</a></li>
<li class="chapter" data-level="12.2" data-path="basic-plots.html"><a href="basic-plots.html#histograms"><i class="fa fa-check"></i><b>12.2</b> Histograms</a></li>
<li class="chapter" data-level="12.3" data-path="basic-plots.html"><a href="basic-plots.html#boxplot"><i class="fa fa-check"></i><b>12.3</b> Boxplot</a></li>
<li class="chapter" data-level="" data-path="basic-plots.html"><a href="basic-plots.html#exercises-6"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="importing-data.html"><a href="importing-data.html"><i class="fa fa-check"></i><b>13</b> Importing data</a><ul>
<li class="chapter" data-level="" data-path="importing-data.html"><a href="importing-data.html#paths-and-the-working-directory"><i class="fa fa-check"></i>Paths and the working directory</a></li>
<li class="chapter" data-level="13.1" data-path="importing-data.html"><a href="importing-data.html#read.csv"><i class="fa fa-check"></i><b>13.1</b> <code>read.csv</code></a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="programming-basics.html"><a href="programming-basics.html"><i class="fa fa-check"></i><b>14</b> Programming basics</a><ul>
<li class="chapter" data-level="14.1" data-path="programming-basics.html"><a href="programming-basics.html#conditionals-expressions"><i class="fa fa-check"></i><b>14.1</b> Conditionals expressions</a></li>
<li class="chapter" data-level="14.2" data-path="programming-basics.html"><a href="programming-basics.html#defining-functions"><i class="fa fa-check"></i><b>14.2</b> Defining functions</a></li>
<li class="chapter" data-level="14.3" data-path="programming-basics.html"><a href="programming-basics.html#for-loops"><i class="fa fa-check"></i><b>14.3</b> For-loops</a></li>
<li class="chapter" data-level="14.4" data-path="programming-basics.html"><a href="programming-basics.html#vectorization-and-functionals"><i class="fa fa-check"></i><b>14.4</b> Vectorization and functionals</a></li>
<li class="chapter" data-level="14.5" data-path="programming-basics.html"><a href="programming-basics.html#map"><i class="fa fa-check"></i><b>14.5</b> map</a></li>
<li class="chapter" data-level="14.6" data-path="programming-basics.html"><a href="programming-basics.html#other-functions"><i class="fa fa-check"></i><b>14.6</b> Other functions</a></li>
<li class="chapter" data-level="" data-path="programming-basics.html"><a href="programming-basics.html#exercises-7"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="matrices.html"><a href="matrices.html"><i class="fa fa-check"></i><b>15</b> Matrices</a><ul>
<li class="chapter" data-level="15.1" data-path="matrices.html"><a href="matrices.html#accessing-matrix-values"><i class="fa fa-check"></i><b>15.1</b> Accessing matrix values</a></li>
</ul></li>
<li class="part"><span><b>II Data Visualization</b></span></li>
<li class="chapter" data-level="16" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>16</b> Introduction</a></li>
<li class="chapter" data-level="17" data-path="variable-types.html"><a href="variable-types.html"><i class="fa fa-check"></i><b>17</b> Variable types</a><ul>
<li class="chapter" data-level="" data-path="variable-types.html"><a href="variable-types.html#exercise-1"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>18</b> Distributions</a><ul>
<li class="chapter" data-level="18.1" data-path="distributions.html"><a href="distributions.html#case-study-student-heights"><i class="fa fa-check"></i><b>18.1</b> Case study: student heights</a></li>
<li class="chapter" data-level="18.2" data-path="distributions.html"><a href="distributions.html#distribution-function"><i class="fa fa-check"></i><b>18.2</b> Distribution function</a></li>
<li class="chapter" data-level="18.3" data-path="distributions.html"><a href="distributions.html#cumulative-distribution-functions"><i class="fa fa-check"></i><b>18.3</b> Cumulative distribution functions</a></li>
<li class="chapter" data-level="18.4" data-path="distributions.html"><a href="distributions.html#histograms-1"><i class="fa fa-check"></i><b>18.4</b> Histograms</a></li>
<li class="chapter" data-level="18.5" data-path="distributions.html"><a href="distributions.html#smoothed-density"><i class="fa fa-check"></i><b>18.5</b> Smoothed density</a><ul>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#interpreting-the-y-axis"><i class="fa fa-check"></i>Interpreting the y-axis</a></li>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#densities-permit-stratification"><i class="fa fa-check"></i>Densities permit stratification</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercises-8"><i class="fa fa-check"></i>Exercises</a></li>
<li class="chapter" data-level="18.6" data-path="distributions.html"><a href="distributions.html#the-normal-distribution"><i class="fa fa-check"></i><b>18.6</b> The normal distribution</a><ul>
<li class="chapter" data-level="18.6.1" data-path="distributions.html"><a href="distributions.html#standardized-units"><i class="fa fa-check"></i><b>18.6.1</b> Standardized units</a></li>
<li class="chapter" data-level="18.6.2" data-path="distributions.html"><a href="distributions.html#quantile-quantile-qq-plots"><i class="fa fa-check"></i><b>18.6.2</b> Quantile-quantile QQ plots</a></li>
</ul></li>
<li class="chapter" data-level="18.7" data-path="distributions.html"><a href="distributions.html#percentiles"><i class="fa fa-check"></i><b>18.7</b> Percentiles</a></li>
<li class="chapter" data-level="18.8" data-path="distributions.html"><a href="distributions.html#case-study-coninued-summarizing-male-heights-with-two-numbers"><i class="fa fa-check"></i><b>18.8</b> Case study coninued: summarizing male heights with two numbers</a></li>
<li class="chapter" data-level="" data-path="distributions.html"><a href="distributions.html#exercises-9"><i class="fa fa-check"></i>Exercises</a></li>
<li class="chapter" data-level="18.9" data-path="distributions.html"><a href="distributions.html#boxplots"><i class="fa fa-check"></i><b>18.9</b> Boxplots</a></li>
<li class="chapter" data-level="18.10" data-path="distributions.html"><a href="distributions.html#case-study-continued-female-student-heights"><i class="fa fa-check"></i><b>18.10</b> Case study continued: female student heights</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="robust-summaries.html"><a href="robust-summaries.html"><i class="fa fa-check"></i><b>19</b> Robust summaries</a><ul>
<li class="chapter" data-level="19.1" data-path="robust-summaries.html"><a href="robust-summaries.html#outliers"><i class="fa fa-check"></i><b>19.1</b> Outliers</a></li>
<li class="chapter" data-level="19.2" data-path="robust-summaries.html"><a href="robust-summaries.html#median"><i class="fa fa-check"></i><b>19.2</b> Median</a></li>
<li class="chapter" data-level="19.3" data-path="robust-summaries.html"><a href="robust-summaries.html#the-inter-quartile-range-iqr"><i class="fa fa-check"></i><b>19.3</b> The inter quartile range (IQR)</a></li>
<li class="chapter" data-level="19.4" data-path="robust-summaries.html"><a href="robust-summaries.html#tukeys-definition-of-an-outlier"><i class="fa fa-check"></i><b>19.4</b> Tukey’s definition of an outlier</a></li>
<li class="chapter" data-level="19.5" data-path="robust-summaries.html"><a href="robust-summaries.html#median-absolute-deviation"><i class="fa fa-check"></i><b>19.5</b> Median absolute deviation</a></li>
<li class="chapter" data-level="" data-path="robust-summaries.html"><a href="robust-summaries.html#exercises-10"><i class="fa fa-check"></i>Exercises</a></li>
<li class="chapter" data-level="19.6" data-path="robust-summaries.html"><a href="robust-summaries.html#case-study-self-reported-heights"><i class="fa fa-check"></i><b>19.6</b> Case study: self-reported heights</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="summarizing-data-with-dplyr.html"><a href="summarizing-data-with-dplyr.html"><i class="fa fa-check"></i><b>20</b> Summarizing data with dplyr</a><ul>
<li class="chapter" data-level="20.1" data-path="summarizing-data-with-dplyr.html"><a href="summarizing-data-with-dplyr.html#summarize"><i class="fa fa-check"></i><b>20.1</b> Summarize</a></li>
<li class="chapter" data-level="20.2" data-path="summarizing-data-with-dplyr.html"><a href="summarizing-data-with-dplyr.html#the-dot-operator"><i class="fa fa-check"></i><b>20.2</b> The dot operator</a></li>
<li class="chapter" data-level="20.3" data-path="summarizing-data-with-dplyr.html"><a href="summarizing-data-with-dplyr.html#group-then-summarize"><i class="fa fa-check"></i><b>20.3</b> Group then summarize</a></li>
<li class="chapter" data-level="20.4" data-path="summarizing-data-with-dplyr.html"><a href="summarizing-data-with-dplyr.html#sorting-data-frames"><i class="fa fa-check"></i><b>20.4</b> Sorting data frames</a><ul>
<li class="chapter" data-level="" data-path="summarizing-data-with-dplyr.html"><a href="summarizing-data-with-dplyr.html#nested-sorting"><i class="fa fa-check"></i>Nested sorting</a></li>
<li><a href="summarizing-data-with-dplyr.html#the-top-n">The top <span class="math inline">\(n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="summarizing-data-with-dplyr.html"><a href="summarizing-data-with-dplyr.html#exercises-11"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="ggplot2.html"><a href="ggplot2.html"><i class="fa fa-check"></i><b>21</b> ggplot2</a><ul>
<li class="chapter" data-level="21.1" data-path="ggplot2.html"><a href="ggplot2.html#the-cheat-sheet"><i class="fa fa-check"></i><b>21.1</b> The cheat sheet</a></li>
<li class="chapter" data-level="21.2" data-path="ggplot2.html"><a href="ggplot2.html#the-components-of-a-graph"><i class="fa fa-check"></i><b>21.2</b> The components of a graph</a></li>
<li class="chapter" data-level="21.3" data-path="ggplot2.html"><a href="ggplot2.html#ggplot-objects-a-blank-slate"><i class="fa fa-check"></i><b>21.3</b> <code>ggplot</code> objects: a blank slate</a></li>
<li class="chapter" data-level="21.4" data-path="ggplot2.html"><a href="ggplot2.html#geometries"><i class="fa fa-check"></i><b>21.4</b> Geometries</a></li>
<li class="chapter" data-level="21.5" data-path="ggplot2.html"><a href="ggplot2.html#aesthetic-mappings"><i class="fa fa-check"></i><b>21.5</b> Aesthetic mappings</a></li>
<li class="chapter" data-level="21.6" data-path="ggplot2.html"><a href="ggplot2.html#layers"><i class="fa fa-check"></i><b>21.6</b> Layers</a></li>
<li class="chapter" data-level="21.7" data-path="ggplot2.html"><a href="ggplot2.html#tinkering-with-arguments"><i class="fa fa-check"></i><b>21.7</b> Tinkering with arguments</a></li>
<li class="chapter" data-level="21.8" data-path="ggplot2.html"><a href="ggplot2.html#global-versus-local-aesthetic-mappings"><i class="fa fa-check"></i><b>21.8</b> Global versus local aesthetic mappings</a></li>
<li class="chapter" data-level="21.9" data-path="ggplot2.html"><a href="ggplot2.html#scales"><i class="fa fa-check"></i><b>21.9</b> Scales</a></li>
<li class="chapter" data-level="21.10" data-path="ggplot2.html"><a href="ggplot2.html#labels-and-titles"><i class="fa fa-check"></i><b>21.10</b> Labels and titles</a></li>
<li class="chapter" data-level="21.11" data-path="ggplot2.html"><a href="ggplot2.html#categories-as-colors"><i class="fa fa-check"></i><b>21.11</b> Categories as colors</a></li>
<li class="chapter" data-level="21.12" data-path="ggplot2.html"><a href="ggplot2.html#annotation-and-shapes"><i class="fa fa-check"></i><b>21.12</b> Annotation and shapes</a></li>
<li class="chapter" data-level="21.13" data-path="ggplot2.html"><a href="ggplot2.html#adjustments"><i class="fa fa-check"></i><b>21.13</b> Adjustments</a></li>
<li class="chapter" data-level="21.14" data-path="ggplot2.html"><a href="ggplot2.html#add-on-packages"><i class="fa fa-check"></i><b>21.14</b> Add-on packages</a></li>
<li class="chapter" data-level="21.15" data-path="ggplot2.html"><a href="ggplot2.html#putting-it-all-together"><i class="fa fa-check"></i><b>21.15</b> Putting it all together</a></li>
<li class="chapter" data-level="21.16" data-path="ggplot2.html"><a href="ggplot2.html#other-geometries"><i class="fa fa-check"></i><b>21.16</b> Other geometries</a><ul>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#histogram"><i class="fa fa-check"></i>Histogram</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#density"><i class="fa fa-check"></i>Density</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#qq-plots"><i class="fa fa-check"></i>QQ-plots</a></li>
</ul></li>
<li class="chapter" data-level="21.17" data-path="ggplot2.html"><a href="ggplot2.html#grids-of-plots"><i class="fa fa-check"></i><b>21.17</b> Grids of plots</a></li>
<li class="chapter" data-level="21.18" data-path="ggplot2.html"><a href="ggplot2.html#quick-plots-with-qplot"><i class="fa fa-check"></i><b>21.18</b> Quick plots with <code>qplot</code></a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html"><i class="fa fa-check"></i><b>22</b> Case study: Trends in world health and economics</a><ul>
<li class="chapter" data-level="22.1" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#example-1-life-expectancy-and-fertility-rates"><i class="fa fa-check"></i><b>22.1</b> Example 1: Life expectancy and fertility rates</a><ul>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#hans-roslings-quiz"><i class="fa fa-check"></i>Hans Rosling’s quiz</a></li>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#a-scatterplot"><i class="fa fa-check"></i>A scatterplot</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#faceting"><i class="fa fa-check"></i><b>22.2</b> Faceting</a><ul>
<li><a href="case-study-trends-in-world-health-and-economics.html#facet_wrap"><code>facet_wrap</code></a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#fixed-scales-for-better-comparisons"><i class="fa fa-check"></i><b>22.3</b> Fixed scales for better comparisons</a></li>
<li class="chapter" data-level="22.4" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#time-series-plots"><i class="fa fa-check"></i><b>22.4</b> Time series plots</a></li>
<li class="chapter" data-level="22.5" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#labels-for-legends"><i class="fa fa-check"></i><b>22.5</b> Labels for legends</a></li>
<li class="chapter" data-level="22.6" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#example-2-income-distribution"><i class="fa fa-check"></i><b>22.6</b> Example 2: Income distribution</a></li>
<li class="chapter" data-level="22.7" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#transformations"><i class="fa fa-check"></i><b>22.7</b> Transformations</a><ul>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#country-income-distribution"><i class="fa fa-check"></i>Country income distribution</a></li>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#which-base"><i class="fa fa-check"></i>Which base?</a></li>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#transform-the-values-or-the-scale"><i class="fa fa-check"></i>Transform the values or the scale?</a></li>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#modes"><i class="fa fa-check"></i>Modes</a></li>
</ul></li>
<li class="chapter" data-level="22.8" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#stratify-and-boxplot"><i class="fa fa-check"></i><b>22.8</b> Stratify and boxplot</a><ul>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#do-not-order-alphabetically"><i class="fa fa-check"></i>Do not order alphabetically</a></li>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#show-the-data"><i class="fa fa-check"></i>Show the data</a></li>
</ul></li>
<li class="chapter" data-level="22.9" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#comparing-distributions"><i class="fa fa-check"></i><b>22.9</b> Comparing distributions</a><ul>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#density-plots"><i class="fa fa-check"></i>Density plots</a></li>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#accessing-computed-variables"><i class="fa fa-check"></i>Accessing computed variables</a></li>
<li class="chapter" data-level="22.9.1" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#case_when"><i class="fa fa-check"></i><b>22.9.1</b> ‘case_when’</a></li>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#weighted-densities"><i class="fa fa-check"></i>Weighted densities</a></li>
</ul></li>
<li class="chapter" data-level="22.10" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#ecological-fallacy"><i class="fa fa-check"></i><b>22.10</b> Ecological fallacy</a><ul>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#logistic-transformation"><i class="fa fa-check"></i>Logistic transformation</a></li>
<li class="chapter" data-level="" data-path="case-study-trends-in-world-health-and-economics.html"><a href="case-study-trends-in-world-health-and-economics.html#show-the-data-1"><i class="fa fa-check"></i>Show the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html"><i class="fa fa-check"></i><b>23</b> Data visualization principles</a><ul>
<li class="chapter" data-level="23.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#encoding-data-using-visual-cues"><i class="fa fa-check"></i><b>23.1</b> Encoding data using visual cues</a></li>
<li class="chapter" data-level="23.2" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#know-when-to-include-0"><i class="fa fa-check"></i><b>23.2</b> Know when to include 0</a></li>
<li class="chapter" data-level="23.3" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#do-not-distort-quantities"><i class="fa fa-check"></i><b>23.3</b> Do not distort quantities</a></li>
<li class="chapter" data-level="23.4" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#order-by-a-meaningful-value"><i class="fa fa-check"></i><b>23.4</b> Order by a meaningful value</a></li>
<li class="chapter" data-level="23.5" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#show-the-data-2"><i class="fa fa-check"></i><b>23.5</b> Show the data</a></li>
<li class="chapter" data-level="23.6" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#ease-comparisons-use-common-axes"><i class="fa fa-check"></i><b>23.6</b> Ease comparisons: use common axes</a></li>
<li class="chapter" data-level="23.7" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#ease-comparisons-align-plots-vertically-to-see-horizontal-changes-and-horizontally-to-see-vertical-changes"><i class="fa fa-check"></i><b>23.7</b> Ease comparisons: align plots vertically to see horizontal changes and horizontally to see vertical changes</a></li>
<li class="chapter" data-level="23.8" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#consider-transformations"><i class="fa fa-check"></i><b>23.8</b> Consider transformations</a></li>
<li class="chapter" data-level="23.9" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#ease-comparisons-visual-cues-to-be-compared-should-be-adjacent."><i class="fa fa-check"></i><b>23.9</b> Ease comparisons: Visual cues to be compared should be adjacent.</a></li>
<li class="chapter" data-level="23.10" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#ease-comparison-use-color"><i class="fa fa-check"></i><b>23.10</b> Ease comparison: use color</a></li>
<li class="chapter" data-level="23.11" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#think-of-the-color-blind"><i class="fa fa-check"></i><b>23.11</b> Think of the color blind</a></li>
<li class="chapter" data-level="23.12" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#use-scatterplots-to-examine-the-relationship-between-two-variables"><i class="fa fa-check"></i><b>23.12</b> Use scatterplots to examine the relationship between two variables</a><ul>
<li class="chapter" data-level="23.12.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#slope-charts"><i class="fa fa-check"></i><b>23.12.1</b> Slope charts</a></li>
<li class="chapter" data-level="23.12.2" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#bland-altman-plot"><i class="fa fa-check"></i><b>23.12.2</b> Bland-Altman plot</a></li>
</ul></li>
<li class="chapter" data-level="23.13" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#encoding-a-third-variable"><i class="fa fa-check"></i><b>23.13</b> Encoding a third variable</a></li>
<li class="chapter" data-level="23.14" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#avoid-pseudo-three-dimensional-plots"><i class="fa fa-check"></i><b>23.14</b> Avoid pseudo three dimensional plots</a></li>
<li class="chapter" data-level="23.15" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#avoid-gratuitous-three-dimensional-plots"><i class="fa fa-check"></i><b>23.15</b> Avoid gratuitous three dimensional plots</a></li>
<li class="chapter" data-level="23.16" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#avoid-too-many-significant-digits"><i class="fa fa-check"></i><b>23.16</b> Avoid too many significant digits</a></li>
<li class="chapter" data-level="23.17" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#further-reading"><i class="fa fa-check"></i><b>23.17</b> Further reading:</a></li>
<li class="chapter" data-level="" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#exercises-12"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="case-study-the-impact-of-vaccines-on-battling-infectious-diseases.html"><a href="case-study-the-impact-of-vaccines-on-battling-infectious-diseases.html"><i class="fa fa-check"></i><b>24</b> Case study: the impact of vaccines on battling infectious diseases</a></li>
<li class="part"><span><b>III Probability</b></span></li>
<li class="chapter" data-level="25" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i><b>25</b> Introduction</a></li>
<li class="chapter" data-level="26" data-path="discrete-probability.html"><a href="discrete-probability.html"><i class="fa fa-check"></i><b>26</b> Discrete probability</a><ul>
<li class="chapter" data-level="26.1" data-path="discrete-probability.html"><a href="discrete-probability.html#relative-frequency"><i class="fa fa-check"></i><b>26.1</b> Relative frequency</a></li>
<li class="chapter" data-level="26.2" data-path="discrete-probability.html"><a href="discrete-probability.html#notation"><i class="fa fa-check"></i><b>26.2</b> Notation</a></li>
<li class="chapter" data-level="26.3" data-path="discrete-probability.html"><a href="discrete-probability.html#monte-carlo-simulations"><i class="fa fa-check"></i><b>26.3</b> Monte Carlo simulations</a></li>
<li class="chapter" data-level="26.4" data-path="discrete-probability.html"><a href="discrete-probability.html#setting-the-random-seed"><i class="fa fa-check"></i><b>26.4</b> Setting the random seed</a><ul>
<li class="chapter" data-level="" data-path="discrete-probability.html"><a href="discrete-probability.html#with-and-without-replacement"><i class="fa fa-check"></i>With and without replacement</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="discrete-probability.html"><a href="discrete-probability.html#probability-distributions"><i class="fa fa-check"></i><b>26.5</b> Probability distributions</a></li>
<li class="chapter" data-level="26.6" data-path="discrete-probability.html"><a href="discrete-probability.html#independence"><i class="fa fa-check"></i><b>26.6</b> Independence</a></li>
<li class="chapter" data-level="26.7" data-path="discrete-probability.html"><a href="discrete-probability.html#conditional-probabilities"><i class="fa fa-check"></i><b>26.7</b> Conditional probabilities</a></li>
<li class="chapter" data-level="26.8" data-path="discrete-probability.html"><a href="discrete-probability.html#multiplication-rule"><i class="fa fa-check"></i><b>26.8</b> Multiplication rule</a><ul>
<li class="chapter" data-level="" data-path="discrete-probability.html"><a href="discrete-probability.html#multiplication-rule-under-indepedence"><i class="fa fa-check"></i>Multiplication rule under indepedence</a></li>
</ul></li>
<li class="chapter" data-level="26.9" data-path="discrete-probability.html"><a href="discrete-probability.html#combinations-and-permutations"><i class="fa fa-check"></i><b>26.9</b> Combinations and permutations</a><ul>
<li class="chapter" data-level="" data-path="discrete-probability.html"><a href="discrete-probability.html#monte-carlo-example"><i class="fa fa-check"></i>Monte Carlo example</a></li>
</ul></li>
<li class="chapter" data-level="26.10" data-path="discrete-probability.html"><a href="discrete-probability.html#birthday-problem"><i class="fa fa-check"></i><b>26.10</b> Birthday problem</a></li>
<li class="chapter" data-level="26.11" data-path="discrete-probability.html"><a href="discrete-probability.html#how-many-monte-carlo-experiments-are-enough"><i class="fa fa-check"></i><b>26.11</b> How many Monte Carlo experiments are enough</a></li>
<li class="chapter" data-level="26.12" data-path="discrete-probability.html"><a href="discrete-probability.html#addition-rule"><i class="fa fa-check"></i><b>26.12</b> Addition rule</a></li>
<li class="chapter" data-level="26.13" data-path="discrete-probability.html"><a href="discrete-probability.html#monty-hall-problem"><i class="fa fa-check"></i><b>26.13</b> Monty Hall problem</a></li>
<li class="chapter" data-level="" data-path="discrete-probability.html"><a href="discrete-probability.html#exercises-13"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="continuous-probability.html"><a href="continuous-probability.html"><i class="fa fa-check"></i><b>27</b> Continuous probability</a><ul>
<li class="chapter" data-level="27.1" data-path="continuous-probability.html"><a href="continuous-probability.html#theoretical-distribution"><i class="fa fa-check"></i><b>27.1</b> Theoretical distribution</a></li>
<li class="chapter" data-level="27.2" data-path="continuous-probability.html"><a href="continuous-probability.html#approximations"><i class="fa fa-check"></i><b>27.2</b> Approximations</a></li>
<li class="chapter" data-level="27.3" data-path="continuous-probability.html"><a href="continuous-probability.html#the-probability-density"><i class="fa fa-check"></i><b>27.3</b> The probability density</a></li>
<li class="chapter" data-level="27.4" data-path="continuous-probability.html"><a href="continuous-probability.html#monte-carlo-simulations-1"><i class="fa fa-check"></i><b>27.4</b> Monte Carlo simulations</a></li>
<li class="chapter" data-level="27.5" data-path="continuous-probability.html"><a href="continuous-probability.html#other-continuous-distributions"><i class="fa fa-check"></i><b>27.5</b> Other continuous distributions</a></li>
<li class="chapter" data-level="" data-path="continuous-probability.html"><a href="continuous-probability.html#exercise-2"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>28</b> Random variables</a><ul>
<li class="chapter" data-level="28.1" data-path="random-variables.html"><a href="random-variables.html#sampling-models"><i class="fa fa-check"></i><b>28.1</b> Sampling models</a></li>
<li class="chapter" data-level="28.2" data-path="random-variables.html"><a href="random-variables.html#the-probability-distribution-of-a-random-variable"><i class="fa fa-check"></i><b>28.2</b> The probability distribution of a random variable</a></li>
<li class="chapter" data-level="28.3" data-path="random-variables.html"><a href="random-variables.html#distributions-versus-probability-distributions"><i class="fa fa-check"></i><b>28.3</b> Distributions versus probability distributions</a></li>
<li class="chapter" data-level="28.4" data-path="random-variables.html"><a href="random-variables.html#notation-for-random-variables"><i class="fa fa-check"></i><b>28.4</b> Notation for random variables</a></li>
<li class="chapter" data-level="28.5" data-path="random-variables.html"><a href="random-variables.html#central-limit-theorem"><i class="fa fa-check"></i><b>28.5</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="28.6" data-path="random-variables.html"><a href="random-variables.html#the-expected-value-and-standard-error"><i class="fa fa-check"></i><b>28.6</b> The expected value and standard error</a></li>
<li class="chapter" data-level="28.7" data-path="random-variables.html"><a href="random-variables.html#central-limit-theorem-approximation"><i class="fa fa-check"></i><b>28.7</b> Central Limit Theorem approximation</a></li>
<li class="chapter" data-level="28.8" data-path="random-variables.html"><a href="random-variables.html#statistical-properties-of-averages"><i class="fa fa-check"></i><b>28.8</b> Statistical properties of averages</a><ul>
<li><a href="random-variables.html#why-we-use-mu-and-sigma">Why we use <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span></a></li>
</ul></li>
<li class="chapter" data-level="28.9" data-path="random-variables.html"><a href="random-variables.html#law-of-large-numbers"><i class="fa fa-check"></i><b>28.9</b> Law of large numbers</a><ul>
<li class="chapter" data-level="28.9.1" data-path="random-variables.html"><a href="random-variables.html#misinterpreting-law-of-averages"><i class="fa fa-check"></i><b>28.9.1</b> Misinterpreting law of averages</a></li>
</ul></li>
<li class="chapter" data-level="28.10" data-path="random-variables.html"><a href="random-variables.html#how-large-is-large-in-clt"><i class="fa fa-check"></i><b>28.10</b> How large is large in CLT?</a></li>
<li class="chapter" data-level="28.11" data-path="random-variables.html"><a href="random-variables.html#population-sd-versus-the-sample-sd"><i class="fa fa-check"></i><b>28.11</b> Population SD versus the sample SD</a></li>
<li class="chapter" data-level="" data-path="random-variables.html"><a href="random-variables.html#exercises-14"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="case-study-the-big-short.html"><a href="case-study-the-big-short.html"><i class="fa fa-check"></i><b>29</b> Case study: The Big Short</a><ul>
<li class="chapter" data-level="29.1" data-path="case-study-the-big-short.html"><a href="case-study-the-big-short.html#interest-rates-explained-with-chance-model"><i class="fa fa-check"></i><b>29.1</b> Interest rates explained with chance model</a></li>
<li class="chapter" data-level="29.2" data-path="case-study-the-big-short.html"><a href="case-study-the-big-short.html#the-big-short"><i class="fa fa-check"></i><b>29.2</b> The Big Short</a></li>
<li class="chapter" data-level="" data-path="case-study-the-big-short.html"><a href="case-study-the-big-short.html#exercises-15"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="part"><span><b>IV Inference and modeling</b></span></li>
<li class="chapter" data-level="30" data-path="introduction-4.html"><a href="introduction-4.html"><i class="fa fa-check"></i><b>30</b> Introduction</a></li>
<li class="chapter" data-level="31" data-path="polls.html"><a href="polls.html"><i class="fa fa-check"></i><b>31</b> Polls</a><ul>
<li class="chapter" data-level="31.1" data-path="polls.html"><a href="polls.html#the-sampling-model-for-polls"><i class="fa fa-check"></i><b>31.1</b> The sampling model for polls</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="populations-samples-parameters-and-estimates.html"><a href="populations-samples-parameters-and-estimates.html"><i class="fa fa-check"></i><b>32</b> Populations, samples, parameters and estimates</a><ul>
<li class="chapter" data-level="32.1" data-path="populations-samples-parameters-and-estimates.html"><a href="populations-samples-parameters-and-estimates.html#the-sample-average"><i class="fa fa-check"></i><b>32.1</b> The sample average</a></li>
<li class="chapter" data-level="32.2" data-path="populations-samples-parameters-and-estimates.html"><a href="populations-samples-parameters-and-estimates.html#parameters"><i class="fa fa-check"></i><b>32.2</b> Parameters</a></li>
<li class="chapter" data-level="32.3" data-path="populations-samples-parameters-and-estimates.html"><a href="populations-samples-parameters-and-estimates.html#polling-versus-forecasting"><i class="fa fa-check"></i><b>32.3</b> Polling versus forecasting</a></li>
<li class="chapter" data-level="32.4" data-path="populations-samples-parameters-and-estimates.html"><a href="populations-samples-parameters-and-estimates.html#properties-of-our-estimate-expected-value-and-standard-error"><i class="fa fa-check"></i><b>32.4</b> Properties of our estimate: expected value and standard error</a></li>
<li class="chapter" data-level="" data-path="populations-samples-parameters-and-estimates.html"><a href="populations-samples-parameters-and-estimates.html#exercises-16"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="central-limit-theorem-in-practice.html"><a href="central-limit-theorem-in-practice.html"><i class="fa fa-check"></i><b>33</b> Central Limit Theorem in practice</a><ul>
<li class="chapter" data-level="33.1" data-path="central-limit-theorem-in-practice.html"><a href="central-limit-theorem-in-practice.html#a-monte-carlo-simulation"><i class="fa fa-check"></i><b>33.1</b> A Monte Carlo simulation</a></li>
<li class="chapter" data-level="33.2" data-path="central-limit-theorem-in-practice.html"><a href="central-limit-theorem-in-practice.html#the-spread"><i class="fa fa-check"></i><b>33.2</b> The spread</a></li>
<li class="chapter" data-level="33.3" data-path="central-limit-theorem-in-practice.html"><a href="central-limit-theorem-in-practice.html#bias-why-not-run-a-very-large-poll"><i class="fa fa-check"></i><b>33.3</b> Bias: why not run a very large poll?</a></li>
<li class="chapter" data-level="" data-path="central-limit-theorem-in-practice.html"><a href="central-limit-theorem-in-practice.html#exercises-17"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>34</b> Confidence intervals</a><ul>
<li class="chapter" data-level="34.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#a-monte-carlo-simulation-1"><i class="fa fa-check"></i><b>34.1</b> A Monte Carlo simulation</a></li>
<li class="chapter" data-level="34.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#the-correct-language"><i class="fa fa-check"></i><b>34.2</b> The correct language</a></li>
<li class="chapter" data-level="34.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#power"><i class="fa fa-check"></i><b>34.3</b> Power</a></li>
<li class="chapter" data-level="34.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#p-values"><i class="fa fa-check"></i><b>34.4</b> p-values</a></li>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#exercises-18"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="statistical-models.html"><a href="statistical-models.html"><i class="fa fa-check"></i><b>35</b> Statistical models</a><ul>
<li class="chapter" data-level="35.1" data-path="statistical-models.html"><a href="statistical-models.html#poll-aggregators"><i class="fa fa-check"></i><b>35.1</b> Poll aggregators</a></li>
<li class="chapter" data-level="35.2" data-path="statistical-models.html"><a href="statistical-models.html#poll-data"><i class="fa fa-check"></i><b>35.2</b> Poll data</a></li>
<li class="chapter" data-level="35.3" data-path="statistical-models.html"><a href="statistical-models.html#pollster-bias"><i class="fa fa-check"></i><b>35.3</b> Pollster bias</a></li>
<li class="chapter" data-level="35.4" data-path="statistical-models.html"><a href="statistical-models.html#data-driven-model"><i class="fa fa-check"></i><b>35.4</b> Data driven model</a></li>
<li class="chapter" data-level="" data-path="statistical-models.html"><a href="statistical-models.html#exercises-19"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="36" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>36</b> Bayesian statistics</a><ul>
<li class="chapter" data-level="36.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-theorem"><i class="fa fa-check"></i><b>36.1</b> Bayes theorem</a></li>
<li class="chapter" data-level="36.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-theorem-simulation"><i class="fa fa-check"></i><b>36.2</b> Bayes Theorem simulation</a></li>
<li class="chapter" data-level="36.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-in-practice"><i class="fa fa-check"></i><b>36.3</b> Bayes in practice</a></li>
<li class="chapter" data-level="36.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#the-hierarchical-model"><i class="fa fa-check"></i><b>36.4</b> The hierarchical model</a></li>
<li class="chapter" data-level="" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#exercises-20"><i class="fa fa-check"></i>Exercises</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="election-forecasting.html"><a href="election-forecasting.html"><i class="fa fa-check"></i><b>37</b> Election forecasting</a><ul>
<li class="chapter" data-level="37.1" data-path="election-forecasting.html"><a href="election-forecasting.html#bayesian-approach"><i class="fa fa-check"></i><b>37.1</b> Bayesian approach</a></li>
<li class="chapter" data-level="37.2" data-path="election-forecasting.html"><a href="election-forecasting.html#the-general-bias"><i class="fa fa-check"></i><b>37.2</b> The general bias</a></li>
<li class="chapter" data-level="37.3" data-path="election-forecasting.html"><a href="election-forecasting.html#mathematical-representations-of-models"><i class="fa fa-check"></i><b>37.3</b> Mathematical representations of models</a></li>
<li class="chapter" data-level="37.4" data-path="election-forecasting.html"><a href="election-forecasting.html#predicting-the-electoral-college"><i class="fa fa-check"></i><b>37.4</b> Predicting the electoral college</a></li>
<li class="chapter" data-level="37.5" data-path="election-forecasting.html"><a href="election-forecasting.html#forecasting"><i class="fa fa-check"></i><b>37.5</b> Forecasting</a></li>
<li class="chapter" data-level="" data-path="election-forecasting.html"><a href="election-forecasting.html#exercise-3"><i class="fa fa-check"></i>Exercise</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="association-tests.html"><a href="association-tests.html"><i class="fa fa-check"></i><b>38</b> Association Tests</a><ul>
<li class="chapter" data-level="38.1" data-path="association-tests.html"><a href="association-tests.html#lady-tasting-tea"><i class="fa fa-check"></i><b>38.1</b> Lady Tasting Tea</a></li>
<li class="chapter" data-level="38.2" data-path="association-tests.html"><a href="association-tests.html#two-by-two-tables"><i class="fa fa-check"></i><b>38.2</b> Two-by-two tables</a></li>
<li class="chapter" data-level="38.3" data-path="association-tests.html"><a href="association-tests.html#chi-square-test"><i class="fa fa-check"></i><b>38.3</b> Chi-square Test</a></li>
<li class="chapter" data-level="38.4" data-path="association-tests.html"><a href="association-tests.html#the-odds-ratio"><i class="fa fa-check"></i><b>38.4</b> The Odds Ratio</a></li>
<li class="chapter" data-level="38.5" data-path="association-tests.html"><a href="association-tests.html#large-samples-small-p-values"><i class="fa fa-check"></i><b>38.5</b> Large samples, small p-values</a></li>
<li class="chapter" data-level="38.6" data-path="association-tests.html"><a href="association-tests.html#confidence-intervals-for-the-odds-ratio"><i class="fa fa-check"></i><b>38.6</b> Confidence intervals for the odds ratio</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="election-forecasting" class="section level1">
<h1><span class="header-section-number">Chapter 37</span> Election forecasting</h1>
<p>In previous section we generated these data tables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-31&quot;</span> <span class="op">&amp;</span>
<span class="st">           </span>(grade <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A+&quot;</span>,<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A-&quot;</span>,<span class="st">&quot;B+&quot;</span>) <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(grade))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)

one_poll_per_pollster &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(enddate <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(enddate)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>()

results &lt;-<span class="st"> </span>one_poll_per_pollster <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(spread), <span class="dt">se =</span> <span class="kw">sd</span>(spread)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">length</span>(spread))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">start =</span> avg <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>se, <span class="dt">end =</span> avg <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>se) </code></pre></div>
<p>We will use these below for our forecasting.</p>
<div id="bayesian-approach" class="section level2">
<h2><span class="header-section-number">37.1</span> Bayesian approach</h2>
<p>Pollsters tend to make probabilistic statements about the results of the election. For example, “The chance that Obama wins the electoral colleges is 91%” is a probabilistic statement about the parameter <span class="math inline">\(d\)</span>. We showed that for the 2016 election, FiveThirtyEight gave Clinton a 81.4% chance of winning the popular vote. To do this, they used the Bayesian approach we described.</p>
<p>We assume a hierarchical model similar to what we did to predict the performance of a baseball player. Statistical textbooks will write the model like this:</p>
<p><span class="math display">\[
\begin{aligned}
d &amp;\sim N(\mu, \tau^2) \mbox{ describes our best guess had we not seen any polling data}\\
\bar{X} \mid d &amp;\sim N(d, \sigma^2) \mbox{ describes randomness due to sampling and the  pollster effect}
\end{aligned}
\]</span></p>
<p>For our best guess, we note that before any poll data is available we can use data sources other than polling data. A popular approach is to use what are called <em>fundamentals</em>, which are based on properties about the current economy that historically appear to have an effect in favor or against the incumbent party. We won’t use these here. Instead we will use <span class="math inline">\(\mu = 0\)</span>, which is interpreted as a model that simply does not provide any information on who will win. For the standard deviation, we will use recent historical data that shows the winner of the popular vote has an average spread of about 3.5%. Therefore we set <span class="math inline">\(\tau = 0.035\)</span>.</p>
<p>Now we can use the formulas for the posterior distribution for the parameter <span class="math inline">\(d\)</span>: the probability of <span class="math inline">\(d&gt;0\)</span> given the observed poll data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="dv">0</span>
tau &lt;-<span class="st"> </span><span class="fl">0.035</span>
sigma &lt;-<span class="st"> </span>results<span class="op">$</span>se
Y &lt;-<span class="st"> </span>results<span class="op">$</span>avg
B &lt;-<span class="st"> </span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>)

posterior_mean &lt;-<span class="st"> </span>B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>Y
posterior_se &lt;-<span class="st"> </span><span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>))

posterior_mean
<span class="co">#&gt; [1] 0.0281</span>
posterior_se
<span class="co">#&gt; [1] 0.00615</span></code></pre></div>
<p>To make a probability statement, we use the fact that the posterior distribution is also normal. And we have a credible interval of:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">posterior_mean <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">1.96</span>, <span class="fl">1.96</span>)<span class="op">*</span>posterior_se
<span class="co">#&gt; [1] 0.0160 0.0401</span></code></pre></div>
<p>The posterior probability <span class="math inline">\(\mbox{Pr(d&gt;0 \mid \bar{X})}\)</span> is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">0</span>, posterior_mean, posterior_se)
<span class="co">#&gt; [1] 1</span></code></pre></div>
<p>This says we are 100% sure Clinton will win the popular vote which seems too overconfident. Also, it is not in agreement with FiveThirtyEight’s 81.4%. What explains this difference?</p>
</div>
<div id="the-general-bias" class="section level2">
<h2><span class="header-section-number">37.2</span> The general bias</h2>
<p>After elections are over, one can look at the difference between pollster predictions and actual result. An important observation that our model does not take into account, is that it is common to see the general bias that affects many pollsters in the same way. There is no good explanation for this, but we do observe it in historical data: in one election, the average of polls favors Democrats by 2%, then in the following election they favor Republicans by 1%, then in the next election there is no bias, then in the following one Republicans are favored by 3%, and so on. In 2016, the polls were biased in favor of the democrats by 1-2%.</p>
<p>Although we know this bias term affects our polls, we have no way of knowing what this bias is until election. So we can’t correct our polls accordingly. What we can do is include a term in our model that accounts for this variability.</p>
</div>
<div id="mathematical-representations-of-models" class="section level2">
<h2><span class="header-section-number">37.3</span> Mathematical representations of models</h2>
<p>Suppose we are collecting data from one pollster and we assume there is no general bias. The pollster collects several polls with a sample size of <span class="math inline">\(N\)</span>, so we observe several measurements of the spread <span class="math inline">\(X_1, \dots, X_J\)</span>. The theory tells us that these random variables have expected value <span class="math inline">\(d\)</span> and <span class="math inline">\(2 \sqrt{p(1-p)/N}\)</span>. For reasons that will soon become clear, we can represent this model mathematically like this:</p>
<p><span class="math display">\[
X_j = d + \varepsilon_j
\]</span> We use the index <span class="math inline">\(j\)</span> to represent the different polls and we define <span class="math inline">\(\varepsilon_j\)</span> to be a random variable that explains the poll to poll variability introduced by sampling error. To do this, we assume its average is 0 and standard error is <span class="math inline">\(2 \sqrt{p(1-p)/N}\)</span>. If <span class="math inline">\(d\)</span> is 2.1 and the sample size for these polls is 2,000, we can simulate <span class="math inline">\(J=6\)</span> data points from this model like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">3</span>)
J&lt;-<span class="st"> </span><span class="dv">6</span>
N &lt;-<span class="st"> </span><span class="dv">2000</span>
d &lt;-<span class="st"> </span>.<span class="dv">021</span>
p &lt;-<span class="st"> </span>(d <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>
X &lt;-<span class="st"> </span>d <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(J,<span class="dv">0</span>,<span class="dv">2</span><span class="op">*</span><span class="kw">sqrt</span>(p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)<span class="op">/</span>N))</code></pre></div>
<p>Now suppose we <span class="math inline">\(J=6\)</span> data points from have data from <span class="math inline">\(I=5\)</span> different pollsters. To represent this we now need two indexes, one for pollster and one for the polls each pollster takes. We use <span class="math inline">\(X_{ij}\)</span> with <span class="math inline">\(i\)</span> representing the pollster and <span class="math inline">\(j\)</span> representing the <span class="math inline">\(j\)</span>-th poll from that pollster. If we apply the same model, we write:</p>
<p><span class="math display">\[
X_{i,j} = d + h_i + \varepsilon_{i,j}
\]</span></p>
<p>To simulate data, we now have to loop through the pollsters:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">I &lt;-<span class="st"> </span><span class="dv">5</span>
J &lt;-<span class="st"> </span><span class="dv">6</span>
N &lt;-<span class="st"> </span><span class="dv">2000</span>
X &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span>I, <span class="cf">function</span>(i){
  d <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(J,<span class="dv">0</span>,<span class="dv">2</span><span class="op">*</span><span class="kw">sqrt</span>(p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)<span class="op">/</span>N))
})</code></pre></div>
<p>The simulated data:</p>
<p><img src="book_files/figure-html/simulated-data-without-bias-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>does not really seem to capture the features of the actual data:</p>
<p><img src="book_files/figure-html/pollster-bias-data-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The model above does not account for pollster to pollster variability. To fix this, we add a new term for the pollster effect. We will use <span class="math inline">\(\theta_i\)</span> to represent the house effect of the <span class="math inline">\(i\)</span>-th pollster. The model is now augmented to:</p>
<p><span class="math display">\[
X_{i,j} = d + h_i + \varepsilon_{i,j}
\]</span></p>
<p>To simulate data from a specific pollster, we now need to draw an <span class="math inline">\(h_i\)</span> and then add the <span class="math inline">\(\varepsilon\)</span>s. Here is how we would do it for one specific pollster. We assume <span class="math inline">\(\sigma_h\)</span> is 0.025:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">I &lt;-<span class="st"> </span><span class="dv">5</span>
J &lt;-<span class="st"> </span><span class="dv">6</span>
N &lt;-<span class="st"> </span><span class="dv">2000</span>
d &lt;-<span class="st"> </span>.<span class="dv">021</span>
p &lt;-<span class="st"> </span>(d <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>
h &lt;-<span class="st"> </span><span class="kw">rnorm</span>(I, <span class="dv">0</span>, <span class="fl">0.025</span>)
X &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span>I, <span class="cf">function</span>(i){
  d <span class="op">+</span><span class="st"> </span>h[i] <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(J,<span class="dv">0</span>,<span class="dv">2</span><span class="op">*</span><span class="kw">sqrt</span>(p<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p)<span class="op">/</span>N))
})</code></pre></div>
<p>The simulated data now looks more like the actual data:</p>
<p><img src="book_files/figure-html/simulated-pollster-data-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Note that <span class="math inline">\(h_i\)</span> is common to all the observed spreads from a specific pollster. Different pollsters have a different <span class="math inline">\(h_i\)</span>, which explains why we can see the groups of points shift up and down from pollster to pollster.</p>
<p>Now, in the model above, we assume the average house effect is 0. We think that for every pollster biased in favor of our party, there is another one in favor of the other and assume the standard deviation is <span class="math inline">\(\sigma_h\)</span>. But historically we see that every election has a general bias affecting all polls. We can observe this with the 2016 data, but if we collect historical data we see that the average of polls misses by more than models like the one above predict. To see this, we would take the average of polls for each election year and compare it to the actual value. If we did this, we would see a difference with a standard deviation of between 2-3%. To incorporate this into the model, we can add another term to account for this variability: <span class="math display">\[
X_{ij} = d + b + h_i + \varepsilon_{ij}
\]</span></p>
<p>and model <span class="math inline">\(b\)</span> as having expected value 0 and, based on historical data, assume the standard error for <span class="math inline">\(b\)</span> is <span class="math inline">\(\sigma_b = 0.025\)</span>.</p>
<p><span class="math display">\[
X_{ij} = d + b + h_i + \varepsilon_{ij}
\]</span></p>
<p>The variability of <span class="math inline">\(b\)</span> is not observed because every single poll we observe in 2016 has this general bias.</p>
<p>An implication of adding this term to the model is that the standard deviation for <span class="math inline">\(X_{ij}\)</span> is actually higher than what we earlier called <span class="math inline">\(\sigma\)</span>, which combines the pollster variability and the sample in variability, and was estimated with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(one_poll_per_pollster<span class="op">$</span>spread)
<span class="co">#&gt; [1] 0.0242</span></code></pre></div>
<p>since we have to add <span class="math inline">\(\sigma_b\)</span>.</p>
<p>And note that:</p>
<p><span class="math display">\[
\bar{X} = d + b + \frac{1}{N}\sum_{i=1}^N X_i
\]</span></p>
<p>which implies that the standard deviation of <span class="math inline">\(\bar{X}\)</span> is:</p>
<p><span class="math display">\[
\sqrt{\sigma^2/N + \sigma_b^2}
\]</span> Since the same <span class="math inline">\(b\)</span> is in every measurement, the average does not reduce its variance. This is an important point: it does not matter how many polls you take, this bias does not get reduced.</p>
<p>If we redo the Bayesian calculation taking this variability into account, we get a result much closer to FiveThirtyEight’s:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="dv">0</span>
tau &lt;-<span class="st"> </span><span class="fl">0.035</span>
sigma &lt;-<span class="st"> </span><span class="kw">sqrt</span>(results<span class="op">$</span>se<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>.<span class="dv">025</span><span class="op">^</span><span class="dv">2</span>)
Y &lt;-<span class="st"> </span>results<span class="op">$</span>avg
B &lt;-<span class="st"> </span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>)

posterior_mean &lt;-<span class="st"> </span>B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>Y
posterior_se &lt;-<span class="st"> </span><span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>))

<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">0</span>, posterior_mean, posterior_se)
<span class="co">#&gt; [1] 0.817</span></code></pre></div>
</div>
<div id="predicting-the-electoral-college" class="section level2">
<h2><span class="header-section-number">37.4</span> Predicting the electoral college</h2>
<p>Up to now we have focused on the popular vote. But in the United States, elections are not decided by the popular vote but rather by what is known as the electoral college. Each state gets a number of electoral votes that depends, in a somewhat complex way, on the population size of the state. Here are the top 5 states ranked by electoral votes:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">top_n</span>(<span class="dv">5</span>, electoral_votes)
<span class="co">#&gt;          state electoral_votes clinton trump others</span>
<span class="co">#&gt; 1   California              55    61.7  31.6    6.7</span>
<span class="co">#&gt; 2      Florida              29    47.8  49.0    3.2</span>
<span class="co">#&gt; 3     Illinois              20    55.8  38.8    5.4</span>
<span class="co">#&gt; 4     New York              29    59.0  36.5    4.5</span>
<span class="co">#&gt; 5 Pennsylvania              20    47.9  48.6    3.6</span>
<span class="co">#&gt; 6        Texas              38    43.2  52.2    4.5</span></code></pre></div>
<p>With some minor exceptions we don’t discuss, the electoral votes are won all or nothing. For example, if you win California by just 1 vote, you still get all 55 of its electoral votes. This means that by winning a few big states by a large margin, but losing many small states by small margins, you can win the popular vote and yet lose the electoral college. This happened in 1876, 1888, 2000 and 2016. The idea behind this is to avoid a few large states having the power to dominate the presidential election. Nonetheless, many people in the US consider the electoral college unfair and would like to see it abolished.</p>
<p>We are now ready to predict the electoral college result for 2016. We start by aggregating results from a poll taken during the last week before the election:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(state<span class="op">!=</span><span class="st">&quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>
<span class="st">           </span><span class="op">!</span><span class="kw">grepl</span>(<span class="st">&quot;CD&quot;</span>, state) <span class="op">&amp;</span><span class="st"> </span>
<span class="st">           </span>enddate <span class="op">&gt;=</span><span class="st">&quot;2016-10-31&quot;</span> <span class="op">&amp;</span><span class="st"> </span>
<span class="st">           </span>(grade <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A+&quot;</span>,<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A-&quot;</span>,<span class="st">&quot;B+&quot;</span>) <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(grade))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(state) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(spread), <span class="dt">sd =</span> <span class="kw">sd</span>(spread), <span class="dt">n =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">state =</span> <span class="kw">as.character</span>(state))</code></pre></div>
<p>Here are the 10 closest races according to the polls:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">abs</span>(avg))
<span class="co">#&gt; # A tibble: 47 x 4</span>
<span class="co">#&gt;            state      avg     sd     n</span>
<span class="co">#&gt;            &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;</span>
<span class="co">#&gt; 1        Florida  0.00356 0.0163     7</span>
<span class="co">#&gt; 2 North Carolina -0.00730 0.0306     9</span>
<span class="co">#&gt; 3           Ohio -0.01042 0.0252     6</span>
<span class="co">#&gt; 4         Nevada  0.01686 0.0441     7</span>
<span class="co">#&gt; 5           Iowa -0.01973 0.0437     3</span>
<span class="co">#&gt; 6       Michigan  0.02095 0.0203     6</span>
<span class="co">#&gt; # ... with 41 more rows</span></code></pre></div>
<p>We now introduce the command <code>left_join</code> that will let us easily add the number of electoral votes for each state from the data set <code>us_electoral_votes_2016</code>. We will describe this function in detail in the Wrangling chapter. Here, we simply say that the function combines the two datasets so that the information from the second argument is added to the information in the first:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span><span class="kw">left_join</span>(results, results_us_election_<span class="dv">2016</span>, <span class="dt">by =</span> <span class="st">&quot;state&quot;</span>)</code></pre></div>
<p>Notice that some states have no polls because the winner is pretty much known:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="op">!</span>state <span class="op">%in%</span><span class="st"> </span>results<span class="op">$</span>state)
<span class="co">#&gt;                  state electoral_votes clinton trump others</span>
<span class="co">#&gt; 1               Alaska               3    36.6  51.3   12.2</span>
<span class="co">#&gt; 2         Rhode Island               4    54.4  38.9    6.7</span>
<span class="co">#&gt; 3              Wyoming               3    21.9  68.2   10.0</span>
<span class="co">#&gt; 4 District of Columbia               3    90.9   4.1    5.0</span></code></pre></div>
<p>No polls were conducted in DC, Rhode Island, Alaska, and Wyoming because the first two are sure to be Democrats and the last two Republicans.</p>
<p>The code below assigns a standard deviation, the median of the rest, to states with just one poll.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span>results <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sd =</span> <span class="kw">ifelse</span>(<span class="kw">is.na</span>(sd), <span class="kw">median</span>(results<span class="op">$</span>sd, <span class="dt">na.rm=</span><span class="ot">TRUE</span>), sd))</code></pre></div>
<p>To make probabilistic arguments, we will use a Monte Carlo simulation. For each state, we apply the Bayesian approach to generate an election day <span class="math inline">\(d\)</span>. We could construct the priors for each state based on recent history. However, to keep it simple, we assign a prior to each state that assumes we know nothing about what will happen. Since from election year to election year the results from a specific state don’t change that much, we will assign a standard deviation of 2% or <span class="math inline">\(\tau=0.02\)</span>. The Bayesian calculation looks like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="dv">0</span>
tau &lt;-<span class="st"> </span><span class="fl">0.02</span>
results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">sigma =</span> sd<span class="op">/</span><span class="kw">sqrt</span>(n), 
                   <span class="dt">B =</span> sigma<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(sd<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>),
                   <span class="dt">posterior_mean =</span> B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>avg,
                   <span class="dt">posterior_se =</span> <span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">abs</span>(posterior_mean))
<span class="co">#&gt; # A tibble: 47 x 12</span>
<span class="co">#&gt;            state      avg     sd     n electoral_votes clinton trump</span>
<span class="co">#&gt;            &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;           &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;</span>
<span class="co">#&gt; 1        Florida  0.00356 0.0163     7              29    47.8  49.0</span>
<span class="co">#&gt; 2 North Carolina -0.00730 0.0306     9              15    46.2  49.8</span>
<span class="co">#&gt; 3           Ohio -0.01042 0.0252     6              18    43.5  51.7</span>
<span class="co">#&gt; 4           Iowa -0.01973 0.0437     3               6    41.7  51.1</span>
<span class="co">#&gt; 5         Nevada  0.01686 0.0441     7               6    47.9  45.5</span>
<span class="co">#&gt; 6       Michigan  0.02095 0.0203     6              16    47.3  47.5</span>
<span class="co">#&gt; # ... with 41 more rows, and 5 more variables: others &lt;dbl&gt;, sigma &lt;dbl&gt;,</span>
<span class="co">#&gt; #   B &lt;dbl&gt;, posterior_mean &lt;dbl&gt;, posterior_se &lt;dbl&gt;</span></code></pre></div>
<p>The estimates based on posterior does move the estimates towards 0, although the states with many polls are influenced less. This is expected as the more poll data we collect, the more we trust those results:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">sigma =</span> sd<span class="op">/</span><span class="kw">sqrt</span>(n), 
                   <span class="dt">B =</span> sigma<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>),
                   <span class="dt">posterior_mean =</span> B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>avg,
                   <span class="dt">posterior_se =</span> <span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(avg, posterior_mean, <span class="dt">size =</span> n)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">intercept =</span> <span class="dv">0</span>)</code></pre></div>
<p><img src="book_files/figure-html/posterior-versus-original-estimates-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Now we repeat this 10,000 times and generate an outcome from the posterior. In each iteration, we keep the total number of electoral votes for Clinton. Note that we add 7 to account for Rhode Island and D.C.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="dv">0</span>
tau &lt;-<span class="st"> </span><span class="fl">0.02</span>
clinton_EV &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">1000</span>, {
  results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">sigma =</span> sd<span class="op">/</span><span class="kw">sqrt</span>(n), 
                   <span class="dt">B =</span> sigma<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>),
                   <span class="dt">posterior_mean =</span> B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>avg,
                   <span class="dt">posterior_se =</span> <span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>)),
                   <span class="dt">simulated_result =</span> <span class="kw">rnorm</span>(<span class="kw">length</span>(posterior_mean), posterior_mean, posterior_se),
                   <span class="dt">clinton =</span> <span class="kw">ifelse</span>(simulated_result<span class="op">&gt;</span><span class="dv">0</span>, electoral_votes, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">clinton =</span> <span class="kw">sum</span>(clinton)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>.<span class="op">$</span>clinton <span class="op">+</span><span class="st"> </span><span class="dv">7</span>## 7 for Rhode Island and D.C.
})
<span class="kw">mean</span>(clinton_EV<span class="op">&gt;</span><span class="dv">269</span>)
<span class="co">#&gt; [1] 0.998</span></code></pre></div>
<p>This model gives Clinton over 99% chance of winning. Here is a histogram of the possible outcomes:</p>
<p><img src="book_files/figure-html/election-forecast-posterior-no-bias-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>A similar prediction was made by the Princeton Election Consortium. We now know it was quite off. What happened?</p>
<p>The model above ignores the general bias. The general bias in 2016 was not that big compared to other years: it was between 1 and 2%. But because the election was close in several big states, a large number of polls made the estimates of standard errors small, and by ignoring the variability introduced by the general bias, pollsters were over confident on the poll data. FiveThirtyEight, which models the general bias in a rather sophisticated way, reported a closer result. We can simulate the results now with a bias term. For the state level, the general bias can be larger so we set it at <span class="math inline">\(\sigma_b = 0.03\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tau &lt;-<span class="st"> </span><span class="fl">0.02</span>
bias_sd &lt;-<span class="st"> </span><span class="fl">0.03</span>
clinton_EV_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">1000</span>, {
  results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">sigma =</span> <span class="kw">sqrt</span>(sd<span class="op">^</span><span class="dv">2</span><span class="op">/</span>n  <span class="op">+</span><span class="st"> </span>bias_sd<span class="op">^</span><span class="dv">2</span>),  
                   <span class="dt">B =</span> sigma<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>),
                   <span class="dt">posterior_mean =</span> B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>avg,
                   <span class="dt">posterior_se =</span> <span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>)),
                   <span class="dt">simulated_result =</span> <span class="kw">rnorm</span>(<span class="kw">length</span>(posterior_mean), posterior_mean, posterior_se),
                   <span class="dt">clinton =</span> <span class="kw">ifelse</span>(simulated_result<span class="op">&gt;</span><span class="dv">0</span>, electoral_votes, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">clinton =</span> <span class="kw">sum</span>(clinton) <span class="op">+</span><span class="st"> </span><span class="dv">7</span>) <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>clinton ## 7 for Rhode Island and D.C.
})
<span class="kw">mean</span>(clinton_EV_<span class="dv">2</span><span class="op">&gt;</span><span class="dv">269</span>)
<span class="co">#&gt; [1] 0.837</span></code></pre></div>
<p>This gives us a much more sensible result. Looking at the outcomes of the simulation, we see how the bias term adds variability to the final results.</p>
<p><img src="book_files/figure-html/comparison-forecast-with-and-without-bias-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>FiveThirtyEight includes many other features we do not include here. One is that they model variability with distributions that have high probabilities for extreme events compared to the normal. They predicted a probability of 71%.</p>
</div>
<div id="forecasting" class="section level2">
<h2><span class="header-section-number">37.5</span> Forecasting</h2>
<p>Forecasters like to make predictions well before the election. The predictions are adapted as new polls come out. However, an important question forecasters must ask is: how informative are polls taken several weeks before the election? Here we study the variability of poll results across time.</p>
<p>To make sure the variability we observe is not due to pollster effects, let’s study data from one pollster:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">one_pollster &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(pollster <span class="op">==</span><span class="st"> &quot;Ipsos&quot;</span> <span class="op">&amp;</span><span class="st"> </span>state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</code></pre></div>
<p>Since there is no pollster effect, then perhaps the theoretical standard error matches the data-derived standard deviation. We compute both here:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">se &lt;-<span class="st"> </span>one_pollster <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">empirical =</span> <span class="kw">sd</span>(spread), 
            <span class="dt">theoretical =</span> <span class="dv">2</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="kw">mean</span>(spread)<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">mean</span>(spread))<span class="op">/</span><span class="kw">min</span>(samplesize)))
se
<span class="co">#&gt;   empirical theoretical</span>
<span class="co">#&gt; 1    0.0403      0.0326</span></code></pre></div>
<p>The empirical standard deviation is higher than the highest possible theoretical estimate. Furthermore, the spread data does not look normal as the theory would predict:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">one_pollster <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(spread)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.01</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>)</code></pre></div>
<p><img src="book_files/figure-html/time-trend-variability-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Where is the extra variability coming from? The following plots make a strong case that the extra variability comes from time annunciations not accounted for by the theory that assumes <span class="math inline">\(p\)</span> is fixed:</p>
<p><img src="book_files/figure-html/time-trend-estimate-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Some of the peaks and valleys we see coincide with events such as the party conventions, which tend to give the candidate a boost. We can see them consistently across several pollsters:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate<span class="op">&gt;=</span><span class="st">&quot;2016-07-01&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">n</span>()<span class="op">&gt;=</span><span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(enddate, spread)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">span =</span> <span class="fl">0.1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>pollster), <span class="dt">show.legend =</span> <span class="ot">FALSE</span>, <span class="dt">alpha=</span><span class="fl">0.6</span>) </code></pre></div>
<p><img src="book_files/figure-html/time-trend-estimate-several-pollsters-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>This implies that, if we are going to forecast, our model must include a term to model that accounts for the time effect. We need to write a model including a bias term for time:</p>
<p><span class="math display">\[
Y_{ijt} = d + b + h_j + b_t + \varepsilon_{ijt}
\]</span></p>
<p>The standard deviation of <span class="math inline">\(b_t\)</span> would depend on <span class="math inline">\(t\)</span> since the closer we get to election day, the smaller this bias term should be.</p>
<p>Pollsters also try to estimate trends, call them <span class="math inline">\(f(t)\)</span>, from these data and incorporate these into their predictions. The blue lines in the plots above:</p>
<p><span class="math display">\[
Y_{ijt} = d + b + h_j + b_t + f(t) + \varepsilon_{ijt}
\]</span></p>
<p>We usually see the estimated <span class="math inline">\(f(t)\)</span> not for the difference, but for the actual percentages for each candidate:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate<span class="op">&gt;=</span><span class="st">&quot;2016-07-01&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(enddate, pollster, rawpoll_clinton, rawpoll_trump) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">Clinton =</span> rawpoll_clinton, <span class="dt">Trump =</span> rawpoll_trump) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(candidate, percentage, <span class="op">-</span>enddate, <span class="op">-</span>pollster) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">candidate =</span> <span class="kw">factor</span>(candidate, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Trump&quot;</span>,<span class="st">&quot;Clinton&quot;</span>)))<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">n</span>()<span class="op">&gt;=</span><span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(enddate, percentage, <span class="dt">color =</span> candidate)) <span class="op">+</span><span class="st">  </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">show.legend =</span> <span class="ot">FALSE</span>, <span class="dt">alpha=</span><span class="fl">0.4</span>)  <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">span =</span> <span class="fl">0.15</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">30</span>,<span class="dv">50</span>))
<span class="co">#&gt; Warning: Removed 22 rows containing non-finite values (stat_smooth).</span>
<span class="co">#&gt; Warning: Removed 22 rows containing missing values (geom_point).</span></code></pre></div>
<p><img src="book_files/figure-html/trend-estimate-for-all-pollsters-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Once a model like the one above is selected, we can use historical and present data to estimate all the necessary parameters to make predictions. There are a variety of methods for fitting models which we don’t discuss here. In a later chapter, we discuss some of these methods.</p>
</div>
<div id="exercise-3" class="section level2 unnumbered">
<h2>Exercise</h2>
<ol style="list-style-type: decimal">
<li>Create this table:</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(dslabs)
<span class="kw">data</span>(<span class="st">&quot;polls_us_election_2016&quot;</span>)
polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(state <span class="op">!=</span><span class="st"> &quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-31&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</code></pre></div>
<pre><code>Now for each poll use the CLT to create a 95% confidence interval for the spread reported by each poll. Call the resulting object cis with columns lower and upper for the limits of the confidence intervals. Use the `select` function to keep the columns `state, startdate, end date, pollster, grade, spread, lower, upper`.</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>You can add the final result to the <code>cis</code> table you just created using the <code>right_join</code> function like this:</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">add &lt;-<span class="st"> </span>results_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">actual_spread =</span> clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(state, actual_spread)
cis &lt;-<span class="st"> </span>cis <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">state =</span> <span class="kw">as.character</span>(state)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">left_join</span>(add, <span class="dt">by =</span> <span class="st">&quot;state&quot;</span>)</code></pre></div>
<pre><code>Now determine how often the 95% confidence interval includes the actual result.</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>Now repeat this, but show the proportion of hits for each pollster. Show only pollsters with more than 5 polls and order them from best to worst. Show the number of polls conducted by each pollster and the FiveThirtyEight grade of each pollster. Hint: use <code>n=n(), grade = grade[1]</code> in the call to summarize.</p></li>
<li><p>Repeat exercise 3, but instead of pollster, stratify by state. Here we can’t show grades.</p></li>
<li><p>Make a barplot based on the result of exercise 4. Use <code>coord_flip</code>.</p></li>
<li><p>For forecasters, it is important to call the correct winner. Hence, even if your confidence interval is incorrect, if you correctly called the right winner, your overall predictions will do better. Add two columns to the <code>cis</code> table by computing, for each poll, the difference between the predicted spread and the actual spread, and define a column <code>hit</code> that is true if the signs are the same. Hint: use the function <code>sign</code>. Call the object <code>resids</code></p></li>
<li><p>Create a plot like in exercise 5, but for the proportion of times the sign of the spread agreed.</p></li>
<li><p>In exercise 7, we see that for most states the polls had it right 100% of the time. For only 9 states did the polls miss more than 25% of the time. In particular, notice that in Wisconsin every single poll got it wrong. In Pennsylvania and Michigan more than 90% of the polls had the signs wrong. Make a histogram of the errors. What is the median of these errors?</p></li>
<li><p>We see that at the state level, the median error was 3% in favor of Clinton. The distribution is not centered at 0, but at 0.03. This is the general bias we described in the section above. Create a boxplot to see if the bias was general to all states or it affected some states differently. Use <code>filter(grade %in% c(&quot;A+&quot;,&quot;A&quot;,&quot;A-&quot;,&quot;B+&quot;) | is.na(grade)))</code> to only include pollsters with high grades.</p></li>
<li><p>Some of these states only have a few polls. Repeat exercise 9, but only include states with 5 good polls or more. Hint: use <code>group_by</code>, <code>filter</code> then <code>ungroup</code>.You will see that the West (Washington, New Mexico, California) underestimated Hillary’s performance, while the Midwest (Michigan, Pennsylvania, Wisconsin, Ohio, Missouri) overestimated it. In our simulation, we did not model this behavior since we added general bias, rather than a regional bias. Some pollsters are now modeling correlation between similar states and estimating this correlation from historical data. To learn more about this, you can learn about random effects and mixed models.</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bayesian-statistics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="association-tests.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rafalab/dsbook/edit/master/inference/election-forecasting.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
