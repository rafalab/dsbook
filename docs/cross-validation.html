<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 30 Cross validation | Introduction to Data Science</title>
  <meta name="description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  <meta name="generator" content="bookdown 0.25 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 30 Cross validation | Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 30 Cross validation | Introduction to Data Science" />
  
  <meta name="twitter:description" content="This book introduces concepts and skills that can help you tackle real-world data analysis challenges. It covers concepts from probability, statistical inference, linear regression and machine learning and helps you develop skills such as R programming, data wrangling with dplyr, data visualization with ggplot2, file organization with UNIX/Linux shell, version control with GitHub, and reproducible document preparation with R markdown." />
  

<meta name="author" content="Rafael A. Irizarry" />


<meta name="date" content="2022-04-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="smoothing.html"/>
<link rel="next" href="caret.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li><a href="index.html#preface">Preface<span></span></a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments<span></span></a></li>
<li><a href="introduction.html#introduction">Introduction<span></span></a>
<ul>
<li><a href="introduction.html#case-studies">Case studies<span></span></a></li>
<li><a href="introduction.html#who-will-find-this-book-useful">Who will find this book useful?<span></span></a></li>
<li><a href="introduction.html#what-does-this-book-cover">What does this book cover?<span></span></a></li>
<li><a href="introduction.html#what-is-not-covered-by-this-book">What is not covered by this book?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>1</b> Getting started with R and RStudio<span></span></a>
<ul>
<li class="chapter" data-level="1.1" data-path="getting-started.html"><a href="getting-started.html#why-r"><i class="fa fa-check"></i><b>1.1</b> Why R?<span></span></a></li>
<li class="chapter" data-level="1.2" data-path="getting-started.html"><a href="getting-started.html#the-r-console"><i class="fa fa-check"></i><b>1.2</b> The R console<span></span></a></li>
<li class="chapter" data-level="1.3" data-path="getting-started.html"><a href="getting-started.html#scripts"><i class="fa fa-check"></i><b>1.3</b> Scripts<span></span></a></li>
<li class="chapter" data-level="1.4" data-path="getting-started.html"><a href="getting-started.html#rstudio"><i class="fa fa-check"></i><b>1.4</b> RStudio<span></span></a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="getting-started.html"><a href="getting-started.html#the-panes"><i class="fa fa-check"></i><b>1.4.1</b> The panes<span></span></a></li>
<li class="chapter" data-level="1.4.2" data-path="getting-started.html"><a href="getting-started.html#key-bindings"><i class="fa fa-check"></i><b>1.4.2</b> Key bindings<span></span></a></li>
<li class="chapter" data-level="1.4.3" data-path="getting-started.html"><a href="getting-started.html#running-commands-while-editing-scripts"><i class="fa fa-check"></i><b>1.4.3</b> Running commands while editing scripts<span></span></a></li>
<li class="chapter" data-level="1.4.4" data-path="getting-started.html"><a href="getting-started.html#changing-global-options"><i class="fa fa-check"></i><b>1.4.4</b> Changing global options<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="getting-started.html"><a href="getting-started.html#installing-r-packages"><i class="fa fa-check"></i><b>1.5</b> Installing R packages<span></span></a></li>
</ul></li>
<li class="part"><span><b>I R<span></span></b></span></li>
<li class="chapter" data-level="2" data-path="r-basics.html"><a href="r-basics.html"><i class="fa fa-check"></i><b>2</b> R basics<span></span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="r-basics.html"><a href="r-basics.html#case-study-us-gun-murders"><i class="fa fa-check"></i><b>2.1</b> Case study: US Gun Murders<span></span></a></li>
<li class="chapter" data-level="2.2" data-path="r-basics.html"><a href="r-basics.html#the-very-basics"><i class="fa fa-check"></i><b>2.2</b> The very basics<span></span></a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="r-basics.html"><a href="r-basics.html#objects"><i class="fa fa-check"></i><b>2.2.1</b> Objects<span></span></a></li>
<li class="chapter" data-level="2.2.2" data-path="r-basics.html"><a href="r-basics.html#the-workspace"><i class="fa fa-check"></i><b>2.2.2</b> The workspace<span></span></a></li>
<li class="chapter" data-level="2.2.3" data-path="r-basics.html"><a href="r-basics.html#functions"><i class="fa fa-check"></i><b>2.2.3</b> Functions<span></span></a></li>
<li class="chapter" data-level="2.2.4" data-path="r-basics.html"><a href="r-basics.html#other-prebuilt-objects"><i class="fa fa-check"></i><b>2.2.4</b> Other prebuilt objects<span></span></a></li>
<li class="chapter" data-level="2.2.5" data-path="r-basics.html"><a href="r-basics.html#variable-names"><i class="fa fa-check"></i><b>2.2.5</b> Variable names<span></span></a></li>
<li class="chapter" data-level="2.2.6" data-path="r-basics.html"><a href="r-basics.html#saving-your-workspace"><i class="fa fa-check"></i><b>2.2.6</b> Saving your workspace<span></span></a></li>
<li class="chapter" data-level="2.2.7" data-path="r-basics.html"><a href="r-basics.html#motivating-scripts"><i class="fa fa-check"></i><b>2.2.7</b> Motivating scripts<span></span></a></li>
<li class="chapter" data-level="2.2.8" data-path="r-basics.html"><a href="r-basics.html#commenting-your-code"><i class="fa fa-check"></i><b>2.2.8</b> Commenting your code<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="r-basics.html"><a href="r-basics.html#exercises"><i class="fa fa-check"></i><b>2.3</b> Exercises<span></span></a></li>
<li class="chapter" data-level="2.4" data-path="r-basics.html"><a href="r-basics.html#data-types"><i class="fa fa-check"></i><b>2.4</b> Data types<span></span></a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="r-basics.html"><a href="r-basics.html#data-frames"><i class="fa fa-check"></i><b>2.4.1</b> Data frames<span></span></a></li>
<li class="chapter" data-level="2.4.2" data-path="r-basics.html"><a href="r-basics.html#examining-an-object"><i class="fa fa-check"></i><b>2.4.2</b> Examining an object<span></span></a></li>
<li class="chapter" data-level="2.4.3" data-path="r-basics.html"><a href="r-basics.html#the-accessor"><i class="fa fa-check"></i><b>2.4.3</b> The accessor: <code>$</code><span></span></a></li>
<li class="chapter" data-level="2.4.4" data-path="r-basics.html"><a href="r-basics.html#vectors-numerics-characters-and-logical"><i class="fa fa-check"></i><b>2.4.4</b> Vectors: numerics, characters, and logical<span></span></a></li>
<li class="chapter" data-level="2.4.5" data-path="r-basics.html"><a href="r-basics.html#factors"><i class="fa fa-check"></i><b>2.4.5</b> Factors<span></span></a></li>
<li class="chapter" data-level="2.4.6" data-path="r-basics.html"><a href="r-basics.html#lists"><i class="fa fa-check"></i><b>2.4.6</b> Lists<span></span></a></li>
<li class="chapter" data-level="2.4.7" data-path="r-basics.html"><a href="r-basics.html#matrices"><i class="fa fa-check"></i><b>2.4.7</b> Matrices<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="r-basics.html"><a href="r-basics.html#exercises-1"><i class="fa fa-check"></i><b>2.5</b> Exercises<span></span></a></li>
<li class="chapter" data-level="2.6" data-path="r-basics.html"><a href="r-basics.html#vectors"><i class="fa fa-check"></i><b>2.6</b> Vectors<span></span></a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="r-basics.html"><a href="r-basics.html#creating-vectors"><i class="fa fa-check"></i><b>2.6.1</b> Creating vectors<span></span></a></li>
<li class="chapter" data-level="2.6.2" data-path="r-basics.html"><a href="r-basics.html#names"><i class="fa fa-check"></i><b>2.6.2</b> Names<span></span></a></li>
<li class="chapter" data-level="2.6.3" data-path="r-basics.html"><a href="r-basics.html#sequences"><i class="fa fa-check"></i><b>2.6.3</b> Sequences<span></span></a></li>
<li class="chapter" data-level="2.6.4" data-path="r-basics.html"><a href="r-basics.html#subsetting"><i class="fa fa-check"></i><b>2.6.4</b> Subsetting<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="r-basics.html"><a href="r-basics.html#coercion"><i class="fa fa-check"></i><b>2.7</b> Coercion<span></span></a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="r-basics.html"><a href="r-basics.html#not-availables-na"><i class="fa fa-check"></i><b>2.7.1</b> Not availables (NA)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="r-basics.html"><a href="r-basics.html#exercises-2"><i class="fa fa-check"></i><b>2.8</b> Exercises<span></span></a></li>
<li class="chapter" data-level="2.9" data-path="r-basics.html"><a href="r-basics.html#sorting"><i class="fa fa-check"></i><b>2.9</b> Sorting<span></span></a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="r-basics.html"><a href="r-basics.html#sort"><i class="fa fa-check"></i><b>2.9.1</b> <code>sort</code><span></span></a></li>
<li class="chapter" data-level="2.9.2" data-path="r-basics.html"><a href="r-basics.html#order"><i class="fa fa-check"></i><b>2.9.2</b> <code>order</code><span></span></a></li>
<li class="chapter" data-level="2.9.3" data-path="r-basics.html"><a href="r-basics.html#max-and-which.max"><i class="fa fa-check"></i><b>2.9.3</b> <code>max</code> and <code>which.max</code><span></span></a></li>
<li class="chapter" data-level="2.9.4" data-path="r-basics.html"><a href="r-basics.html#rank"><i class="fa fa-check"></i><b>2.9.4</b> <code>rank</code><span></span></a></li>
<li class="chapter" data-level="2.9.5" data-path="r-basics.html"><a href="r-basics.html#beware-of-recycling"><i class="fa fa-check"></i><b>2.9.5</b> Beware of recycling<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="r-basics.html"><a href="r-basics.html#exercises-3"><i class="fa fa-check"></i><b>2.10</b> Exercises<span></span></a></li>
<li class="chapter" data-level="2.11" data-path="r-basics.html"><a href="r-basics.html#vector-arithmetics"><i class="fa fa-check"></i><b>2.11</b> Vector arithmetics<span></span></a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="r-basics.html"><a href="r-basics.html#rescaling-a-vector"><i class="fa fa-check"></i><b>2.11.1</b> Rescaling a vector<span></span></a></li>
<li class="chapter" data-level="2.11.2" data-path="r-basics.html"><a href="r-basics.html#two-vectors"><i class="fa fa-check"></i><b>2.11.2</b> Two vectors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="r-basics.html"><a href="r-basics.html#exercises-4"><i class="fa fa-check"></i><b>2.12</b> Exercises<span></span></a></li>
<li class="chapter" data-level="2.13" data-path="r-basics.html"><a href="r-basics.html#indexing"><i class="fa fa-check"></i><b>2.13</b> Indexing<span></span></a>
<ul>
<li class="chapter" data-level="2.13.1" data-path="r-basics.html"><a href="r-basics.html#subsetting-with-logicals"><i class="fa fa-check"></i><b>2.13.1</b> Subsetting with logicals<span></span></a></li>
<li class="chapter" data-level="2.13.2" data-path="r-basics.html"><a href="r-basics.html#logical-operators"><i class="fa fa-check"></i><b>2.13.2</b> Logical operators<span></span></a></li>
<li class="chapter" data-level="2.13.3" data-path="r-basics.html"><a href="r-basics.html#which"><i class="fa fa-check"></i><b>2.13.3</b> <code>which</code><span></span></a></li>
<li class="chapter" data-level="2.13.4" data-path="r-basics.html"><a href="r-basics.html#match"><i class="fa fa-check"></i><b>2.13.4</b> <code>match</code><span></span></a></li>
<li class="chapter" data-level="2.13.5" data-path="r-basics.html"><a href="r-basics.html#in"><i class="fa fa-check"></i><b>2.13.5</b> <code>%in%</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="r-basics.html"><a href="r-basics.html#exercises-5"><i class="fa fa-check"></i><b>2.14</b> Exercises<span></span></a></li>
<li class="chapter" data-level="2.15" data-path="r-basics.html"><a href="r-basics.html#basic-plots"><i class="fa fa-check"></i><b>2.15</b> Basic plots<span></span></a>
<ul>
<li class="chapter" data-level="2.15.1" data-path="r-basics.html"><a href="r-basics.html#plot"><i class="fa fa-check"></i><b>2.15.1</b> <code>plot</code><span></span></a></li>
<li class="chapter" data-level="2.15.2" data-path="r-basics.html"><a href="r-basics.html#hist"><i class="fa fa-check"></i><b>2.15.2</b> <code>hist</code><span></span></a></li>
<li class="chapter" data-level="2.15.3" data-path="r-basics.html"><a href="r-basics.html#boxplot"><i class="fa fa-check"></i><b>2.15.3</b> <code>boxplot</code><span></span></a></li>
<li class="chapter" data-level="2.15.4" data-path="r-basics.html"><a href="r-basics.html#image"><i class="fa fa-check"></i><b>2.15.4</b> <code>image</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.16" data-path="r-basics.html"><a href="r-basics.html#exercises-6"><i class="fa fa-check"></i><b>2.16</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="programming-basics.html"><a href="programming-basics.html"><i class="fa fa-check"></i><b>3</b> Programming basics<span></span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="programming-basics.html"><a href="programming-basics.html#conditionals"><i class="fa fa-check"></i><b>3.1</b> Conditional expressions<span></span></a></li>
<li class="chapter" data-level="3.2" data-path="programming-basics.html"><a href="programming-basics.html#defining-functions"><i class="fa fa-check"></i><b>3.2</b> Defining functions<span></span></a></li>
<li class="chapter" data-level="3.3" data-path="programming-basics.html"><a href="programming-basics.html#namespaces"><i class="fa fa-check"></i><b>3.3</b> Namespaces<span></span></a></li>
<li class="chapter" data-level="3.4" data-path="programming-basics.html"><a href="programming-basics.html#for-loops"><i class="fa fa-check"></i><b>3.4</b> For-loops<span></span></a></li>
<li class="chapter" data-level="3.5" data-path="programming-basics.html"><a href="programming-basics.html#vectorization"><i class="fa fa-check"></i><b>3.5</b> Vectorization and functionals<span></span></a></li>
<li class="chapter" data-level="3.6" data-path="programming-basics.html"><a href="programming-basics.html#exercises-7"><i class="fa fa-check"></i><b>3.6</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i><b>4</b> The tidyverse<span></span></a>
<ul>
<li class="chapter" data-level="4.1" data-path="tidyverse.html"><a href="tidyverse.html#tidy-data"><i class="fa fa-check"></i><b>4.1</b> Tidy data<span></span></a></li>
<li class="chapter" data-level="4.2" data-path="tidyverse.html"><a href="tidyverse.html#exercises-8"><i class="fa fa-check"></i><b>4.2</b> Exercises<span></span></a></li>
<li class="chapter" data-level="4.3" data-path="tidyverse.html"><a href="tidyverse.html#manipulating-data-frames"><i class="fa fa-check"></i><b>4.3</b> Manipulating data frames<span></span></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="tidyverse.html"><a href="tidyverse.html#adding-a-column-with-mutate"><i class="fa fa-check"></i><b>4.3.1</b> Adding a column with <code>mutate</code><span></span></a></li>
<li class="chapter" data-level="4.3.2" data-path="tidyverse.html"><a href="tidyverse.html#subsetting-with-filter"><i class="fa fa-check"></i><b>4.3.2</b> Subsetting with <code>filter</code><span></span></a></li>
<li class="chapter" data-level="4.3.3" data-path="tidyverse.html"><a href="tidyverse.html#selecting-columns-with-select"><i class="fa fa-check"></i><b>4.3.3</b> Selecting columns with <code>select</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tidyverse.html"><a href="tidyverse.html#exercises-9"><i class="fa fa-check"></i><b>4.4</b> Exercises<span></span></a></li>
<li class="chapter" data-level="4.5" data-path="tidyverse.html"><a href="tidyverse.html#the-pipe-or"><i class="fa fa-check"></i><b>4.5</b> The pipe: <code>%&gt;%</code> or <code>|&gt;</code><span></span></a></li>
<li class="chapter" data-level="4.6" data-path="tidyverse.html"><a href="tidyverse.html#exercises-10"><i class="fa fa-check"></i><b>4.6</b> Exercises<span></span></a></li>
<li class="chapter" data-level="4.7" data-path="tidyverse.html"><a href="tidyverse.html#summarizing-data"><i class="fa fa-check"></i><b>4.7</b> Summarizing data<span></span></a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="tidyverse.html"><a href="tidyverse.html#summarize"><i class="fa fa-check"></i><b>4.7.1</b> <code>summarize</code><span></span></a></li>
<li class="chapter" data-level="4.7.2" data-path="tidyverse.html"><a href="tidyverse.html#multiple-summaries"><i class="fa fa-check"></i><b>4.7.2</b> Multiple summaries<span></span></a></li>
<li class="chapter" data-level="4.7.3" data-path="tidyverse.html"><a href="tidyverse.html#group-by"><i class="fa fa-check"></i><b>4.7.3</b> Group then summarize with <code>group_by</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="tidyverse.html"><a href="tidyverse.html#pull"><i class="fa fa-check"></i><b>4.8</b> <code>pull</code><span></span></a></li>
<li class="chapter" data-level="4.9" data-path="tidyverse.html"><a href="tidyverse.html#sorting-data-frames"><i class="fa fa-check"></i><b>4.9</b> Sorting data frames<span></span></a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="tidyverse.html"><a href="tidyverse.html#nested-sorting"><i class="fa fa-check"></i><b>4.9.1</b> Nested sorting<span></span></a></li>
<li class="chapter" data-level="4.9.2" data-path="tidyverse.html"><a href="tidyverse.html#the-top-n"><i class="fa fa-check"></i><b>4.9.2</b> The top <span class="math inline">\(n\)</span><span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="tidyverse.html"><a href="tidyverse.html#exercises-11"><i class="fa fa-check"></i><b>4.10</b> Exercises<span></span></a></li>
<li class="chapter" data-level="4.11" data-path="tidyverse.html"><a href="tidyverse.html#tibbles"><i class="fa fa-check"></i><b>4.11</b> Tibbles<span></span></a>
<ul>
<li class="chapter" data-level="4.11.1" data-path="tidyverse.html"><a href="tidyverse.html#tibbles-display-better"><i class="fa fa-check"></i><b>4.11.1</b> Tibbles display better<span></span></a></li>
<li class="chapter" data-level="4.11.2" data-path="tidyverse.html"><a href="tidyverse.html#subsets-of-tibbles-are-tibbles"><i class="fa fa-check"></i><b>4.11.2</b> Subsets of tibbles are tibbles<span></span></a></li>
<li class="chapter" data-level="4.11.3" data-path="tidyverse.html"><a href="tidyverse.html#tibbles-can-have-complex-entries"><i class="fa fa-check"></i><b>4.11.3</b> Tibbles can have complex entries<span></span></a></li>
<li class="chapter" data-level="4.11.4" data-path="tidyverse.html"><a href="tidyverse.html#tibbles-can-be-grouped"><i class="fa fa-check"></i><b>4.11.4</b> Tibbles can be grouped<span></span></a></li>
<li class="chapter" data-level="4.11.5" data-path="tidyverse.html"><a href="tidyverse.html#create-a-tibble-using-tibble-instead-of-data.frame"><i class="fa fa-check"></i><b>4.11.5</b> Create a tibble using <code>tibble</code> instead of <code>data.frame</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.12" data-path="tidyverse.html"><a href="tidyverse.html#the-dot-operator"><i class="fa fa-check"></i><b>4.12</b> The dot operator<span></span></a></li>
<li class="chapter" data-level="4.13" data-path="tidyverse.html"><a href="tidyverse.html#the-purrr-package"><i class="fa fa-check"></i><b>4.13</b> The <strong>purrr</strong> package<span></span></a></li>
<li class="chapter" data-level="4.14" data-path="tidyverse.html"><a href="tidyverse.html#tidyverse-conditionals"><i class="fa fa-check"></i><b>4.14</b> Tidyverse conditionals<span></span></a>
<ul>
<li class="chapter" data-level="4.14.1" data-path="tidyverse.html"><a href="tidyverse.html#case_when"><i class="fa fa-check"></i><b>4.14.1</b> <code>case_when</code><span></span></a></li>
<li class="chapter" data-level="4.14.2" data-path="tidyverse.html"><a href="tidyverse.html#between"><i class="fa fa-check"></i><b>4.14.2</b> <code>between</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="tidyverse.html"><a href="tidyverse.html#exercises-12"><i class="fa fa-check"></i><b>4.15</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="importing-data.html"><a href="importing-data.html"><i class="fa fa-check"></i><b>5</b> Importing data<span></span></a>
<ul>
<li class="chapter" data-level="5.1" data-path="importing-data.html"><a href="importing-data.html#paths-and-the-working-directory"><i class="fa fa-check"></i><b>5.1</b> Paths and the working directory<span></span></a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="importing-data.html"><a href="importing-data.html#the-filesystem"><i class="fa fa-check"></i><b>5.1.1</b> The filesystem<span></span></a></li>
<li class="chapter" data-level="5.1.2" data-path="importing-data.html"><a href="importing-data.html#relative-and-full-paths"><i class="fa fa-check"></i><b>5.1.2</b> Relative and full paths<span></span></a></li>
<li class="chapter" data-level="5.1.3" data-path="importing-data.html"><a href="importing-data.html#the-working-directory"><i class="fa fa-check"></i><b>5.1.3</b> The working directory<span></span></a></li>
<li class="chapter" data-level="5.1.4" data-path="importing-data.html"><a href="importing-data.html#generating-path-names"><i class="fa fa-check"></i><b>5.1.4</b> Generating path names<span></span></a></li>
<li class="chapter" data-level="5.1.5" data-path="importing-data.html"><a href="importing-data.html#copying-files-using-paths"><i class="fa fa-check"></i><b>5.1.5</b> Copying files using paths<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="importing-data.html"><a href="importing-data.html#the-readr-and-readxl-packages"><i class="fa fa-check"></i><b>5.2</b> The readr and readxl packages<span></span></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="importing-data.html"><a href="importing-data.html#readr"><i class="fa fa-check"></i><b>5.2.1</b> readr<span></span></a></li>
<li class="chapter" data-level="5.2.2" data-path="importing-data.html"><a href="importing-data.html#readxl"><i class="fa fa-check"></i><b>5.2.2</b> readxl<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="importing-data.html"><a href="importing-data.html#exercises-13"><i class="fa fa-check"></i><b>5.3</b> Exercises<span></span></a></li>
<li class="chapter" data-level="5.4" data-path="importing-data.html"><a href="importing-data.html#downloading-files"><i class="fa fa-check"></i><b>5.4</b> Downloading files<span></span></a></li>
<li class="chapter" data-level="5.5" data-path="importing-data.html"><a href="importing-data.html#r-base-importing-functions"><i class="fa fa-check"></i><b>5.5</b> R-base importing functions<span></span></a></li>
<li class="chapter" data-level="5.6" data-path="importing-data.html"><a href="importing-data.html#text-versus-binary-files"><i class="fa fa-check"></i><b>5.6</b> Text versus binary files<span></span></a></li>
<li class="chapter" data-level="5.7" data-path="importing-data.html"><a href="importing-data.html#unicode-versus-ascii"><i class="fa fa-check"></i><b>5.7</b> Unicode versus ASCII<span></span></a></li>
<li class="chapter" data-level="5.8" data-path="importing-data.html"><a href="importing-data.html#organizing-data-with-spreadsheets"><i class="fa fa-check"></i><b>5.8</b> Organizing data with spreadsheets<span></span></a></li>
<li class="chapter" data-level="5.9" data-path="importing-data.html"><a href="importing-data.html#exercises-14"><i class="fa fa-check"></i><b>5.9</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>6</b> data.table<span></span></a>
<ul>
<li class="chapter" data-level="6.1" data-path="data.html"><a href="data.html#manipulating-data-tables"><i class="fa fa-check"></i><b>6.1</b> Manipulating data tables<span></span></a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="data.html"><a href="data.html#selecting"><i class="fa fa-check"></i><b>6.1.1</b> Selecting<span></span></a></li>
<li class="chapter" data-level="6.1.2" data-path="data.html"><a href="data.html#adding-a-column-or-changing-columns"><i class="fa fa-check"></i><b>6.1.2</b> Adding a column or changing columns<span></span></a></li>
<li class="chapter" data-level="6.1.3" data-path="data.html"><a href="data.html#technical-detail-reference-versus-copy"><i class="fa fa-check"></i><b>6.1.3</b> Technical detail: reference versus copy<span></span></a></li>
<li class="chapter" data-level="6.1.4" data-path="data.html"><a href="data.html#subsetting-1"><i class="fa fa-check"></i><b>6.1.4</b> Subsetting<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="data.html"><a href="data.html#exercises-15"><i class="fa fa-check"></i><b>6.2</b> Exercises<span></span></a></li>
<li class="chapter" data-level="6.3" data-path="data.html"><a href="data.html#summarizing-data-1"><i class="fa fa-check"></i><b>6.3</b> Summarizing data<span></span></a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="data.html"><a href="data.html#multiple-summaries-1"><i class="fa fa-check"></i><b>6.3.1</b> Multiple summaries<span></span></a></li>
<li class="chapter" data-level="6.3.2" data-path="data.html"><a href="data.html#group-then-summarize"><i class="fa fa-check"></i><b>6.3.2</b> Group then summarize<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="data.html"><a href="data.html#sorting-data-frames-1"><i class="fa fa-check"></i><b>6.4</b> Sorting data frames<span></span></a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="data.html"><a href="data.html#nested-sorting-1"><i class="fa fa-check"></i><b>6.4.1</b> Nested sorting<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="data.html"><a href="data.html#exercises-16"><i class="fa fa-check"></i><b>6.5</b> Exercises<span></span></a></li>
</ul></li>
<li class="part"><span><b>II Data Visualization<span></span></b></span></li>
<li class="chapter" data-level="7" data-path="introduction-to-data-visualization.html"><a href="introduction-to-data-visualization.html"><i class="fa fa-check"></i><b>7</b> Introduction to data visualization<span></span></a></li>
<li class="chapter" data-level="8" data-path="ggplot2.html"><a href="ggplot2.html"><i class="fa fa-check"></i><b>8</b> ggplot2<span></span></a>
<ul>
<li class="chapter" data-level="8.1" data-path="ggplot2.html"><a href="ggplot2.html#the-components-of-a-graph"><i class="fa fa-check"></i><b>8.1</b> The components of a graph<span></span></a></li>
<li class="chapter" data-level="8.2" data-path="ggplot2.html"><a href="ggplot2.html#ggplot-objects"><i class="fa fa-check"></i><b>8.2</b> <code>ggplot</code> objects<span></span></a></li>
<li class="chapter" data-level="8.3" data-path="ggplot2.html"><a href="ggplot2.html#geometries"><i class="fa fa-check"></i><b>8.3</b> Geometries<span></span></a></li>
<li class="chapter" data-level="8.4" data-path="ggplot2.html"><a href="ggplot2.html#aesthetic-mappings"><i class="fa fa-check"></i><b>8.4</b> Aesthetic mappings<span></span></a></li>
<li class="chapter" data-level="8.5" data-path="ggplot2.html"><a href="ggplot2.html#layers"><i class="fa fa-check"></i><b>8.5</b> Layers<span></span></a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="ggplot2.html"><a href="ggplot2.html#tinkering-with-arguments"><i class="fa fa-check"></i><b>8.5.1</b> Tinkering with arguments<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="ggplot2.html"><a href="ggplot2.html#global-versus-local-aesthetic-mappings"><i class="fa fa-check"></i><b>8.6</b> Global versus local aesthetic mappings<span></span></a></li>
<li class="chapter" data-level="8.7" data-path="ggplot2.html"><a href="ggplot2.html#scales"><i class="fa fa-check"></i><b>8.7</b> Scales<span></span></a></li>
<li class="chapter" data-level="8.8" data-path="ggplot2.html"><a href="ggplot2.html#labels-and-titles"><i class="fa fa-check"></i><b>8.8</b> Labels and titles<span></span></a></li>
<li class="chapter" data-level="8.9" data-path="ggplot2.html"><a href="ggplot2.html#categories-as-colors"><i class="fa fa-check"></i><b>8.9</b> Categories as colors<span></span></a></li>
<li class="chapter" data-level="8.10" data-path="ggplot2.html"><a href="ggplot2.html#annotation-shapes-and-adjustments"><i class="fa fa-check"></i><b>8.10</b> Annotation, shapes, and adjustments<span></span></a></li>
<li class="chapter" data-level="8.11" data-path="ggplot2.html"><a href="ggplot2.html#add-on-packages"><i class="fa fa-check"></i><b>8.11</b> Add-on packages<span></span></a></li>
<li class="chapter" data-level="8.12" data-path="ggplot2.html"><a href="ggplot2.html#putting-it-all-together"><i class="fa fa-check"></i><b>8.12</b> Putting it all together<span></span></a></li>
<li class="chapter" data-level="8.13" data-path="ggplot2.html"><a href="ggplot2.html#qplot"><i class="fa fa-check"></i><b>8.13</b> Quick plots with <code>qplot</code><span></span></a></li>
<li class="chapter" data-level="8.14" data-path="ggplot2.html"><a href="ggplot2.html#grids-of-plots"><i class="fa fa-check"></i><b>8.14</b> Grids of plots<span></span></a></li>
<li class="chapter" data-level="8.15" data-path="ggplot2.html"><a href="ggplot2.html#exercises-17"><i class="fa fa-check"></i><b>8.15</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>9</b> Visualizing data distributions<span></span></a>
<ul>
<li class="chapter" data-level="9.1" data-path="distributions.html"><a href="distributions.html#variable-types"><i class="fa fa-check"></i><b>9.1</b> Variable types<span></span></a></li>
<li class="chapter" data-level="9.2" data-path="distributions.html"><a href="distributions.html#case-study-describing-student-heights"><i class="fa fa-check"></i><b>9.2</b> Case study: describing student heights<span></span></a></li>
<li class="chapter" data-level="9.3" data-path="distributions.html"><a href="distributions.html#distribution-function"><i class="fa fa-check"></i><b>9.3</b> Distribution function<span></span></a></li>
<li class="chapter" data-level="9.4" data-path="distributions.html"><a href="distributions.html#cdf-intro"><i class="fa fa-check"></i><b>9.4</b> Cumulative distribution functions<span></span></a></li>
<li class="chapter" data-level="9.5" data-path="distributions.html"><a href="distributions.html#histograms"><i class="fa fa-check"></i><b>9.5</b> Histograms<span></span></a></li>
<li class="chapter" data-level="9.6" data-path="distributions.html"><a href="distributions.html#smoothed-density"><i class="fa fa-check"></i><b>9.6</b> Smoothed density<span></span></a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="distributions.html"><a href="distributions.html#interpreting-the-y-axis"><i class="fa fa-check"></i><b>9.6.1</b> Interpreting the y-axis<span></span></a></li>
<li class="chapter" data-level="9.6.2" data-path="distributions.html"><a href="distributions.html#densities-permit-stratification"><i class="fa fa-check"></i><b>9.6.2</b> Densities permit stratification<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="distributions.html"><a href="distributions.html#exercises-18"><i class="fa fa-check"></i><b>9.7</b> Exercises<span></span></a></li>
<li class="chapter" data-level="9.8" data-path="distributions.html"><a href="distributions.html#normal-distribution"><i class="fa fa-check"></i><b>9.8</b> The normal distribution<span></span></a></li>
<li class="chapter" data-level="9.9" data-path="distributions.html"><a href="distributions.html#standard-units"><i class="fa fa-check"></i><b>9.9</b> Standard units<span></span></a></li>
<li class="chapter" data-level="9.10" data-path="distributions.html"><a href="distributions.html#quantile-quantile-plots"><i class="fa fa-check"></i><b>9.10</b> Quantile-quantile plots<span></span></a></li>
<li class="chapter" data-level="9.11" data-path="distributions.html"><a href="distributions.html#percentiles"><i class="fa fa-check"></i><b>9.11</b> Percentiles<span></span></a></li>
<li class="chapter" data-level="9.12" data-path="distributions.html"><a href="distributions.html#boxplots"><i class="fa fa-check"></i><b>9.12</b> Boxplots<span></span></a></li>
<li class="chapter" data-level="9.13" data-path="distributions.html"><a href="distributions.html#stratification"><i class="fa fa-check"></i><b>9.13</b> Stratification<span></span></a></li>
<li class="chapter" data-level="9.14" data-path="distributions.html"><a href="distributions.html#student-height-cont"><i class="fa fa-check"></i><b>9.14</b> Case study: describing student heights (continued)<span></span></a></li>
<li class="chapter" data-level="9.15" data-path="distributions.html"><a href="distributions.html#exercises-19"><i class="fa fa-check"></i><b>9.15</b> Exercises<span></span></a></li>
<li class="chapter" data-level="9.16" data-path="distributions.html"><a href="distributions.html#other-geometries"><i class="fa fa-check"></i><b>9.16</b> ggplot2 geometries<span></span></a>
<ul>
<li class="chapter" data-level="9.16.1" data-path="distributions.html"><a href="distributions.html#barplots"><i class="fa fa-check"></i><b>9.16.1</b> Barplots<span></span></a></li>
<li class="chapter" data-level="9.16.2" data-path="distributions.html"><a href="distributions.html#histograms-1"><i class="fa fa-check"></i><b>9.16.2</b> Histograms<span></span></a></li>
<li class="chapter" data-level="9.16.3" data-path="distributions.html"><a href="distributions.html#density-plots"><i class="fa fa-check"></i><b>9.16.3</b> Density plots<span></span></a></li>
<li class="chapter" data-level="9.16.4" data-path="distributions.html"><a href="distributions.html#boxplots-1"><i class="fa fa-check"></i><b>9.16.4</b> Boxplots<span></span></a></li>
<li class="chapter" data-level="9.16.5" data-path="distributions.html"><a href="distributions.html#qq-plots"><i class="fa fa-check"></i><b>9.16.5</b> QQ-plots<span></span></a></li>
<li class="chapter" data-level="9.16.6" data-path="distributions.html"><a href="distributions.html#images"><i class="fa fa-check"></i><b>9.16.6</b> Images<span></span></a></li>
<li class="chapter" data-level="9.16.7" data-path="distributions.html"><a href="distributions.html#quick-plots"><i class="fa fa-check"></i><b>9.16.7</b> Quick plots<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.17" data-path="distributions.html"><a href="distributions.html#exercises-20"><i class="fa fa-check"></i><b>9.17</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="gapminder.html"><a href="gapminder.html"><i class="fa fa-check"></i><b>10</b> Data visualization in practice<span></span></a>
<ul>
<li class="chapter" data-level="10.1" data-path="gapminder.html"><a href="gapminder.html#case-study-new-insights-on-poverty"><i class="fa fa-check"></i><b>10.1</b> Case study: new insights on poverty<span></span></a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="gapminder.html"><a href="gapminder.html#hans-roslings-quiz"><i class="fa fa-check"></i><b>10.1.1</b> Hans Roslingâ€™s quiz<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="gapminder.html"><a href="gapminder.html#scatterplots"><i class="fa fa-check"></i><b>10.2</b> Scatterplots<span></span></a></li>
<li class="chapter" data-level="10.3" data-path="gapminder.html"><a href="gapminder.html#faceting"><i class="fa fa-check"></i><b>10.3</b> Faceting<span></span></a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="gapminder.html"><a href="gapminder.html#facet_wrap"><i class="fa fa-check"></i><b>10.3.1</b> <code>facet_wrap</code><span></span></a></li>
<li class="chapter" data-level="10.3.2" data-path="gapminder.html"><a href="gapminder.html#fixed-scales-for-better-comparisons"><i class="fa fa-check"></i><b>10.3.2</b> Fixed scales for better comparisons<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="gapminder.html"><a href="gapminder.html#time-series-plots"><i class="fa fa-check"></i><b>10.4</b> Time series plots<span></span></a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="gapminder.html"><a href="gapminder.html#labels-instead-of-legends"><i class="fa fa-check"></i><b>10.4.1</b> Labels instead of legends<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="gapminder.html"><a href="gapminder.html#data-transformations"><i class="fa fa-check"></i><b>10.5</b> Data transformations<span></span></a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="gapminder.html"><a href="gapminder.html#log-transformation"><i class="fa fa-check"></i><b>10.5.1</b> Log transformation<span></span></a></li>
<li class="chapter" data-level="10.5.2" data-path="gapminder.html"><a href="gapminder.html#which-base"><i class="fa fa-check"></i><b>10.5.2</b> Which base?<span></span></a></li>
<li class="chapter" data-level="10.5.3" data-path="gapminder.html"><a href="gapminder.html#transform-the-values-or-the-scale"><i class="fa fa-check"></i><b>10.5.3</b> Transform the values or the scale?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="gapminder.html"><a href="gapminder.html#visualizing-multimodal-distributions"><i class="fa fa-check"></i><b>10.6</b> Visualizing multimodal distributions<span></span></a></li>
<li class="chapter" data-level="10.7" data-path="gapminder.html"><a href="gapminder.html#comparing-multiple-distributions-with-boxplots-and-ridge-plots"><i class="fa fa-check"></i><b>10.7</b> Comparing multiple distributions with boxplots and ridge plots<span></span></a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="gapminder.html"><a href="gapminder.html#boxplots-2"><i class="fa fa-check"></i><b>10.7.1</b> Boxplots<span></span></a></li>
<li class="chapter" data-level="10.7.2" data-path="gapminder.html"><a href="gapminder.html#ridge-plots"><i class="fa fa-check"></i><b>10.7.2</b> Ridge plots<span></span></a></li>
<li class="chapter" data-level="10.7.3" data-path="gapminder.html"><a href="gapminder.html#example-1970-versus-2010-income-distributions"><i class="fa fa-check"></i><b>10.7.3</b> Example: 1970 versus 2010 income distributions<span></span></a></li>
<li class="chapter" data-level="10.7.4" data-path="gapminder.html"><a href="gapminder.html#accessing-computed-variables"><i class="fa fa-check"></i><b>10.7.4</b> Accessing computed variables<span></span></a></li>
<li class="chapter" data-level="10.7.5" data-path="gapminder.html"><a href="gapminder.html#weighted-densities"><i class="fa fa-check"></i><b>10.7.5</b> Weighted densities<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="gapminder.html"><a href="gapminder.html#the-ecological-fallacy-and-importance-of-showing-the-data"><i class="fa fa-check"></i><b>10.8</b> The ecological fallacy and importance of showing the data<span></span></a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="gapminder.html"><a href="gapminder.html#logit"><i class="fa fa-check"></i><b>10.8.1</b> Logistic transformation<span></span></a></li>
<li class="chapter" data-level="10.8.2" data-path="gapminder.html"><a href="gapminder.html#show-the-data"><i class="fa fa-check"></i><b>10.8.2</b> Show the data<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html"><i class="fa fa-check"></i><b>11</b> Data visualization principles<span></span></a>
<ul>
<li class="chapter" data-level="11.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#encoding-data-using-visual-cues"><i class="fa fa-check"></i><b>11.1</b> Encoding data using visual cues<span></span></a></li>
<li class="chapter" data-level="11.2" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#know-when-to-include-0"><i class="fa fa-check"></i><b>11.2</b> Know when to include 0<span></span></a></li>
<li class="chapter" data-level="11.3" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#do-not-distort-quantities"><i class="fa fa-check"></i><b>11.3</b> Do not distort quantities<span></span></a></li>
<li class="chapter" data-level="11.4" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#order-categories-by-a-meaningful-value"><i class="fa fa-check"></i><b>11.4</b> Order categories by a meaningful value<span></span></a></li>
<li class="chapter" data-level="11.5" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#show-the-data-1"><i class="fa fa-check"></i><b>11.5</b> Show the data<span></span></a></li>
<li class="chapter" data-level="11.6" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#ease-comparisons"><i class="fa fa-check"></i><b>11.6</b> Ease comparisons<span></span></a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#use-common-axes"><i class="fa fa-check"></i><b>11.6.1</b> Use common axes<span></span></a></li>
<li class="chapter" data-level="11.6.2" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#align-plots-vertically-to-see-horizontal-changes-and-horizontally-to-see-vertical-changes"><i class="fa fa-check"></i><b>11.6.2</b> Align plots vertically to see horizontal changes and horizontally to see vertical changes<span></span></a></li>
<li class="chapter" data-level="11.6.3" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#consider-transformations"><i class="fa fa-check"></i><b>11.6.3</b> Consider transformations<span></span></a></li>
<li class="chapter" data-level="11.6.4" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#visual-cues-to-be-compared-should-be-adjacent"><i class="fa fa-check"></i><b>11.6.4</b> Visual cues to be compared should be adjacent<span></span></a></li>
<li class="chapter" data-level="11.6.5" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#use-color"><i class="fa fa-check"></i><b>11.6.5</b> Use color<span></span></a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#think-of-the-color-blind"><i class="fa fa-check"></i><b>11.7</b> Think of the color blind<span></span></a></li>
<li class="chapter" data-level="11.8" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#plots-for-two-variables"><i class="fa fa-check"></i><b>11.8</b> Plots for two variables<span></span></a>
<ul>
<li class="chapter" data-level="11.8.1" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#slope-charts"><i class="fa fa-check"></i><b>11.8.1</b> Slope charts<span></span></a></li>
<li class="chapter" data-level="11.8.2" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#bland-altman-plot"><i class="fa fa-check"></i><b>11.8.2</b> Bland-Altman plot<span></span></a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#encoding-a-third-variable"><i class="fa fa-check"></i><b>11.9</b> Encoding a third variable<span></span></a></li>
<li class="chapter" data-level="11.10" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#avoid-pseudo-three-dimensional-plots"><i class="fa fa-check"></i><b>11.10</b> Avoid pseudo-three-dimensional plots<span></span></a></li>
<li class="chapter" data-level="11.11" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#avoid-too-many-significant-digits"><i class="fa fa-check"></i><b>11.11</b> Avoid too many significant digits<span></span></a></li>
<li class="chapter" data-level="11.12" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#know-your-audience"><i class="fa fa-check"></i><b>11.12</b> Know your audience<span></span></a></li>
<li class="chapter" data-level="11.13" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#exercises-21"><i class="fa fa-check"></i><b>11.13</b> Exercises<span></span></a></li>
<li class="chapter" data-level="11.14" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#vaccines"><i class="fa fa-check"></i><b>11.14</b> Case study: vaccines and infectious diseases<span></span></a></li>
<li class="chapter" data-level="11.15" data-path="data-visualization-principles.html"><a href="data-visualization-principles.html#exercises-22"><i class="fa fa-check"></i><b>11.15</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="robust-summaries.html"><a href="robust-summaries.html"><i class="fa fa-check"></i><b>12</b> Robust summaries<span></span></a>
<ul>
<li class="chapter" data-level="12.1" data-path="robust-summaries.html"><a href="robust-summaries.html#outliers"><i class="fa fa-check"></i><b>12.1</b> Outliers<span></span></a></li>
<li class="chapter" data-level="12.2" data-path="robust-summaries.html"><a href="robust-summaries.html#median"><i class="fa fa-check"></i><b>12.2</b> Median<span></span></a></li>
<li class="chapter" data-level="12.3" data-path="robust-summaries.html"><a href="robust-summaries.html#the-inter-quartile-range-iqr"><i class="fa fa-check"></i><b>12.3</b> The inter quartile range (IQR)<span></span></a></li>
<li class="chapter" data-level="12.4" data-path="robust-summaries.html"><a href="robust-summaries.html#tukeys-definition-of-an-outlier"><i class="fa fa-check"></i><b>12.4</b> Tukeyâ€™s definition of an outlier<span></span></a></li>
<li class="chapter" data-level="12.5" data-path="robust-summaries.html"><a href="robust-summaries.html#median-absolute-deviation"><i class="fa fa-check"></i><b>12.5</b> Median absolute deviation<span></span></a></li>
<li class="chapter" data-level="12.6" data-path="robust-summaries.html"><a href="robust-summaries.html#exercises-23"><i class="fa fa-check"></i><b>12.6</b> Exercises<span></span></a></li>
<li class="chapter" data-level="12.7" data-path="robust-summaries.html"><a href="robust-summaries.html#case-study-self-reported-student-heights"><i class="fa fa-check"></i><b>12.7</b> Case study: self-reported student heights<span></span></a></li>
</ul></li>
<li class="part"><span><b>III Statistics with R<span></span></b></span></li>
<li class="chapter" data-level="13" data-path="introduction-to-statistics-with-r.html"><a href="introduction-to-statistics-with-r.html"><i class="fa fa-check"></i><b>13</b> Introduction to statistics with R<span></span></a></li>
<li class="chapter" data-level="14" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>14</b> Probability<span></span></a>
<ul>
<li class="chapter" data-level="14.1" data-path="probability.html"><a href="probability.html#discrete-probability"><i class="fa fa-check"></i><b>14.1</b> Discrete probability<span></span></a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="probability.html"><a href="probability.html#relative-frequency"><i class="fa fa-check"></i><b>14.1.1</b> Relative frequency<span></span></a></li>
<li class="chapter" data-level="14.1.2" data-path="probability.html"><a href="probability.html#notation"><i class="fa fa-check"></i><b>14.1.2</b> Notation<span></span></a></li>
<li class="chapter" data-level="14.1.3" data-path="probability.html"><a href="probability.html#probability-distributions"><i class="fa fa-check"></i><b>14.1.3</b> Probability distributions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="probability.html"><a href="probability.html#monte-carlo-simulations-for-categorical-data"><i class="fa fa-check"></i><b>14.2</b> Monte Carlo simulations for categorical data<span></span></a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="probability.html"><a href="probability.html#setting-the-random-seed"><i class="fa fa-check"></i><b>14.2.1</b> Setting the random seed<span></span></a></li>
<li class="chapter" data-level="14.2.2" data-path="probability.html"><a href="probability.html#with-and-without-replacement"><i class="fa fa-check"></i><b>14.2.2</b> With and without replacement<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>14.3</b> Independence<span></span></a></li>
<li class="chapter" data-level="14.4" data-path="probability.html"><a href="probability.html#conditional-probabilities"><i class="fa fa-check"></i><b>14.4</b> Conditional probabilities<span></span></a></li>
<li class="chapter" data-level="14.5" data-path="probability.html"><a href="probability.html#addition-and-multiplication-rules"><i class="fa fa-check"></i><b>14.5</b> Addition and multiplication rules<span></span></a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="probability.html"><a href="probability.html#multiplication-rule"><i class="fa fa-check"></i><b>14.5.1</b> Multiplication rule<span></span></a></li>
<li class="chapter" data-level="14.5.2" data-path="probability.html"><a href="probability.html#multiplication-rule-under-independence"><i class="fa fa-check"></i><b>14.5.2</b> Multiplication rule under independence<span></span></a></li>
<li class="chapter" data-level="14.5.3" data-path="probability.html"><a href="probability.html#addition-rule"><i class="fa fa-check"></i><b>14.5.3</b> Addition rule<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="probability.html"><a href="probability.html#combinations-and-permutations"><i class="fa fa-check"></i><b>14.6</b> Combinations and permutations<span></span></a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="probability.html"><a href="probability.html#monte-carlo-example"><i class="fa fa-check"></i><b>14.6.1</b> Monte Carlo example<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="probability.html"><a href="probability.html#examples"><i class="fa fa-check"></i><b>14.7</b> Examples<span></span></a>
<ul>
<li class="chapter" data-level="14.7.1" data-path="probability.html"><a href="probability.html#monty-hall-problem"><i class="fa fa-check"></i><b>14.7.1</b> Monty Hall problem<span></span></a></li>
<li class="chapter" data-level="14.7.2" data-path="probability.html"><a href="probability.html#birthday-problem"><i class="fa fa-check"></i><b>14.7.2</b> Birthday problem<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="probability.html"><a href="probability.html#infinity-in-practice"><i class="fa fa-check"></i><b>14.8</b> Infinity in practice<span></span></a></li>
<li class="chapter" data-level="14.9" data-path="probability.html"><a href="probability.html#exercises-24"><i class="fa fa-check"></i><b>14.9</b> Exercises<span></span></a></li>
<li class="chapter" data-level="14.10" data-path="probability.html"><a href="probability.html#continuous-probability"><i class="fa fa-check"></i><b>14.10</b> Continuous probability<span></span></a></li>
<li class="chapter" data-level="14.11" data-path="probability.html"><a href="probability.html#theoretical-continuous-distributions"><i class="fa fa-check"></i><b>14.11</b> Theoretical continuous distributions<span></span></a>
<ul>
<li class="chapter" data-level="14.11.1" data-path="probability.html"><a href="probability.html#theoretical-distributions-as-approximations"><i class="fa fa-check"></i><b>14.11.1</b> Theoretical distributions as approximations<span></span></a></li>
<li class="chapter" data-level="14.11.2" data-path="probability.html"><a href="probability.html#the-probability-density"><i class="fa fa-check"></i><b>14.11.2</b> The probability density<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14.12" data-path="probability.html"><a href="probability.html#monte-carlo-simulations-for-continuous-variables"><i class="fa fa-check"></i><b>14.12</b> Monte Carlo simulations for continuous variables<span></span></a></li>
<li class="chapter" data-level="14.13" data-path="probability.html"><a href="probability.html#continuous-distributions"><i class="fa fa-check"></i><b>14.13</b> Continuous distributions<span></span></a></li>
<li class="chapter" data-level="14.14" data-path="probability.html"><a href="probability.html#exercises-25"><i class="fa fa-check"></i><b>14.14</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>15</b> Random variables<span></span></a>
<ul>
<li class="chapter" data-level="15.1" data-path="random-variables.html"><a href="random-variables.html#random-variables-1"><i class="fa fa-check"></i><b>15.1</b> Random variables<span></span></a></li>
<li class="chapter" data-level="15.2" data-path="random-variables.html"><a href="random-variables.html#sampling-models"><i class="fa fa-check"></i><b>15.2</b> Sampling models<span></span></a></li>
<li class="chapter" data-level="15.3" data-path="random-variables.html"><a href="random-variables.html#the-probability-distribution-of-a-random-variable"><i class="fa fa-check"></i><b>15.3</b> The probability distribution of a random variable<span></span></a></li>
<li class="chapter" data-level="15.4" data-path="random-variables.html"><a href="random-variables.html#distributions-versus-probability-distributions"><i class="fa fa-check"></i><b>15.4</b> Distributions versus probability distributions<span></span></a></li>
<li class="chapter" data-level="15.5" data-path="random-variables.html"><a href="random-variables.html#notation-for-random-variables"><i class="fa fa-check"></i><b>15.5</b> Notation for random variables<span></span></a></li>
<li class="chapter" data-level="15.6" data-path="random-variables.html"><a href="random-variables.html#the-expected-value-and-standard-error"><i class="fa fa-check"></i><b>15.6</b> The expected value and standard error<span></span></a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="random-variables.html"><a href="random-variables.html#population-sd-versus-the-sample-sd"><i class="fa fa-check"></i><b>15.6.1</b> Population SD versus the sample SD<span></span></a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="random-variables.html"><a href="random-variables.html#central-limit-theorem"><i class="fa fa-check"></i><b>15.7</b> Central Limit Theorem<span></span></a>
<ul>
<li class="chapter" data-level="15.7.1" data-path="random-variables.html"><a href="random-variables.html#how-large-is-large-in-the-central-limit-theorem"><i class="fa fa-check"></i><b>15.7.1</b> How large is large in the Central Limit Theorem?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="random-variables.html"><a href="random-variables.html#statistical-properties-of-averages"><i class="fa fa-check"></i><b>15.8</b> Statistical properties of averages<span></span></a></li>
<li class="chapter" data-level="15.9" data-path="random-variables.html"><a href="random-variables.html#law-of-large-numbers"><i class="fa fa-check"></i><b>15.9</b> Law of large numbers<span></span></a>
<ul>
<li class="chapter" data-level="15.9.1" data-path="random-variables.html"><a href="random-variables.html#misinterpreting-law-of-averages"><i class="fa fa-check"></i><b>15.9.1</b> Misinterpreting law of averages<span></span></a></li>
</ul></li>
<li class="chapter" data-level="15.10" data-path="random-variables.html"><a href="random-variables.html#exercises-26"><i class="fa fa-check"></i><b>15.10</b> Exercises<span></span></a></li>
<li class="chapter" data-level="15.11" data-path="random-variables.html"><a href="random-variables.html#case-study-the-big-short"><i class="fa fa-check"></i><b>15.11</b> Case study: The Big Short<span></span></a>
<ul>
<li class="chapter" data-level="15.11.1" data-path="random-variables.html"><a href="random-variables.html#interest-rates-explained-with-chance-model"><i class="fa fa-check"></i><b>15.11.1</b> Interest rates explained with chance model<span></span></a></li>
<li class="chapter" data-level="15.11.2" data-path="random-variables.html"><a href="random-variables.html#the-big-short"><i class="fa fa-check"></i><b>15.11.2</b> The Big Short<span></span></a></li>
</ul></li>
<li class="chapter" data-level="15.12" data-path="random-variables.html"><a href="random-variables.html#exercises-27"><i class="fa fa-check"></i><b>15.12</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>16</b> Statistical inference<span></span></a>
<ul>
<li class="chapter" data-level="16.1" data-path="inference.html"><a href="inference.html#polls"><i class="fa fa-check"></i><b>16.1</b> Polls<span></span></a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="inference.html"><a href="inference.html#the-sampling-model-for-polls"><i class="fa fa-check"></i><b>16.1.1</b> The sampling model for polls<span></span></a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="inference.html"><a href="inference.html#populations-samples-parameters-and-estimates"><i class="fa fa-check"></i><b>16.2</b> Populations, samples, parameters, and estimates<span></span></a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="inference.html"><a href="inference.html#the-sample-average"><i class="fa fa-check"></i><b>16.2.1</b> The sample average<span></span></a></li>
<li class="chapter" data-level="16.2.2" data-path="inference.html"><a href="inference.html#parameters"><i class="fa fa-check"></i><b>16.2.2</b> Parameters<span></span></a></li>
<li class="chapter" data-level="16.2.3" data-path="inference.html"><a href="inference.html#polling-versus-forecasting"><i class="fa fa-check"></i><b>16.2.3</b> Polling versus forecasting<span></span></a></li>
<li class="chapter" data-level="16.2.4" data-path="inference.html"><a href="inference.html#properties-of-our-estimate-expected-value-and-standard-error"><i class="fa fa-check"></i><b>16.2.4</b> Properties of our estimate: expected value and standard error<span></span></a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="inference.html"><a href="inference.html#exercises-28"><i class="fa fa-check"></i><b>16.3</b> Exercises<span></span></a></li>
<li class="chapter" data-level="16.4" data-path="inference.html"><a href="inference.html#clt"><i class="fa fa-check"></i><b>16.4</b> Central Limit Theorem in practice<span></span></a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="inference.html"><a href="inference.html#a-monte-carlo-simulation"><i class="fa fa-check"></i><b>16.4.1</b> A Monte Carlo simulation<span></span></a></li>
<li class="chapter" data-level="16.4.2" data-path="inference.html"><a href="inference.html#the-spread"><i class="fa fa-check"></i><b>16.4.2</b> The spread<span></span></a></li>
<li class="chapter" data-level="16.4.3" data-path="inference.html"><a href="inference.html#bias-why-not-run-a-very-large-poll"><i class="fa fa-check"></i><b>16.4.3</b> Bias: why not run a very large poll?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="inference.html"><a href="inference.html#exercises-29"><i class="fa fa-check"></i><b>16.5</b> Exercises<span></span></a></li>
<li class="chapter" data-level="16.6" data-path="inference.html"><a href="inference.html#confidence-intervals"><i class="fa fa-check"></i><b>16.6</b> Confidence intervals<span></span></a>
<ul>
<li class="chapter" data-level="16.6.1" data-path="inference.html"><a href="inference.html#a-monte-carlo-simulation-1"><i class="fa fa-check"></i><b>16.6.1</b> A Monte Carlo simulation<span></span></a></li>
<li class="chapter" data-level="16.6.2" data-path="inference.html"><a href="inference.html#the-correct-language"><i class="fa fa-check"></i><b>16.6.2</b> The correct language<span></span></a></li>
</ul></li>
<li class="chapter" data-level="16.7" data-path="inference.html"><a href="inference.html#exercises-30"><i class="fa fa-check"></i><b>16.7</b> Exercises<span></span></a></li>
<li class="chapter" data-level="16.8" data-path="inference.html"><a href="inference.html#power"><i class="fa fa-check"></i><b>16.8</b> Power<span></span></a></li>
<li class="chapter" data-level="16.9" data-path="inference.html"><a href="inference.html#p-values"><i class="fa fa-check"></i><b>16.9</b> p-values<span></span></a></li>
<li class="chapter" data-level="16.10" data-path="inference.html"><a href="inference.html#association-tests"><i class="fa fa-check"></i><b>16.10</b> Association tests<span></span></a>
<ul>
<li class="chapter" data-level="16.10.1" data-path="inference.html"><a href="inference.html#lady-tasting-tea"><i class="fa fa-check"></i><b>16.10.1</b> Lady Tasting Tea<span></span></a></li>
<li class="chapter" data-level="16.10.2" data-path="inference.html"><a href="inference.html#two-by-two-tables"><i class="fa fa-check"></i><b>16.10.2</b> Two-by-two tables<span></span></a></li>
<li class="chapter" data-level="16.10.3" data-path="inference.html"><a href="inference.html#chi-square-test"><i class="fa fa-check"></i><b>16.10.3</b> Chi-square Test<span></span></a></li>
<li class="chapter" data-level="16.10.4" data-path="inference.html"><a href="inference.html#odds-ratio"><i class="fa fa-check"></i><b>16.10.4</b> The odds ratio<span></span></a></li>
<li class="chapter" data-level="16.10.5" data-path="inference.html"><a href="inference.html#confidence-intervals-for-the-odds-ratio"><i class="fa fa-check"></i><b>16.10.5</b> Confidence intervals for the odds ratio<span></span></a></li>
<li class="chapter" data-level="16.10.6" data-path="inference.html"><a href="inference.html#small-count-correction"><i class="fa fa-check"></i><b>16.10.6</b> Small count correction<span></span></a></li>
<li class="chapter" data-level="16.10.7" data-path="inference.html"><a href="inference.html#large-samples-small-p-values"><i class="fa fa-check"></i><b>16.10.7</b> Large samples, small p-values<span></span></a></li>
</ul></li>
<li class="chapter" data-level="16.11" data-path="inference.html"><a href="inference.html#exercises-31"><i class="fa fa-check"></i><b>16.11</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>17</b> Statistical models<span></span></a>
<ul>
<li class="chapter" data-level="17.1" data-path="models.html"><a href="models.html#poll-aggregators"><i class="fa fa-check"></i><b>17.1</b> Poll aggregators<span></span></a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="models.html"><a href="models.html#poll-data"><i class="fa fa-check"></i><b>17.1.1</b> Poll data<span></span></a></li>
<li class="chapter" data-level="17.1.2" data-path="models.html"><a href="models.html#pollster-bias"><i class="fa fa-check"></i><b>17.1.2</b> Pollster bias<span></span></a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="models.html"><a href="models.html#data-driven-model"><i class="fa fa-check"></i><b>17.2</b> Data-driven models<span></span></a></li>
<li class="chapter" data-level="17.3" data-path="models.html"><a href="models.html#exercises-32"><i class="fa fa-check"></i><b>17.3</b> Exercises<span></span></a></li>
<li class="chapter" data-level="17.4" data-path="models.html"><a href="models.html#bayesian-statistics"><i class="fa fa-check"></i><b>17.4</b> Bayesian statistics<span></span></a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="models.html"><a href="models.html#bayes-theorem"><i class="fa fa-check"></i><b>17.4.1</b> Bayes theorem<span></span></a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="models.html"><a href="models.html#bayes-theorem-simulation"><i class="fa fa-check"></i><b>17.5</b> Bayes theorem simulation<span></span></a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="models.html"><a href="models.html#bayes-in-practice"><i class="fa fa-check"></i><b>17.5.1</b> Bayes in practice<span></span></a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="models.html"><a href="models.html#hierarchical-models"><i class="fa fa-check"></i><b>17.6</b> Hierarchical models<span></span></a></li>
<li class="chapter" data-level="17.7" data-path="models.html"><a href="models.html#exercises-33"><i class="fa fa-check"></i><b>17.7</b> Exercises<span></span></a></li>
<li class="chapter" data-level="17.8" data-path="models.html"><a href="models.html#election-forecasting"><i class="fa fa-check"></i><b>17.8</b> Case study: election forecasting<span></span></a>
<ul>
<li class="chapter" data-level="17.8.1" data-path="models.html"><a href="models.html#bayesian-approach"><i class="fa fa-check"></i><b>17.8.1</b> Bayesian approach<span></span></a></li>
<li class="chapter" data-level="17.8.2" data-path="models.html"><a href="models.html#the-general-bias"><i class="fa fa-check"></i><b>17.8.2</b> The general bias<span></span></a></li>
<li class="chapter" data-level="17.8.3" data-path="models.html"><a href="models.html#mathematical-representations-of-models"><i class="fa fa-check"></i><b>17.8.3</b> Mathematical representations of models<span></span></a></li>
<li class="chapter" data-level="17.8.4" data-path="models.html"><a href="models.html#predicting-the-electoral-college"><i class="fa fa-check"></i><b>17.8.4</b> Predicting the electoral college<span></span></a></li>
<li class="chapter" data-level="17.8.5" data-path="models.html"><a href="models.html#forecasting"><i class="fa fa-check"></i><b>17.8.5</b> Forecasting<span></span></a></li>
</ul></li>
<li class="chapter" data-level="17.9" data-path="models.html"><a href="models.html#exercises-34"><i class="fa fa-check"></i><b>17.9</b> Exercises<span></span></a></li>
<li class="chapter" data-level="17.10" data-path="models.html"><a href="models.html#t-dist"><i class="fa fa-check"></i><b>17.10</b> The t-distribution<span></span></a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>18</b> Regression<span></span></a>
<ul>
<li class="chapter" data-level="18.1" data-path="regression.html"><a href="regression.html#galton"><i class="fa fa-check"></i><b>18.1</b> Case study: is height hereditary?<span></span></a></li>
<li class="chapter" data-level="18.2" data-path="regression.html"><a href="regression.html#corr-coef"><i class="fa fa-check"></i><b>18.2</b> The correlation coefficient<span></span></a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="regression.html"><a href="regression.html#sample-correlation-is-a-random-variable"><i class="fa fa-check"></i><b>18.2.1</b> Sample correlation is a random variable<span></span></a></li>
<li class="chapter" data-level="18.2.2" data-path="regression.html"><a href="regression.html#correlation-is-not-always-a-useful-summary"><i class="fa fa-check"></i><b>18.2.2</b> Correlation is not always a useful summary<span></span></a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="regression.html"><a href="regression.html#conditional-expectation"><i class="fa fa-check"></i><b>18.3</b> Conditional expectations<span></span></a></li>
<li class="chapter" data-level="18.4" data-path="regression.html"><a href="regression.html#the-regression-line"><i class="fa fa-check"></i><b>18.4</b> The regression line<span></span></a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="regression.html"><a href="regression.html#regression-improves-precision"><i class="fa fa-check"></i><b>18.4.1</b> Regression improves precision<span></span></a></li>
<li class="chapter" data-level="18.4.2" data-path="regression.html"><a href="regression.html#bivariate-normal-distribution-advanced"><i class="fa fa-check"></i><b>18.4.2</b> Bivariate normal distribution (advanced)<span></span></a></li>
<li class="chapter" data-level="18.4.3" data-path="regression.html"><a href="regression.html#variance-explained"><i class="fa fa-check"></i><b>18.4.3</b> Variance explained<span></span></a></li>
<li class="chapter" data-level="18.4.4" data-path="regression.html"><a href="regression.html#warning-there-are-two-regression-lines"><i class="fa fa-check"></i><b>18.4.4</b> Warning: there are two regression lines<span></span></a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="regression.html"><a href="regression.html#exercises-35"><i class="fa fa-check"></i><b>18.5</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>19</b> Linear models<span></span></a>
<ul>
<li class="chapter" data-level="19.1" data-path="linear-models.html"><a href="linear-models.html#case-study-moneyball"><i class="fa fa-check"></i><b>19.1</b> Case study: Moneyball<span></span></a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="linear-models.html"><a href="linear-models.html#sabermetics"><i class="fa fa-check"></i><b>19.1.1</b> Sabermetics<span></span></a></li>
<li class="chapter" data-level="19.1.2" data-path="linear-models.html"><a href="linear-models.html#baseball-basics"><i class="fa fa-check"></i><b>19.1.2</b> Baseball basics<span></span></a></li>
<li class="chapter" data-level="19.1.3" data-path="linear-models.html"><a href="linear-models.html#no-awards-for-bb"><i class="fa fa-check"></i><b>19.1.3</b> No awards for BB<span></span></a></li>
<li class="chapter" data-level="19.1.4" data-path="linear-models.html"><a href="linear-models.html#base-on-balls-or-stolen-bases"><i class="fa fa-check"></i><b>19.1.4</b> Base on balls or stolen bases?<span></span></a></li>
<li class="chapter" data-level="19.1.5" data-path="linear-models.html"><a href="linear-models.html#regression-applied-to-baseball-statistics"><i class="fa fa-check"></i><b>19.1.5</b> Regression applied to baseball statistics<span></span></a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="linear-models.html"><a href="linear-models.html#confounding"><i class="fa fa-check"></i><b>19.2</b> Confounding<span></span></a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="linear-models.html"><a href="linear-models.html#understanding-confounding-through-stratification"><i class="fa fa-check"></i><b>19.2.1</b> Understanding confounding through stratification<span></span></a></li>
<li class="chapter" data-level="19.2.2" data-path="linear-models.html"><a href="linear-models.html#multivariable-regression"><i class="fa fa-check"></i><b>19.2.2</b> multivariable regression<span></span></a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="linear-models.html"><a href="linear-models.html#lse"><i class="fa fa-check"></i><b>19.3</b> Least squares estimates<span></span></a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="linear-models.html"><a href="linear-models.html#interpreting-linear-models"><i class="fa fa-check"></i><b>19.3.1</b> Interpreting linear models<span></span></a></li>
<li class="chapter" data-level="19.3.2" data-path="linear-models.html"><a href="linear-models.html#least-squares-estimates-lse"><i class="fa fa-check"></i><b>19.3.2</b> Least Squares Estimates (LSE)<span></span></a></li>
<li class="chapter" data-level="19.3.3" data-path="linear-models.html"><a href="linear-models.html#the-lm-function"><i class="fa fa-check"></i><b>19.3.3</b> The <code>lm</code> function<span></span></a></li>
<li class="chapter" data-level="19.3.4" data-path="linear-models.html"><a href="linear-models.html#lse-are-random-variables"><i class="fa fa-check"></i><b>19.3.4</b> LSE are random variables<span></span></a></li>
<li class="chapter" data-level="19.3.5" data-path="linear-models.html"><a href="linear-models.html#predicted-values-are-random-variables"><i class="fa fa-check"></i><b>19.3.5</b> Predicted values are random variables<span></span></a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="linear-models.html"><a href="linear-models.html#exercises-36"><i class="fa fa-check"></i><b>19.4</b> Exercises<span></span></a></li>
<li class="chapter" data-level="19.5" data-path="linear-models.html"><a href="linear-models.html#linear-regression-in-the-tidyverse"><i class="fa fa-check"></i><b>19.5</b> Linear regression in the tidyverse<span></span></a>
<ul>
<li class="chapter" data-level="19.5.1" data-path="linear-models.html"><a href="linear-models.html#the-broom-package"><i class="fa fa-check"></i><b>19.5.1</b> The broom package<span></span></a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="linear-models.html"><a href="linear-models.html#exercises-37"><i class="fa fa-check"></i><b>19.6</b> Exercises<span></span></a></li>
<li class="chapter" data-level="19.7" data-path="linear-models.html"><a href="linear-models.html#case-study-moneyball-continued"><i class="fa fa-check"></i><b>19.7</b> Case study: Moneyball (continued)<span></span></a>
<ul>
<li class="chapter" data-level="19.7.1" data-path="linear-models.html"><a href="linear-models.html#adding-salary-and-position-information"><i class="fa fa-check"></i><b>19.7.1</b> Adding salary and position information<span></span></a></li>
<li class="chapter" data-level="19.7.2" data-path="linear-models.html"><a href="linear-models.html#picking-nine-players"><i class="fa fa-check"></i><b>19.7.2</b> Picking nine players<span></span></a></li>
</ul></li>
<li class="chapter" data-level="19.8" data-path="linear-models.html"><a href="linear-models.html#the-regression-fallacy"><i class="fa fa-check"></i><b>19.8</b> The regression fallacy<span></span></a></li>
<li class="chapter" data-level="19.9" data-path="linear-models.html"><a href="linear-models.html#measurement-error-models"><i class="fa fa-check"></i><b>19.9</b> Measurement error models<span></span></a></li>
<li class="chapter" data-level="19.10" data-path="linear-models.html"><a href="linear-models.html#exercises-38"><i class="fa fa-check"></i><b>19.10</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html"><i class="fa fa-check"></i><b>20</b> Association is not causation<span></span></a>
<ul>
<li class="chapter" data-level="20.1" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#spurious-correlation"><i class="fa fa-check"></i><b>20.1</b> Spurious correlation<span></span></a></li>
<li class="chapter" data-level="20.2" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#outliers-1"><i class="fa fa-check"></i><b>20.2</b> Outliers<span></span></a></li>
<li class="chapter" data-level="20.3" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#reversing-cause-and-effect"><i class="fa fa-check"></i><b>20.3</b> Reversing cause and effect<span></span></a></li>
<li class="chapter" data-level="20.4" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#confounders"><i class="fa fa-check"></i><b>20.4</b> Confounders<span></span></a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#example-uc-berkeley-admissions"><i class="fa fa-check"></i><b>20.4.1</b> Example: UC Berkeley admissions<span></span></a></li>
<li class="chapter" data-level="20.4.2" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#confounding-explained-graphically"><i class="fa fa-check"></i><b>20.4.2</b> Confounding explained graphically<span></span></a></li>
<li class="chapter" data-level="20.4.3" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#average-after-stratifying"><i class="fa fa-check"></i><b>20.4.3</b> Average after stratifying<span></span></a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#simpsons-paradox"><i class="fa fa-check"></i><b>20.5</b> Simpsonâ€™s paradox<span></span></a></li>
<li class="chapter" data-level="20.6" data-path="association-is-not-causation.html"><a href="association-is-not-causation.html#exercises-39"><i class="fa fa-check"></i><b>20.6</b> Exercises<span></span></a></li>
</ul></li>
<li class="part"><span><b>IV Data Wrangling<span></span></b></span></li>
<li class="chapter" data-level="21" data-path="introduction-to-data-wrangling.html"><a href="introduction-to-data-wrangling.html"><i class="fa fa-check"></i><b>21</b> Introduction to data wrangling<span></span></a></li>
<li class="chapter" data-level="22" data-path="reshaping-data.html"><a href="reshaping-data.html"><i class="fa fa-check"></i><b>22</b> Reshaping data<span></span></a>
<ul>
<li class="chapter" data-level="22.1" data-path="reshaping-data.html"><a href="reshaping-data.html#pivot_longer"><i class="fa fa-check"></i><b>22.1</b> <code>pivot_longer</code><span></span></a></li>
<li class="chapter" data-level="22.2" data-path="reshaping-data.html"><a href="reshaping-data.html#pivot_wider"><i class="fa fa-check"></i><b>22.2</b> <code>pivot_wider</code><span></span></a></li>
<li class="chapter" data-level="22.3" data-path="reshaping-data.html"><a href="reshaping-data.html#separate"><i class="fa fa-check"></i><b>22.3</b> <code>separate</code><span></span></a></li>
<li class="chapter" data-level="22.4" data-path="reshaping-data.html"><a href="reshaping-data.html#unite"><i class="fa fa-check"></i><b>22.4</b> <code>unite</code><span></span></a></li>
<li class="chapter" data-level="22.5" data-path="reshaping-data.html"><a href="reshaping-data.html#exercises-40"><i class="fa fa-check"></i><b>22.5</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="joining-tables.html"><a href="joining-tables.html"><i class="fa fa-check"></i><b>23</b> Joining tables<span></span></a>
<ul>
<li class="chapter" data-level="23.1" data-path="joining-tables.html"><a href="joining-tables.html#joins"><i class="fa fa-check"></i><b>23.1</b> Joins<span></span></a>
<ul>
<li class="chapter" data-level="23.1.1" data-path="joining-tables.html"><a href="joining-tables.html#left-join"><i class="fa fa-check"></i><b>23.1.1</b> Left join<span></span></a></li>
<li class="chapter" data-level="23.1.2" data-path="joining-tables.html"><a href="joining-tables.html#right-join"><i class="fa fa-check"></i><b>23.1.2</b> Right join<span></span></a></li>
<li class="chapter" data-level="23.1.3" data-path="joining-tables.html"><a href="joining-tables.html#inner-join"><i class="fa fa-check"></i><b>23.1.3</b> Inner join<span></span></a></li>
<li class="chapter" data-level="23.1.4" data-path="joining-tables.html"><a href="joining-tables.html#full-join"><i class="fa fa-check"></i><b>23.1.4</b> Full join<span></span></a></li>
<li class="chapter" data-level="23.1.5" data-path="joining-tables.html"><a href="joining-tables.html#semi-join"><i class="fa fa-check"></i><b>23.1.5</b> Semi join<span></span></a></li>
<li class="chapter" data-level="23.1.6" data-path="joining-tables.html"><a href="joining-tables.html#anti-join"><i class="fa fa-check"></i><b>23.1.6</b> Anti join<span></span></a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="joining-tables.html"><a href="joining-tables.html#binding"><i class="fa fa-check"></i><b>23.2</b> Binding<span></span></a>
<ul>
<li class="chapter" data-level="23.2.1" data-path="joining-tables.html"><a href="joining-tables.html#binding-columns"><i class="fa fa-check"></i><b>23.2.1</b> Binding columns<span></span></a></li>
<li class="chapter" data-level="23.2.2" data-path="joining-tables.html"><a href="joining-tables.html#binding-by-rows"><i class="fa fa-check"></i><b>23.2.2</b> Binding by rows<span></span></a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="joining-tables.html"><a href="joining-tables.html#set-operators"><i class="fa fa-check"></i><b>23.3</b> Set operators<span></span></a>
<ul>
<li class="chapter" data-level="23.3.1" data-path="joining-tables.html"><a href="joining-tables.html#intersect"><i class="fa fa-check"></i><b>23.3.1</b> Intersect<span></span></a></li>
<li class="chapter" data-level="23.3.2" data-path="joining-tables.html"><a href="joining-tables.html#union"><i class="fa fa-check"></i><b>23.3.2</b> Union<span></span></a></li>
<li class="chapter" data-level="23.3.3" data-path="joining-tables.html"><a href="joining-tables.html#setdiff"><i class="fa fa-check"></i><b>23.3.3</b> <code>setdiff</code><span></span></a></li>
<li class="chapter" data-level="23.3.4" data-path="joining-tables.html"><a href="joining-tables.html#setequal"><i class="fa fa-check"></i><b>23.3.4</b> <code>setequal</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="joining-tables.html"><a href="joining-tables.html#exercises-41"><i class="fa fa-check"></i><b>23.4</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="web-scraping.html"><a href="web-scraping.html"><i class="fa fa-check"></i><b>24</b> Web scraping<span></span></a>
<ul>
<li class="chapter" data-level="24.1" data-path="web-scraping.html"><a href="web-scraping.html#html"><i class="fa fa-check"></i><b>24.1</b> HTML<span></span></a></li>
<li class="chapter" data-level="24.2" data-path="web-scraping.html"><a href="web-scraping.html#the-rvest-package"><i class="fa fa-check"></i><b>24.2</b> The rvest package<span></span></a></li>
<li class="chapter" data-level="24.3" data-path="web-scraping.html"><a href="web-scraping.html#css-selectors"><i class="fa fa-check"></i><b>24.3</b> CSS selectors<span></span></a></li>
<li class="chapter" data-level="24.4" data-path="web-scraping.html"><a href="web-scraping.html#json"><i class="fa fa-check"></i><b>24.4</b> JSON<span></span></a></li>
<li class="chapter" data-level="24.5" data-path="web-scraping.html"><a href="web-scraping.html#exercises-42"><i class="fa fa-check"></i><b>24.5</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="string-processing.html"><a href="string-processing.html"><i class="fa fa-check"></i><b>25</b> String processing<span></span></a>
<ul>
<li class="chapter" data-level="25.1" data-path="string-processing.html"><a href="string-processing.html#stringr"><i class="fa fa-check"></i><b>25.1</b> The stringr package<span></span></a></li>
<li class="chapter" data-level="25.2" data-path="string-processing.html"><a href="string-processing.html#case-study-1-us-murders-data"><i class="fa fa-check"></i><b>25.2</b> Case study 1: US murders data<span></span></a></li>
<li class="chapter" data-level="25.3" data-path="string-processing.html"><a href="string-processing.html#case-study-2-self-reported-heights"><i class="fa fa-check"></i><b>25.3</b> Case study 2: self-reported heights<span></span></a></li>
<li class="chapter" data-level="25.4" data-path="string-processing.html"><a href="string-processing.html#how-to-escape-when-defining-strings"><i class="fa fa-check"></i><b>25.4</b> How to <em>escape</em> when defining strings<span></span></a></li>
<li class="chapter" data-level="25.5" data-path="string-processing.html"><a href="string-processing.html#regular-expressions"><i class="fa fa-check"></i><b>25.5</b> Regular expressions<span></span></a>
<ul>
<li class="chapter" data-level="25.5.1" data-path="string-processing.html"><a href="string-processing.html#strings-are-a-regexp"><i class="fa fa-check"></i><b>25.5.1</b> Strings are a regexp<span></span></a></li>
<li class="chapter" data-level="25.5.2" data-path="string-processing.html"><a href="string-processing.html#special-characters"><i class="fa fa-check"></i><b>25.5.2</b> Special characters<span></span></a></li>
<li class="chapter" data-level="25.5.3" data-path="string-processing.html"><a href="string-processing.html#character-classes"><i class="fa fa-check"></i><b>25.5.3</b> Character classes<span></span></a></li>
<li class="chapter" data-level="25.5.4" data-path="string-processing.html"><a href="string-processing.html#anchors"><i class="fa fa-check"></i><b>25.5.4</b> Anchors<span></span></a></li>
<li class="chapter" data-level="25.5.5" data-path="string-processing.html"><a href="string-processing.html#quantifiers"><i class="fa fa-check"></i><b>25.5.5</b> Quantifiers<span></span></a></li>
<li class="chapter" data-level="25.5.6" data-path="string-processing.html"><a href="string-processing.html#white-space-s"><i class="fa fa-check"></i><b>25.5.6</b> White space <code>\s</code><span></span></a></li>
<li class="chapter" data-level="25.5.7" data-path="string-processing.html"><a href="string-processing.html#quantifiers-1"><i class="fa fa-check"></i><b>25.5.7</b> Quantifiers: <code>*</code>, <code>?</code>, <code>+</code><span></span></a></li>
<li class="chapter" data-level="25.5.8" data-path="string-processing.html"><a href="string-processing.html#not"><i class="fa fa-check"></i><b>25.5.8</b> Not<span></span></a></li>
<li class="chapter" data-level="25.5.9" data-path="string-processing.html"><a href="string-processing.html#groups"><i class="fa fa-check"></i><b>25.5.9</b> Groups<span></span></a></li>
</ul></li>
<li class="chapter" data-level="25.6" data-path="string-processing.html"><a href="string-processing.html#search-and-replace-with-regex"><i class="fa fa-check"></i><b>25.6</b> Search and replace with regex<span></span></a>
<ul>
<li class="chapter" data-level="25.6.1" data-path="string-processing.html"><a href="string-processing.html#search-and-replace-using-groups"><i class="fa fa-check"></i><b>25.6.1</b> Search and replace using groups<span></span></a></li>
</ul></li>
<li class="chapter" data-level="25.7" data-path="string-processing.html"><a href="string-processing.html#testing-and-improving"><i class="fa fa-check"></i><b>25.7</b> Testing and improving<span></span></a></li>
<li class="chapter" data-level="25.8" data-path="string-processing.html"><a href="string-processing.html#trimming"><i class="fa fa-check"></i><b>25.8</b> Trimming<span></span></a></li>
<li class="chapter" data-level="25.9" data-path="string-processing.html"><a href="string-processing.html#changing-lettercase"><i class="fa fa-check"></i><b>25.9</b> Changing lettercase<span></span></a></li>
<li class="chapter" data-level="25.10" data-path="string-processing.html"><a href="string-processing.html#case-study-2-self-reported-heights-continued"><i class="fa fa-check"></i><b>25.10</b> Case study 2: self-reported heights (continued)<span></span></a>
<ul>
<li class="chapter" data-level="25.10.1" data-path="string-processing.html"><a href="string-processing.html#the-extract-function"><i class="fa fa-check"></i><b>25.10.1</b> The <code>extract</code> function<span></span></a></li>
<li class="chapter" data-level="25.10.2" data-path="string-processing.html"><a href="string-processing.html#putting-it-all-together-1"><i class="fa fa-check"></i><b>25.10.2</b> Putting it all together<span></span></a></li>
</ul></li>
<li class="chapter" data-level="25.11" data-path="string-processing.html"><a href="string-processing.html#string-splitting"><i class="fa fa-check"></i><b>25.11</b> String splitting<span></span></a></li>
<li class="chapter" data-level="25.12" data-path="string-processing.html"><a href="string-processing.html#case-study-3-extracting-tables-from-a-pdf"><i class="fa fa-check"></i><b>25.12</b> Case study 3: extracting tables from a PDF<span></span></a></li>
<li class="chapter" data-level="25.13" data-path="string-processing.html"><a href="string-processing.html#recode"><i class="fa fa-check"></i><b>25.13</b> Recoding<span></span></a></li>
<li class="chapter" data-level="25.14" data-path="string-processing.html"><a href="string-processing.html#exercises-43"><i class="fa fa-check"></i><b>25.14</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html"><i class="fa fa-check"></i><b>26</b> Parsing dates and times<span></span></a>
<ul>
<li class="chapter" data-level="26.1" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html#the-date-data-type"><i class="fa fa-check"></i><b>26.1</b> The date data type<span></span></a></li>
<li class="chapter" data-level="26.2" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html#lubridate"><i class="fa fa-check"></i><b>26.2</b> The lubridate package<span></span></a></li>
<li class="chapter" data-level="26.3" data-path="parsing-dates-and-times.html"><a href="parsing-dates-and-times.html#exercises-44"><i class="fa fa-check"></i><b>26.3</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>27</b> Text mining<span></span></a>
<ul>
<li class="chapter" data-level="27.1" data-path="text-mining.html"><a href="text-mining.html#case-study-trump-tweets"><i class="fa fa-check"></i><b>27.1</b> Case study: Trump tweets<span></span></a></li>
<li class="chapter" data-level="27.2" data-path="text-mining.html"><a href="text-mining.html#text-as-data"><i class="fa fa-check"></i><b>27.2</b> Text as data<span></span></a></li>
<li class="chapter" data-level="27.3" data-path="text-mining.html"><a href="text-mining.html#sentiment-analysis"><i class="fa fa-check"></i><b>27.3</b> Sentiment analysis<span></span></a></li>
<li class="chapter" data-level="27.4" data-path="text-mining.html"><a href="text-mining.html#exercises-45"><i class="fa fa-check"></i><b>27.4</b> Exercises<span></span></a></li>
</ul></li>
<li class="part"><span><b>V Machine Learning<span></span></b></span></li>
<li class="chapter" data-level="28" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html"><i class="fa fa-check"></i><b>28</b> Introduction to machine learning<span></span></a>
<ul>
<li class="chapter" data-level="28.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#notation-1"><i class="fa fa-check"></i><b>28.1</b> Notation<span></span></a></li>
<li class="chapter" data-level="28.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#an-example"><i class="fa fa-check"></i><b>28.2</b> An example<span></span></a></li>
<li class="chapter" data-level="28.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#exercises-46"><i class="fa fa-check"></i><b>28.3</b> Exercises<span></span></a></li>
<li class="chapter" data-level="28.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#evaluation-metrics"><i class="fa fa-check"></i><b>28.4</b> Evaluation metrics<span></span></a>
<ul>
<li class="chapter" data-level="28.4.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#training-test"><i class="fa fa-check"></i><b>28.4.1</b> Training and test sets<span></span></a></li>
<li class="chapter" data-level="28.4.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#overall-accuracy"><i class="fa fa-check"></i><b>28.4.2</b> Overall accuracy<span></span></a></li>
<li class="chapter" data-level="28.4.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#the-confusion-matrix"><i class="fa fa-check"></i><b>28.4.3</b> The confusion matrix<span></span></a></li>
<li class="chapter" data-level="28.4.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>28.4.4</b> Sensitivity and specificity<span></span></a></li>
<li class="chapter" data-level="28.4.5" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#balanced-accuracy-and-f_1-score"><i class="fa fa-check"></i><b>28.4.5</b> Balanced accuracy and <span class="math inline">\(F_1\)</span> score<span></span></a></li>
<li class="chapter" data-level="28.4.6" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#prevalence-matters-in-practice"><i class="fa fa-check"></i><b>28.4.6</b> Prevalence matters in practice<span></span></a></li>
<li class="chapter" data-level="28.4.7" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#roc-and-precision-recall-curves"><i class="fa fa-check"></i><b>28.4.7</b> ROC and precision-recall curves<span></span></a></li>
<li class="chapter" data-level="28.4.8" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#loss-function"><i class="fa fa-check"></i><b>28.4.8</b> The loss function<span></span></a></li>
</ul></li>
<li class="chapter" data-level="28.5" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#exercises-47"><i class="fa fa-check"></i><b>28.5</b> Exercises<span></span></a></li>
<li class="chapter" data-level="28.6" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-probabilities-and-expectations"><i class="fa fa-check"></i><b>28.6</b> Conditional probabilities and expectations<span></span></a>
<ul>
<li class="chapter" data-level="28.6.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-probabilities-1"><i class="fa fa-check"></i><b>28.6.1</b> Conditional probabilities<span></span></a></li>
<li class="chapter" data-level="28.6.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-expectations"><i class="fa fa-check"></i><b>28.6.2</b> Conditional expectations<span></span></a></li>
<li class="chapter" data-level="28.6.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#conditional-expectation-minimizes-squared-loss-function"><i class="fa fa-check"></i><b>28.6.3</b> Conditional expectation minimizes squared loss function<span></span></a></li>
</ul></li>
<li class="chapter" data-level="28.7" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#exercises-48"><i class="fa fa-check"></i><b>28.7</b> Exercises<span></span></a></li>
<li class="chapter" data-level="28.8" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#two-or-seven"><i class="fa fa-check"></i><b>28.8</b> Case study: is it a 2 or a 7?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="smoothing.html"><a href="smoothing.html"><i class="fa fa-check"></i><b>29</b> Smoothing<span></span></a>
<ul>
<li class="chapter" data-level="29.1" data-path="smoothing.html"><a href="smoothing.html#bin-smoothing"><i class="fa fa-check"></i><b>29.1</b> Bin smoothing<span></span></a></li>
<li class="chapter" data-level="29.2" data-path="smoothing.html"><a href="smoothing.html#kernels"><i class="fa fa-check"></i><b>29.2</b> Kernels<span></span></a></li>
<li class="chapter" data-level="29.3" data-path="smoothing.html"><a href="smoothing.html#local-weighted-regression-loess"><i class="fa fa-check"></i><b>29.3</b> Local weighted regression (loess)<span></span></a>
<ul>
<li class="chapter" data-level="29.3.1" data-path="smoothing.html"><a href="smoothing.html#fitting-parabolas"><i class="fa fa-check"></i><b>29.3.1</b> Fitting parabolas<span></span></a></li>
<li class="chapter" data-level="29.3.2" data-path="smoothing.html"><a href="smoothing.html#beware-of-default-smoothing-parameters"><i class="fa fa-check"></i><b>29.3.2</b> Beware of default smoothing parameters<span></span></a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="smoothing.html"><a href="smoothing.html#smoothing-ml-connection"><i class="fa fa-check"></i><b>29.4</b> Connecting smoothing to machine learning<span></span></a></li>
<li class="chapter" data-level="29.5" data-path="smoothing.html"><a href="smoothing.html#exercises-49"><i class="fa fa-check"></i><b>29.5</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>30</b> Cross validation<span></span></a>
<ul>
<li class="chapter" data-level="30.1" data-path="cross-validation.html"><a href="cross-validation.html#knn-cv-intro"><i class="fa fa-check"></i><b>30.1</b> Motivation with k-nearest neighbors<span></span></a>
<ul>
<li class="chapter" data-level="30.1.1" data-path="cross-validation.html"><a href="cross-validation.html#over-training"><i class="fa fa-check"></i><b>30.1.1</b> Over-training<span></span></a></li>
<li class="chapter" data-level="30.1.2" data-path="cross-validation.html"><a href="cross-validation.html#over-smoothing"><i class="fa fa-check"></i><b>30.1.2</b> Over-smoothing<span></span></a></li>
<li class="chapter" data-level="30.1.3" data-path="cross-validation.html"><a href="cross-validation.html#picking-the-k-in-knn"><i class="fa fa-check"></i><b>30.1.3</b> Picking the <span class="math inline">\(k\)</span> in kNN<span></span></a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="cross-validation.html"><a href="cross-validation.html#mathematical-description-of-cross-validation"><i class="fa fa-check"></i><b>30.2</b> Mathematical description of cross validation<span></span></a></li>
<li class="chapter" data-level="30.3" data-path="cross-validation.html"><a href="cross-validation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>30.3</b> K-fold cross validation<span></span></a></li>
<li class="chapter" data-level="30.4" data-path="cross-validation.html"><a href="cross-validation.html#exercises-50"><i class="fa fa-check"></i><b>30.4</b> Exercises<span></span></a></li>
<li class="chapter" data-level="30.5" data-path="cross-validation.html"><a href="cross-validation.html#bootstrap"><i class="fa fa-check"></i><b>30.5</b> Bootstrap<span></span></a></li>
<li class="chapter" data-level="30.6" data-path="cross-validation.html"><a href="cross-validation.html#exercises-51"><i class="fa fa-check"></i><b>30.6</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>31</b> The caret package<span></span></a>
<ul>
<li class="chapter" data-level="31.1" data-path="caret.html"><a href="caret.html#the-caret-train-functon"><i class="fa fa-check"></i><b>31.1</b> The caret <code>train</code> functon<span></span></a></li>
<li class="chapter" data-level="31.2" data-path="caret.html"><a href="caret.html#caret-cv"><i class="fa fa-check"></i><b>31.2</b> Cross validation<span></span></a></li>
<li class="chapter" data-level="31.3" data-path="caret.html"><a href="caret.html#example-fitting-with-loess"><i class="fa fa-check"></i><b>31.3</b> Example: fitting with loess<span></span></a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html"><i class="fa fa-check"></i><b>32</b> Examples of algorithms<span></span></a>
<ul>
<li class="chapter" data-level="32.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#linear-regression"><i class="fa fa-check"></i><b>32.1</b> Linear regression<span></span></a>
<ul>
<li class="chapter" data-level="32.1.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#the-predict-function"><i class="fa fa-check"></i><b>32.1.1</b> The <code>predict</code> function<span></span></a></li>
</ul></li>
<li class="chapter" data-level="32.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-52"><i class="fa fa-check"></i><b>32.2</b> Exercises<span></span></a></li>
<li class="chapter" data-level="32.3" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#logistic-regression"><i class="fa fa-check"></i><b>32.3</b> Logistic regression<span></span></a>
<ul>
<li class="chapter" data-level="32.3.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#generalized-linear-models"><i class="fa fa-check"></i><b>32.3.1</b> Generalized linear models<span></span></a></li>
<li class="chapter" data-level="32.3.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#logistic-regression-with-more-than-one-predictor"><i class="fa fa-check"></i><b>32.3.2</b> Logistic regression with more than one predictor<span></span></a></li>
</ul></li>
<li class="chapter" data-level="32.4" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-53"><i class="fa fa-check"></i><b>32.4</b> Exercises<span></span></a></li>
<li class="chapter" data-level="32.5" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>32.5</b> k-nearest neighbors<span></span></a></li>
<li class="chapter" data-level="32.6" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-54"><i class="fa fa-check"></i><b>32.6</b> Exercises<span></span></a></li>
<li class="chapter" data-level="32.7" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#generative-models"><i class="fa fa-check"></i><b>32.7</b> Generative models<span></span></a>
<ul>
<li class="chapter" data-level="32.7.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#naive-bayes"><i class="fa fa-check"></i><b>32.7.1</b> Naive Bayes<span></span></a></li>
<li class="chapter" data-level="32.7.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#controlling-prevalence"><i class="fa fa-check"></i><b>32.7.2</b> Controlling prevalence<span></span></a></li>
<li class="chapter" data-level="32.7.3" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>32.7.3</b> Quadratic discriminant analysis<span></span></a></li>
<li class="chapter" data-level="32.7.4" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>32.7.4</b> Linear discriminant analysis<span></span></a></li>
<li class="chapter" data-level="32.7.5" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#connection-to-distance"><i class="fa fa-check"></i><b>32.7.5</b> Connection to distance<span></span></a></li>
</ul></li>
<li class="chapter" data-level="32.8" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#case-study-more-than-three-classes"><i class="fa fa-check"></i><b>32.8</b> Case study: more than three classes<span></span></a></li>
<li class="chapter" data-level="32.9" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-55"><i class="fa fa-check"></i><b>32.9</b> Exercises<span></span></a></li>
<li class="chapter" data-level="32.10" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>32.10</b> Classification and regression trees (CART)<span></span></a>
<ul>
<li class="chapter" data-level="32.10.1" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#the-curse-of-dimensionality"><i class="fa fa-check"></i><b>32.10.1</b> The curse of dimensionality<span></span></a></li>
<li class="chapter" data-level="32.10.2" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#cart-motivation"><i class="fa fa-check"></i><b>32.10.2</b> CART motivation<span></span></a></li>
<li class="chapter" data-level="32.10.3" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#regression-trees"><i class="fa fa-check"></i><b>32.10.3</b> Regression trees<span></span></a></li>
<li class="chapter" data-level="32.10.4" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#classification-decision-trees"><i class="fa fa-check"></i><b>32.10.4</b> Classification (decision) trees<span></span></a></li>
</ul></li>
<li class="chapter" data-level="32.11" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#random-forests"><i class="fa fa-check"></i><b>32.11</b> Random forests<span></span></a></li>
<li class="chapter" data-level="32.12" data-path="examples-of-algorithms.html"><a href="examples-of-algorithms.html#exercises-56"><i class="fa fa-check"></i><b>32.12</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html"><i class="fa fa-check"></i><b>33</b> Machine learning in practice<span></span></a>
<ul>
<li class="chapter" data-level="33.1" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#preprocessing"><i class="fa fa-check"></i><b>33.1</b> Preprocessing<span></span></a></li>
<li class="chapter" data-level="33.2" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#k-nearest-neighbor-and-random-forest"><i class="fa fa-check"></i><b>33.2</b> k-nearest neighbor and random forest<span></span></a></li>
<li class="chapter" data-level="33.3" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#variable-importance"><i class="fa fa-check"></i><b>33.3</b> Variable importance<span></span></a></li>
<li class="chapter" data-level="33.4" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#visual-assessments"><i class="fa fa-check"></i><b>33.4</b> Visual assessments<span></span></a></li>
<li class="chapter" data-level="33.5" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#ensembles"><i class="fa fa-check"></i><b>33.5</b> Ensembles<span></span></a></li>
<li class="chapter" data-level="33.6" data-path="machine-learning-in-practice.html"><a href="machine-learning-in-practice.html#exercises-57"><i class="fa fa-check"></i><b>33.6</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="large-datasets.html"><a href="large-datasets.html"><i class="fa fa-check"></i><b>34</b> Large datasets<span></span></a>
<ul>
<li class="chapter" data-level="34.1" data-path="large-datasets.html"><a href="large-datasets.html#matrix-algebra"><i class="fa fa-check"></i><b>34.1</b> Matrix algebra<span></span></a>
<ul>
<li class="chapter" data-level="34.1.1" data-path="large-datasets.html"><a href="large-datasets.html#notation-2"><i class="fa fa-check"></i><b>34.1.1</b> Notation<span></span></a></li>
<li class="chapter" data-level="34.1.2" data-path="large-datasets.html"><a href="large-datasets.html#converting-a-vector-to-a-matrix"><i class="fa fa-check"></i><b>34.1.2</b> Converting a vector to a matrix<span></span></a></li>
<li class="chapter" data-level="34.1.3" data-path="large-datasets.html"><a href="large-datasets.html#row-and-column-summaries"><i class="fa fa-check"></i><b>34.1.3</b> Row and column summaries<span></span></a></li>
<li class="chapter" data-level="34.1.4" data-path="large-datasets.html"><a href="large-datasets.html#apply"><i class="fa fa-check"></i><b>34.1.4</b> <code>apply</code><span></span></a></li>
<li class="chapter" data-level="34.1.5" data-path="large-datasets.html"><a href="large-datasets.html#filtering-columns-based-on-summaries"><i class="fa fa-check"></i><b>34.1.5</b> Filtering columns based on summaries<span></span></a></li>
<li class="chapter" data-level="34.1.6" data-path="large-datasets.html"><a href="large-datasets.html#indexing-with-matrices"><i class="fa fa-check"></i><b>34.1.6</b> Indexing with matrices<span></span></a></li>
<li class="chapter" data-level="34.1.7" data-path="large-datasets.html"><a href="large-datasets.html#binarizing-the-data"><i class="fa fa-check"></i><b>34.1.7</b> Binarizing the data<span></span></a></li>
<li class="chapter" data-level="34.1.8" data-path="large-datasets.html"><a href="large-datasets.html#vectorization-for-matrices"><i class="fa fa-check"></i><b>34.1.8</b> Vectorization for matrices<span></span></a></li>
<li class="chapter" data-level="34.1.9" data-path="large-datasets.html"><a href="large-datasets.html#matrix-algebra-operations"><i class="fa fa-check"></i><b>34.1.9</b> Matrix algebra operations<span></span></a></li>
</ul></li>
<li class="chapter" data-level="34.2" data-path="large-datasets.html"><a href="large-datasets.html#exercises-58"><i class="fa fa-check"></i><b>34.2</b> Exercises<span></span></a></li>
<li class="chapter" data-level="34.3" data-path="large-datasets.html"><a href="large-datasets.html#distance"><i class="fa fa-check"></i><b>34.3</b> Distance<span></span></a>
<ul>
<li class="chapter" data-level="34.3.1" data-path="large-datasets.html"><a href="large-datasets.html#euclidean-distance"><i class="fa fa-check"></i><b>34.3.1</b> Euclidean distance<span></span></a></li>
<li class="chapter" data-level="34.3.2" data-path="large-datasets.html"><a href="large-datasets.html#distance-in-higher-dimensions"><i class="fa fa-check"></i><b>34.3.2</b> Distance in higher dimensions<span></span></a></li>
<li class="chapter" data-level="34.3.3" data-path="large-datasets.html"><a href="large-datasets.html#euclidean-distance-example"><i class="fa fa-check"></i><b>34.3.3</b> Euclidean distance example<span></span></a></li>
<li class="chapter" data-level="34.3.4" data-path="large-datasets.html"><a href="large-datasets.html#predictor-space"><i class="fa fa-check"></i><b>34.3.4</b> Predictor space<span></span></a></li>
<li class="chapter" data-level="34.3.5" data-path="large-datasets.html"><a href="large-datasets.html#distance-between-predictors"><i class="fa fa-check"></i><b>34.3.5</b> Distance between predictors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="34.4" data-path="large-datasets.html"><a href="large-datasets.html#exercises-59"><i class="fa fa-check"></i><b>34.4</b> Exercises<span></span></a></li>
<li class="chapter" data-level="34.5" data-path="large-datasets.html"><a href="large-datasets.html#dimension-reduction"><i class="fa fa-check"></i><b>34.5</b> Dimension reduction<span></span></a>
<ul>
<li class="chapter" data-level="34.5.1" data-path="large-datasets.html"><a href="large-datasets.html#preserving-distance"><i class="fa fa-check"></i><b>34.5.1</b> Preserving distance<span></span></a></li>
<li class="chapter" data-level="34.5.2" data-path="large-datasets.html"><a href="large-datasets.html#linear-transformations-advanced"><i class="fa fa-check"></i><b>34.5.2</b> Linear transformations (advanced)<span></span></a></li>
<li class="chapter" data-level="34.5.3" data-path="large-datasets.html"><a href="large-datasets.html#orthogonal-transformations-advanced"><i class="fa fa-check"></i><b>34.5.3</b> Orthogonal transformations (advanced)<span></span></a></li>
<li class="chapter" data-level="34.5.4" data-path="large-datasets.html"><a href="large-datasets.html#pca"><i class="fa fa-check"></i><b>34.5.4</b> Principal component analysis<span></span></a></li>
<li class="chapter" data-level="34.5.5" data-path="large-datasets.html"><a href="large-datasets.html#iris-example"><i class="fa fa-check"></i><b>34.5.5</b> Iris example<span></span></a></li>
<li class="chapter" data-level="34.5.6" data-path="large-datasets.html"><a href="large-datasets.html#mnist-example"><i class="fa fa-check"></i><b>34.5.6</b> MNIST example<span></span></a></li>
</ul></li>
<li class="chapter" data-level="34.6" data-path="large-datasets.html"><a href="large-datasets.html#exercises-60"><i class="fa fa-check"></i><b>34.6</b> Exercises<span></span></a></li>
<li class="chapter" data-level="34.7" data-path="large-datasets.html"><a href="large-datasets.html#recommendation-systems"><i class="fa fa-check"></i><b>34.7</b> Recommendation systems<span></span></a>
<ul>
<li class="chapter" data-level="34.7.1" data-path="large-datasets.html"><a href="large-datasets.html#movielens-data"><i class="fa fa-check"></i><b>34.7.1</b> Movielens data<span></span></a></li>
<li class="chapter" data-level="34.7.2" data-path="large-datasets.html"><a href="large-datasets.html#recommendation-systems-as-a-machine-learning-challenge"><i class="fa fa-check"></i><b>34.7.2</b> Recommendation systems as a machine learning challenge<span></span></a></li>
<li class="chapter" data-level="34.7.3" data-path="large-datasets.html"><a href="large-datasets.html#netflix-loss-function"><i class="fa fa-check"></i><b>34.7.3</b> Loss function<span></span></a></li>
<li class="chapter" data-level="34.7.4" data-path="large-datasets.html"><a href="large-datasets.html#a-first-model"><i class="fa fa-check"></i><b>34.7.4</b> A first model<span></span></a></li>
<li class="chapter" data-level="34.7.5" data-path="large-datasets.html"><a href="large-datasets.html#modeling-movie-effects"><i class="fa fa-check"></i><b>34.7.5</b> Modeling movie effects<span></span></a></li>
<li class="chapter" data-level="34.7.6" data-path="large-datasets.html"><a href="large-datasets.html#user-effects"><i class="fa fa-check"></i><b>34.7.6</b> User effects<span></span></a></li>
</ul></li>
<li class="chapter" data-level="34.8" data-path="large-datasets.html"><a href="large-datasets.html#exercises-61"><i class="fa fa-check"></i><b>34.8</b> Exercises<span></span></a></li>
<li class="chapter" data-level="34.9" data-path="large-datasets.html"><a href="large-datasets.html#regularization"><i class="fa fa-check"></i><b>34.9</b> Regularization<span></span></a>
<ul>
<li class="chapter" data-level="34.9.1" data-path="large-datasets.html"><a href="large-datasets.html#motivation"><i class="fa fa-check"></i><b>34.9.1</b> Motivation<span></span></a></li>
<li class="chapter" data-level="34.9.2" data-path="large-datasets.html"><a href="large-datasets.html#penalized-least-squares"><i class="fa fa-check"></i><b>34.9.2</b> Penalized least squares<span></span></a></li>
<li class="chapter" data-level="34.9.3" data-path="large-datasets.html"><a href="large-datasets.html#choosing-the-penalty-terms"><i class="fa fa-check"></i><b>34.9.3</b> Choosing the penalty terms<span></span></a></li>
</ul></li>
<li class="chapter" data-level="34.10" data-path="large-datasets.html"><a href="large-datasets.html#exercises-62"><i class="fa fa-check"></i><b>34.10</b> Exercises<span></span></a></li>
<li class="chapter" data-level="34.11" data-path="large-datasets.html"><a href="large-datasets.html#matrix-factorization"><i class="fa fa-check"></i><b>34.11</b> Matrix factorization<span></span></a>
<ul>
<li class="chapter" data-level="34.11.1" data-path="large-datasets.html"><a href="large-datasets.html#factor-analysis"><i class="fa fa-check"></i><b>34.11.1</b> Factor analysis<span></span></a></li>
<li class="chapter" data-level="34.11.2" data-path="large-datasets.html"><a href="large-datasets.html#connection-to-svd-and-pca"><i class="fa fa-check"></i><b>34.11.2</b> Connection to SVD and PCA<span></span></a></li>
</ul></li>
<li class="chapter" data-level="34.12" data-path="large-datasets.html"><a href="large-datasets.html#exercises-63"><i class="fa fa-check"></i><b>34.12</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>35</b> Clustering<span></span></a>
<ul>
<li class="chapter" data-level="35.1" data-path="clustering.html"><a href="clustering.html#hierarchical-clustering"><i class="fa fa-check"></i><b>35.1</b> Hierarchical clustering<span></span></a></li>
<li class="chapter" data-level="35.2" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>35.2</b> k-means<span></span></a></li>
<li class="chapter" data-level="35.3" data-path="clustering.html"><a href="clustering.html#heatmaps"><i class="fa fa-check"></i><b>35.3</b> Heatmaps<span></span></a></li>
<li class="chapter" data-level="35.4" data-path="clustering.html"><a href="clustering.html#filtering-features"><i class="fa fa-check"></i><b>35.4</b> Filtering features<span></span></a></li>
<li class="chapter" data-level="35.5" data-path="clustering.html"><a href="clustering.html#exercises-64"><i class="fa fa-check"></i><b>35.5</b> Exercises<span></span></a></li>
</ul></li>
<li class="part"><span><b>VI Productivity Tools<span></span></b></span></li>
<li class="chapter" data-level="36" data-path="introduction-to-productivity-tools.html"><a href="introduction-to-productivity-tools.html"><i class="fa fa-check"></i><b>36</b> Introduction to productivity tools<span></span></a></li>
<li class="chapter" data-level="37" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html"><i class="fa fa-check"></i><b>37</b> Installing R and RStudio<span></span></a>
<ul>
<li class="chapter" data-level="37.1" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html#installing-r"><i class="fa fa-check"></i><b>37.1</b> Installing R<span></span></a></li>
<li class="chapter" data-level="37.2" data-path="installing-r-rstudio.html"><a href="installing-r-rstudio.html#installing-rstudio"><i class="fa fa-check"></i><b>37.2</b> Installing RStudio<span></span></a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html"><i class="fa fa-check"></i><b>38</b> Accessing the terminal and installing Git<span></span></a>
<ul>
<li class="chapter" data-level="38.1" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#terminal-on-mac"><i class="fa fa-check"></i><b>38.1</b> Accessing the terminal on a Mac<span></span></a></li>
<li class="chapter" data-level="38.2" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#installing-git-on-the-mac"><i class="fa fa-check"></i><b>38.2</b> Installing Git on the Mac<span></span></a></li>
<li class="chapter" data-level="38.3" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#installing-git-and-git-bash-on-windows"><i class="fa fa-check"></i><b>38.3</b> Installing Git and Git Bash on Windows<span></span></a></li>
<li class="chapter" data-level="38.4" data-path="accessing-the-terminal-and-installing-git.html"><a href="accessing-the-terminal-and-installing-git.html#terminal-on-windows"><i class="fa fa-check"></i><b>38.4</b> Accessing the terminal on Windows<span></span></a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="unix.html"><a href="unix.html"><i class="fa fa-check"></i><b>39</b> Organizing with Unix<span></span></a>
<ul>
<li class="chapter" data-level="39.1" data-path="unix.html"><a href="unix.html#naming-convention"><i class="fa fa-check"></i><b>39.1</b> Naming convention<span></span></a></li>
<li class="chapter" data-level="39.2" data-path="unix.html"><a href="unix.html#the-terminal"><i class="fa fa-check"></i><b>39.2</b> The terminal<span></span></a></li>
<li class="chapter" data-level="39.3" data-path="unix.html"><a href="unix.html#filesystem"><i class="fa fa-check"></i><b>39.3</b> The filesystem<span></span></a>
<ul>
<li class="chapter" data-level="39.3.1" data-path="unix.html"><a href="unix.html#directories-and-subdirectories"><i class="fa fa-check"></i><b>39.3.1</b> Directories and subdirectories<span></span></a></li>
<li class="chapter" data-level="39.3.2" data-path="unix.html"><a href="unix.html#the-home-directory"><i class="fa fa-check"></i><b>39.3.2</b> The home directory<span></span></a></li>
<li class="chapter" data-level="39.3.3" data-path="unix.html"><a href="unix.html#working-directory"><i class="fa fa-check"></i><b>39.3.3</b> Working directory<span></span></a></li>
<li class="chapter" data-level="39.3.4" data-path="unix.html"><a href="unix.html#paths"><i class="fa fa-check"></i><b>39.3.4</b> Paths<span></span></a></li>
</ul></li>
<li class="chapter" data-level="39.4" data-path="unix.html"><a href="unix.html#unix-commands"><i class="fa fa-check"></i><b>39.4</b> Unix commands<span></span></a>
<ul>
<li class="chapter" data-level="39.4.1" data-path="unix.html"><a href="unix.html#ls-listing-directory-content"><i class="fa fa-check"></i><b>39.4.1</b> <code>ls</code>: Listing directory content<span></span></a></li>
<li class="chapter" data-level="39.4.2" data-path="unix.html"><a href="unix.html#mkdir-and-rmdir-make-and-remove-a-directory"><i class="fa fa-check"></i><b>39.4.2</b> <code>mkdir</code> and <code>rmdir</code>: make and remove a directory<span></span></a></li>
<li class="chapter" data-level="39.4.3" data-path="unix.html"><a href="unix.html#cd-navigating-the-filesystem-by-changing-directories"><i class="fa fa-check"></i><b>39.4.3</b> <code>cd</code>: navigating the filesystem by changing directories<span></span></a></li>
</ul></li>
<li class="chapter" data-level="39.5" data-path="unix.html"><a href="unix.html#some-examples"><i class="fa fa-check"></i><b>39.5</b> Some examples<span></span></a></li>
<li class="chapter" data-level="39.6" data-path="unix.html"><a href="unix.html#more-unix-commands"><i class="fa fa-check"></i><b>39.6</b> More Unix commands<span></span></a>
<ul>
<li class="chapter" data-level="39.6.1" data-path="unix.html"><a href="unix.html#mv-moving-files"><i class="fa fa-check"></i><b>39.6.1</b> <code>mv</code>: moving files<span></span></a></li>
<li class="chapter" data-level="39.6.2" data-path="unix.html"><a href="unix.html#cp-copying-files"><i class="fa fa-check"></i><b>39.6.2</b> <code>cp</code>: copying files<span></span></a></li>
<li class="chapter" data-level="39.6.3" data-path="unix.html"><a href="unix.html#rm-removing-files"><i class="fa fa-check"></i><b>39.6.3</b> <code>rm</code>: removing files<span></span></a></li>
<li class="chapter" data-level="39.6.4" data-path="unix.html"><a href="unix.html#less-looking-at-a-file"><i class="fa fa-check"></i><b>39.6.4</b> <code>less</code>: looking at a file<span></span></a></li>
</ul></li>
<li class="chapter" data-level="39.7" data-path="unix.html"><a href="unix.html#prep-project"><i class="fa fa-check"></i><b>39.7</b> Preparing for a data science project<span></span></a></li>
<li class="chapter" data-level="39.8" data-path="unix.html"><a href="unix.html#advanced-unix"><i class="fa fa-check"></i><b>39.8</b> Advanced Unix<span></span></a>
<ul>
<li class="chapter" data-level="39.8.1" data-path="unix.html"><a href="unix.html#arguments"><i class="fa fa-check"></i><b>39.8.1</b> Arguments<span></span></a></li>
<li class="chapter" data-level="39.8.2" data-path="unix.html"><a href="unix.html#getting-help"><i class="fa fa-check"></i><b>39.8.2</b> Getting help<span></span></a></li>
<li class="chapter" data-level="39.8.3" data-path="unix.html"><a href="unix.html#pipes"><i class="fa fa-check"></i><b>39.8.3</b> Pipes<span></span></a></li>
<li class="chapter" data-level="39.8.4" data-path="unix.html"><a href="unix.html#wild-cards"><i class="fa fa-check"></i><b>39.8.4</b> Wild cards<span></span></a></li>
<li class="chapter" data-level="39.8.5" data-path="unix.html"><a href="unix.html#environment-variables"><i class="fa fa-check"></i><b>39.8.5</b> Environment variables<span></span></a></li>
<li class="chapter" data-level="39.8.6" data-path="unix.html"><a href="unix.html#shells"><i class="fa fa-check"></i><b>39.8.6</b> Shells<span></span></a></li>
<li class="chapter" data-level="39.8.7" data-path="unix.html"><a href="unix.html#executables"><i class="fa fa-check"></i><b>39.8.7</b> Executables<span></span></a></li>
<li class="chapter" data-level="39.8.8" data-path="unix.html"><a href="unix.html#permissions-and-file-types"><i class="fa fa-check"></i><b>39.8.8</b> Permissions and file types<span></span></a></li>
<li class="chapter" data-level="39.8.9" data-path="unix.html"><a href="unix.html#commands-you-should-learn"><i class="fa fa-check"></i><b>39.8.9</b> Commands you should learn<span></span></a></li>
<li class="chapter" data-level="39.8.10" data-path="unix.html"><a href="unix.html#file-manipulation-in-r"><i class="fa fa-check"></i><b>39.8.10</b> File manipulation in R<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="40" data-path="git.html"><a href="git.html"><i class="fa fa-check"></i><b>40</b> Git and GitHub<span></span></a>
<ul>
<li class="chapter" data-level="40.1" data-path="git.html"><a href="git.html#why-use-git-and-github"><i class="fa fa-check"></i><b>40.1</b> Why use Git and GitHub?<span></span></a></li>
<li class="chapter" data-level="40.2" data-path="git.html"><a href="git.html#github-accounts"><i class="fa fa-check"></i><b>40.2</b> GitHub accounts<span></span></a></li>
<li class="chapter" data-level="40.3" data-path="git.html"><a href="git.html#github-repos"><i class="fa fa-check"></i><b>40.3</b> GitHub repositories<span></span></a></li>
<li class="chapter" data-level="40.4" data-path="git.html"><a href="git.html#git-overview"><i class="fa fa-check"></i><b>40.4</b> Overview of Git<span></span></a>
<ul>
<li class="chapter" data-level="40.4.1" data-path="git.html"><a href="git.html#clone"><i class="fa fa-check"></i><b>40.4.1</b> Clone<span></span></a></li>
</ul></li>
<li class="chapter" data-level="40.5" data-path="git.html"><a href="git.html#init"><i class="fa fa-check"></i><b>40.5</b> Initializing a Git directory<span></span></a></li>
<li class="chapter" data-level="40.6" data-path="git.html"><a href="git.html#rstudio-git"><i class="fa fa-check"></i><b>40.6</b> Using Git and GitHub in RStudio<span></span></a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html"><i class="fa fa-check"></i><b>41</b> Reproducible projects with RStudio and R markdown<span></span></a>
<ul>
<li class="chapter" data-level="41.1" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#rstudio-projects"><i class="fa fa-check"></i><b>41.1</b> RStudio projects<span></span></a></li>
<li class="chapter" data-level="41.2" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#r-markdown"><i class="fa fa-check"></i><b>41.2</b> R markdown<span></span></a>
<ul>
<li class="chapter" data-level="41.2.1" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#the-header"><i class="fa fa-check"></i><b>41.2.1</b> The header<span></span></a></li>
<li class="chapter" data-level="41.2.2" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#r-code-chunks"><i class="fa fa-check"></i><b>41.2.2</b> R code chunks<span></span></a></li>
<li class="chapter" data-level="41.2.3" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#global-options"><i class="fa fa-check"></i><b>41.2.3</b> Global options<span></span></a></li>
<li class="chapter" data-level="41.2.4" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#knitr"><i class="fa fa-check"></i><b>41.2.4</b> knitR<span></span></a></li>
<li class="chapter" data-level="41.2.5" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#more-on-r-markdown"><i class="fa fa-check"></i><b>41.2.5</b> More on R markdown<span></span></a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#organizing"><i class="fa fa-check"></i><b>41.3</b> Organizing a data science project<span></span></a>
<ul>
<li class="chapter" data-level="41.3.1" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#create-directories-in-unix"><i class="fa fa-check"></i><b>41.3.1</b> Create directories in Unix<span></span></a></li>
<li class="chapter" data-level="41.3.2" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#create-an-rstudio-project"><i class="fa fa-check"></i><b>41.3.2</b> Create an RStudio project<span></span></a></li>
<li class="chapter" data-level="41.3.3" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#edit-some-r-scripts"><i class="fa fa-check"></i><b>41.3.3</b> Edit some R scripts<span></span></a></li>
<li class="chapter" data-level="41.3.4" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#create-some-more-directories-using-unix"><i class="fa fa-check"></i><b>41.3.4</b> Create some more directories using Unix<span></span></a></li>
<li class="chapter" data-level="41.3.5" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#add-a-readme-file"><i class="fa fa-check"></i><b>41.3.5</b> Add a README file<span></span></a></li>
<li class="chapter" data-level="41.3.6" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#initializing-a-git-directory"><i class="fa fa-check"></i><b>41.3.6</b> Initializing a Git directory<span></span></a></li>
<li class="chapter" data-level="41.3.7" data-path="reproducible-projects-with-rstudio-and-r-markdown.html"><a href="reproducible-projects-with-rstudio-and-r-markdown.html#add-commit-and-push-files-using-rstudio"><i class="fa fa-check"></i><b>41.3.7</b> Add, commit, and push files using RStudio<span></span></a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cross-validation" class="section level1 hasAnchor" number="30">
<h1><span class="header-section-number">Chapter 30</span> Cross validation<a href="cross-validation.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this chapter we introduce cross validation, one of the most important ideas in machine learning. Here we focus on the conceptual and mathematical aspects. We will describe how to implement cross validation in practice with the <strong>caret</strong> package later, in Section <a href="caret.html#caret-cv">31.2</a> in the next chapter. To motivate the concept, we will use the two predictor digits data presented in Section <a href="introduction-to-machine-learning.html#two-or-seven">28.8</a> and introduce, for the first time, an actual machine learning algorithm: k-nearest neighbors (kNN).</p>
<div id="knn-cv-intro" class="section level2 hasAnchor" number="30.1">
<h2><span class="header-section-number">30.1</span> Motivation with k-nearest neighbors<a href="cross-validation.html#knn-cv-intro" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Letâ€™s start by loading the data and showing a plot of the predictors with outcome represented with color.</p>
<div class="sourceCode" id="cb1061"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1061-1"><a href="cross-validation.html#cb1061-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1061-2"><a href="cross-validation.html#cb1061-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dslabs)</span>
<span id="cb1061-3"><a href="cross-validation.html#cb1061-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;mnist_27&quot;</span>)</span>
<span id="cb1061-4"><a href="cross-validation.html#cb1061-4" aria-hidden="true" tabindex="-1"></a>mnist_27<span class="sc">$</span>test<span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(x_1, x_2, <span class="at">color =</span> y)) <span class="sc">+</span>  <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="book_files/figure-html/mnist-27-data-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>We will use these data to estimate the conditional probability function</p>
<p><span class="math display">\[
p(x_1, x_2) = \mbox{Pr}(Y=1 \mid X_1=x_1 , X_2 = x_2).
\]</span>
as defined in Section <a href="smoothing.html#smoothing-ml-connection">29.4</a>. With k-nearest neighbors (kNN) we estimate <span class="math inline">\(p(x_1, x_2)\)</span> in a similar way to bin smoothing. However, as we will see, kNN is easier to adapt to multiple dimensions. First we define the distance between all observations based on the features. Then, for any point <span class="math inline">\((x_1,x_2)\)</span> for which we want an estimate of <span class="math inline">\(p(x_1, x_2)\)</span>, we look for the <span class="math inline">\(k\)</span> nearest points to <span class="math inline">\((x_1,x_2)\)</span> and then take an average of the 0s and 1s associated with these points. We refer to the set of points used to compute the average as the <em>neighborhood</em>. Due to the connection we described earlier between conditional expectations and conditional probabilities, this gives us a <span class="math inline">\(\hat{p}(x_1,x_2)\)</span>, just like the bin smoother gave us an estimate of a trend. As with bin smoothers, we can control the flexibility of our estimate, in this case through the <span class="math inline">\(k\)</span> parameter: larger <span class="math inline">\(k\)</span>s result in smoother estimates, while smaller <span class="math inline">\(k\)</span>s result in more flexible and more wiggly estimates.</p>
<p>To implement the algorithm, we can use the <code>knn3</code> function from the <strong>caret</strong> package. Looking at the help file for this package, we see that we can call it in one of two ways. We will use the first in which we specify a <em>formula</em> and a data frame. The data frame contains all the data to be used. The formula has the form <code>outcome ~ predictor_1 + predictor_2 + predictor_3</code> and so on. Therefore, we would type <code>y ~ x_1 + x_2</code>. If we are going to use all the predictors, we can use the <code>.</code> like this <code>y ~ .</code>. The final call looks like this:</p>
<div class="sourceCode" id="cb1062"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1062-1"><a href="cross-validation.html#cb1062-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb1062-2"><a href="cross-validation.html#cb1062-2" aria-hidden="true" tabindex="-1"></a>knn_fit <span class="ot">&lt;-</span> <span class="fu">knn3</span>(y <span class="sc">~</span> ., <span class="at">data =</span> mnist_27<span class="sc">$</span>train)</span></code></pre></div>
<p>For this function, we also need to pick a parameter: the number of neighbors to include. Letâ€™s start with the default <span class="math inline">\(k=5\)</span>.</p>
<div class="sourceCode" id="cb1063"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1063-1"><a href="cross-validation.html#cb1063-1" aria-hidden="true" tabindex="-1"></a>knn_fit <span class="ot">&lt;-</span> <span class="fu">knn3</span>(y <span class="sc">~</span> ., <span class="at">data =</span> mnist_27<span class="sc">$</span>train, <span class="at">k =</span> <span class="dv">5</span>)</span></code></pre></div>
<p>In this case, since our dataset is balanced and we care just as much about sensitivity as we do about specificity, we will use accuracy to quantify performance.</p>
<p>The <code>predict</code> function for <code>knn</code> produces a probability for each class. We keep the probability of being a 7 as the estimate <span class="math inline">\(\hat{p}(x_1, x_2)\)</span></p>
<div class="sourceCode" id="cb1064"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1064-1"><a href="cross-validation.html#cb1064-1" aria-hidden="true" tabindex="-1"></a>y_hat_knn <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_fit, mnist_27<span class="sc">$</span>test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb1064-2"><a href="cross-validation.html#cb1064-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(y_hat_knn, mnist_27<span class="sc">$</span>test<span class="sc">$</span>y)<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb1064-3"><a href="cross-validation.html#cb1064-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Accuracy </span></span>
<span id="cb1064-4"><a href="cross-validation.html#cb1064-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    0.815</span></span></code></pre></div>
<p>In Section <a href="introduction-to-machine-learning.html#two-or-seven">28.8</a> we used linear regression to generate an estimate.</p>
<div class="sourceCode" id="cb1065"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1065-1"><a href="cross-validation.html#cb1065-1" aria-hidden="true" tabindex="-1"></a>fit_lm <span class="ot">&lt;-</span> mnist_27<span class="sc">$</span>train <span class="sc">%&gt;%</span> </span>
<span id="cb1065-2"><a href="cross-validation.html#cb1065-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">ifelse</span>(y <span class="sc">==</span> <span class="dv">7</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb1065-3"><a href="cross-validation.html#cb1065-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(y <span class="sc">~</span> x_1 <span class="sc">+</span> x_2, <span class="at">data =</span> .)</span>
<span id="cb1065-4"><a href="cross-validation.html#cb1065-4" aria-hidden="true" tabindex="-1"></a>p_hat_lm <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_lm, mnist_27<span class="sc">$</span>test)</span>
<span id="cb1065-5"><a href="cross-validation.html#cb1065-5" aria-hidden="true" tabindex="-1"></a>y_hat_lm <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">ifelse</span>(p_hat_lm <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="dv">7</span>, <span class="dv">2</span>))</span>
<span id="cb1065-6"><a href="cross-validation.html#cb1065-6" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(y_hat_lm, mnist_27<span class="sc">$</span>test<span class="sc">$</span>y)<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb1065-7"><a href="cross-validation.html#cb1065-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Accuracy </span></span>
<span id="cb1065-8"><a href="cross-validation.html#cb1065-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     0.75</span></span></code></pre></div>
<p>And we see that kNN, with the default parameter, already beats regression. To see why this is the case, we will plot <span class="math inline">\(\hat{p}(x_1, x_2)\)</span> and compare it to the true conditional probability <span class="math inline">\(p(x_1, x_2)\)</span>:</p>
<p><img src="book_files/figure-html/knn-fit-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We see that kNN better adapts to the non-linear shape of <span class="math inline">\(p(x_1, x_2)\)</span>. However, our estimate has some islands of blue in the red area, which intuitively does not make much sense. This is due to what we call <em>over-training</em>. We describe over-training in detail below. Over-training is the reason that we have higher accuracy in the train set compared to the test set:</p>
<div class="sourceCode" id="cb1066"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1066-1"><a href="cross-validation.html#cb1066-1" aria-hidden="true" tabindex="-1"></a>y_hat_knn <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_fit, mnist_27<span class="sc">$</span>train, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb1066-2"><a href="cross-validation.html#cb1066-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(y_hat_knn, mnist_27<span class="sc">$</span>train<span class="sc">$</span>y)<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb1066-3"><a href="cross-validation.html#cb1066-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Accuracy </span></span>
<span id="cb1066-4"><a href="cross-validation.html#cb1066-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    0.882</span></span>
<span id="cb1066-5"><a href="cross-validation.html#cb1066-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1066-6"><a href="cross-validation.html#cb1066-6" aria-hidden="true" tabindex="-1"></a>y_hat_knn <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_fit, mnist_27<span class="sc">$</span>test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb1066-7"><a href="cross-validation.html#cb1066-7" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(y_hat_knn, mnist_27<span class="sc">$</span>test<span class="sc">$</span>y)<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb1066-8"><a href="cross-validation.html#cb1066-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Accuracy </span></span>
<span id="cb1066-9"><a href="cross-validation.html#cb1066-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    0.815</span></span></code></pre></div>
<div id="over-training" class="section level3 hasAnchor" number="30.1.1">
<h3><span class="header-section-number">30.1.1</span> Over-training<a href="cross-validation.html#over-training" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Over-training is at its worst when we set <span class="math inline">\(k=1\)</span>. With <span class="math inline">\(k=1\)</span>, the estimate for each <span class="math inline">\((x_1, x_2)\)</span> in the training set is obtained with just the <span class="math inline">\(y\)</span> corresponding to that point. In this case, if the <span class="math inline">\((x_1, x_2)\)</span> are unique, we will obtain perfect accuracy in the training set because each point is used to predict itself. Remember that if the predictors are not unique and have different outcomes for at least one set of predictors, then it is impossible to predict perfectly.</p>
<p>Here we fit a kNN model with <span class="math inline">\(k=1\)</span>:</p>
<div class="sourceCode" id="cb1067"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1067-1"><a href="cross-validation.html#cb1067-1" aria-hidden="true" tabindex="-1"></a>knn_fit_1 <span class="ot">&lt;-</span> <span class="fu">knn3</span>(y <span class="sc">~</span> ., <span class="at">data =</span> mnist_27<span class="sc">$</span>train, <span class="at">k =</span> <span class="dv">1</span>)</span>
<span id="cb1067-2"><a href="cross-validation.html#cb1067-2" aria-hidden="true" tabindex="-1"></a>y_hat_knn_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_fit_1, mnist_27<span class="sc">$</span>train, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb1067-3"><a href="cross-validation.html#cb1067-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(y_hat_knn_1, mnist_27<span class="sc">$</span>train<span class="sc">$</span>y)<span class="sc">$</span>overall[[<span class="st">&quot;Accuracy&quot;</span>]]</span>
<span id="cb1067-4"><a href="cross-validation.html#cb1067-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.998</span></span></code></pre></div>
<p>However, the test set accuracy is actually worse than logistic regression:</p>
<div class="sourceCode" id="cb1068"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1068-1"><a href="cross-validation.html#cb1068-1" aria-hidden="true" tabindex="-1"></a>y_hat_knn_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_fit_1, mnist_27<span class="sc">$</span>test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb1068-2"><a href="cross-validation.html#cb1068-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(y_hat_knn_1, mnist_27<span class="sc">$</span>test<span class="sc">$</span>y)<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb1068-3"><a href="cross-validation.html#cb1068-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Accuracy </span></span>
<span id="cb1068-4"><a href="cross-validation.html#cb1068-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     0.74</span></span></code></pre></div>
<p>We can see the over-fitting problem in this figure.
<img src="book_files/figure-html/knn-1-overfit-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The black curves denote the decision rule boundaries.</p>
<p>The estimate <span class="math inline">\(\hat{p}(x_1, x_2)\)</span> follows the training data too closely (left). You can see that in the training set, boundaries have been drawn to perfectly surround a single red point in a sea of blue. Because most points <span class="math inline">\((x_1, x_2)\)</span> are unique, the prediction is either 1 or 0 and the prediction for that point is the associated label. However, once we introduce the training set (right), we see that many of these small islands now have the opposite color and we end up making several incorrect predictions.</p>
</div>
<div id="over-smoothing" class="section level3 hasAnchor" number="30.1.2">
<h3><span class="header-section-number">30.1.2</span> Over-smoothing<a href="cross-validation.html#over-smoothing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Although not as badly as with the previous examples, we saw that with <span class="math inline">\(k=5\)</span> we also over-trained. Hence, we should consider a larger <span class="math inline">\(k\)</span>. Letâ€™s try, as an example, a much larger number: <span class="math inline">\(k=401\)</span>.</p>
<div class="sourceCode" id="cb1069"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1069-1"><a href="cross-validation.html#cb1069-1" aria-hidden="true" tabindex="-1"></a>knn_fit_401 <span class="ot">&lt;-</span> <span class="fu">knn3</span>(y <span class="sc">~</span> ., <span class="at">data =</span> mnist_27<span class="sc">$</span>train, <span class="at">k =</span> <span class="dv">401</span>)</span>
<span id="cb1069-2"><a href="cross-validation.html#cb1069-2" aria-hidden="true" tabindex="-1"></a>y_hat_knn_401 <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_fit_401, mnist_27<span class="sc">$</span>test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb1069-3"><a href="cross-validation.html#cb1069-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(y_hat_knn_401, mnist_27<span class="sc">$</span>test<span class="sc">$</span>y)<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb1069-4"><a href="cross-validation.html#cb1069-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Accuracy </span></span>
<span id="cb1069-5"><a href="cross-validation.html#cb1069-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     0.79</span></span></code></pre></div>
<p>This turns out to be similar to regression:
<img src="book_files/figure-html/mnist-27-glm-est-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>This size of <span class="math inline">\(k\)</span> is so large that it does not permit enough flexibility. We call this <em>over-smoothing</em>.</p>
</div>
<div id="picking-the-k-in-knn" class="section level3 hasAnchor" number="30.1.3">
<h3><span class="header-section-number">30.1.3</span> Picking the <span class="math inline">\(k\)</span> in kNN<a href="cross-validation.html#picking-the-k-in-knn" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>So how do we pick <span class="math inline">\(k\)</span>? In principle we want to pick the <span class="math inline">\(k\)</span> that maximizes accuracy, or minimizes the expected MSE as defined in <a href="introduction-to-machine-learning.html#loss-function">28.4.8</a>. The goal of cross validation is to estimate these quantities for any given algorithm and set of tuning parameters such as <span class="math inline">\(k\)</span>. To understand why we need a special method to do this letâ€™s repeat what we did above but for different values of <span class="math inline">\(k\)</span>:</p>
<div class="sourceCode" id="cb1070"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1070-1"><a href="cross-validation.html#cb1070-1" aria-hidden="true" tabindex="-1"></a>ks <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">3</span>, <span class="dv">251</span>, <span class="dv">2</span>)</span></code></pre></div>
<p>We do this using <code>map_df</code> function to repeat the above for each one.</p>
<div class="sourceCode" id="cb1071"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1071-1"><a href="cross-validation.html#cb1071-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)</span>
<span id="cb1071-2"><a href="cross-validation.html#cb1071-2" aria-hidden="true" tabindex="-1"></a>accuracy <span class="ot">&lt;-</span> <span class="fu">map_df</span>(ks, <span class="cf">function</span>(k){</span>
<span id="cb1071-3"><a href="cross-validation.html#cb1071-3" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">knn3</span>(y <span class="sc">~</span> ., <span class="at">data =</span> mnist_27<span class="sc">$</span>train, <span class="at">k =</span> k)</span>
<span id="cb1071-4"><a href="cross-validation.html#cb1071-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1071-5"><a href="cross-validation.html#cb1071-5" aria-hidden="true" tabindex="-1"></a>  y_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, mnist_27<span class="sc">$</span>train, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb1071-6"><a href="cross-validation.html#cb1071-6" aria-hidden="true" tabindex="-1"></a>  cm_train <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(y_hat, mnist_27<span class="sc">$</span>train<span class="sc">$</span>y)</span>
<span id="cb1071-7"><a href="cross-validation.html#cb1071-7" aria-hidden="true" tabindex="-1"></a>  train_error <span class="ot">&lt;-</span> cm_train<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb1071-8"><a href="cross-validation.html#cb1071-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1071-9"><a href="cross-validation.html#cb1071-9" aria-hidden="true" tabindex="-1"></a>  y_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, mnist_27<span class="sc">$</span>test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb1071-10"><a href="cross-validation.html#cb1071-10" aria-hidden="true" tabindex="-1"></a>  cm_test <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(y_hat, mnist_27<span class="sc">$</span>test<span class="sc">$</span>y)</span>
<span id="cb1071-11"><a href="cross-validation.html#cb1071-11" aria-hidden="true" tabindex="-1"></a>  test_error <span class="ot">&lt;-</span> cm_test<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb1071-12"><a href="cross-validation.html#cb1071-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1071-13"><a href="cross-validation.html#cb1071-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">train =</span> train_error, <span class="at">test =</span> test_error)</span>
<span id="cb1071-14"><a href="cross-validation.html#cb1071-14" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
<p>Note that we estimate accuracy by using both the training set and the test set. We can now plot the accuracy estimates for each value of <span class="math inline">\(k\)</span>:</p>
<p><img src="book_files/figure-html/accuracy-vs-k-knn-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>First, note that the estimate obtained on the training set is generally lower than the estimate obtained with the test set, with the difference larger for smaller values of <span class="math inline">\(k\)</span>. This is due to over-training. Also note that the accuracy versus <span class="math inline">\(k\)</span> plot is quite jagged. We do not expect this because small changes in <span class="math inline">\(k\)</span> should not affect the algorithmâ€™s performance too much. The jaggedness is explained by the fact that the accuracy is computed on a sample and therefore is a random variable. This demonstrates why we prefer to minimize the expected loss rather than the loss we observe with one dataset.</p>
<p>If we were to use these estimates to pick the <span class="math inline">\(k\)</span> that maximizes accuracy, we would use the estimates built on the test data:</p>
<div class="sourceCode" id="cb1072"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1072-1"><a href="cross-validation.html#cb1072-1" aria-hidden="true" tabindex="-1"></a>ks[<span class="fu">which.max</span>(accuracy<span class="sc">$</span>test)]</span>
<span id="cb1072-2"><a href="cross-validation.html#cb1072-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 41</span></span>
<span id="cb1072-3"><a href="cross-validation.html#cb1072-3" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(accuracy<span class="sc">$</span>test)</span>
<span id="cb1072-4"><a href="cross-validation.html#cb1072-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.86</span></span></code></pre></div>
<p>Another reason we need a better estimate of accuracy is that if we use the test set to pick this <span class="math inline">\(k\)</span>, we should not expect the accompanying accuracy estimate to extrapolate to the real world. This is because even here we broke a golden rule of machine learning: we selected the <span class="math inline">\(k\)</span> using the test set. Cross validation also provides an estimate that takes this into account.</p>
</div>
</div>
<div id="mathematical-description-of-cross-validation" class="section level2 hasAnchor" number="30.2">
<h2><span class="header-section-number">30.2</span> Mathematical description of cross validation<a href="cross-validation.html#mathematical-description-of-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Section <a href="introduction-to-machine-learning.html#loss-function">28.4.8</a>, we described that a common goal of machine learning is to find an algorithm that produces predictors <span class="math inline">\(\hat{Y}\)</span> for an outcome <span class="math inline">\(Y\)</span> that minimizes the MSE:</p>
<p><span class="math display">\[
\mbox{MSE} = \mbox{E}\left\{ \frac{1}{N}\sum_{i=1}^N (\hat{Y}_i - Y_i)^2 \right\}
\]</span>
When all we have at our disposal is one dataset, we can estimate the MSE with the observed MSE like this:</p>
<p><span class="math display">\[
\hat{\mbox{MSE}} = \frac{1}{N}\sum_{i=1}^N (\hat{y}_i - y_i)^2
\]</span>
These two are often referred to as the <em>true error</em> and <em>apparent error</em>, respectively.</p>
<p>There are two important characteristics of the apparent error we should always keep in mind:</p>
<ol style="list-style-type: decimal">
<li><p>Because our data is random, the apparent error is a random variable. For example, the dataset we have may be a random sample from a larger population. An algorithm may have a lower apparent error than another algorithm due to luck.</p></li>
<li><p>If we train an algorithm on the same dataset that we use to compute the apparent error, we might be overtraining. In general, when we do this, the apparent error will be an underestimate of the true error. We will see an extreme example of this with k-nearest neighbors.</p></li>
</ol>
<p>Cross validation is a technique that permits us to alleviate both these problems. To understand cross validation, it helps to think of the true error, a theoretical quantity, as the average of many apparent errors obtained by applying the algorithm to <span class="math inline">\(B\)</span> new random samples of the data, none of them used to train the algorithm. As shown in a previous chapter, we think of the true error as:</p>
<p><span class="math display">\[
\frac{1}{B} \sum_{b=1}^B \frac{1}{N}\sum_{i=1}^N \left(\hat{y}_i^b - y_i^b\right)^2
\]</span>
with <span class="math inline">\(B\)</span> a large number that can be thought of as practically infinite.
As already mentioned, this is a theoretical quantity because we only have available one set of outcomes: <span class="math inline">\(y_1, \dots, y_n\)</span>. Cross validation is based on the idea of imitating the theoretical setup above as best we can with the data we have. To do this, we have to generate a series of different random samples. There are several approaches we can use, but the general idea for all of them is to randomly generate smaller datasets that are not used for training, and instead used to estimate the true error.</p>
</div>
<div id="k-fold-cross-validation" class="section level2 hasAnchor" number="30.3">
<h2><span class="header-section-number">30.3</span> K-fold cross validation<a href="cross-validation.html#k-fold-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The first one we describe is <em>K-fold cross validation</em>.
Generally speaking, a machine learning challenge starts with a dataset (blue in the image below). We need to build an algorithm using this dataset that will eventually be used in completely independent datasets (yellow).</p>
<p><img src="ml/img/cv-1.png" width="500px" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" style="display: block; margin: auto;" /></p>
<p>But we donâ€™t get to see these independent datasets.</p>
<p><img src="ml/img/cv-2.png" width="500px" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" style="display: block; margin: auto;" /></p>
<p>So to imitate this situation, we carve out a piece of our dataset and pretend it is an independent dataset: we divide the dataset into a <em>training set</em> (blue) and a <em>test set</em> (red). We will train our algorithm exclusively on the training set and use the test set only for evaluation purposes.</p>
<p>We usually try to select a small piece of the dataset so that we have as much data as possible to train. However, we also want the test set to be large so that we obtain a stable estimate of the loss without fitting an impractical number of models. Typical choices are to use 10%-20% of the data for testing.</p>
<p><img src="ml/img/cv-3.png" width="500px" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" style="display: block; margin: auto;" /></p>
<p>Letâ€™s reiterate that it is indispensable that we not use the test set at all: not for filtering out rows, not for selecting features, nothing!</p>
<p>Now this presents a new problem because for most machine learning algorithms we need to select parameters, for example the number of neighbors <span class="math inline">\(k\)</span> in k-nearest neighbors. Here, we will refer to the set of parameters as <span class="math inline">\(\lambda\)</span>. We need to optimize algorithm parameters without using our test set and we know that if we optimize and evaluate on the same dataset, we will overtrain. This is where cross validation is most useful.</p>
<p>For each set of algorithm parameters being considered, we want an estimate of the MSE and then we will choose the parameters with the smallest MSE. Cross validation provides this estimate.</p>
<p>First, before we start the cross validation procedure, it is important to fix all the algorithm parameters. Although we will train the algorithm on the set of training sets, the parameters <span class="math inline">\(\lambda\)</span> will be the same across all training sets. We will use <span class="math inline">\(\hat{y}_i(\lambda)\)</span> to denote the predictors obtained when we use parameters <span class="math inline">\(\lambda\)</span>.</p>
<p>So, if we are going to imitate this definition:</p>
<p><span class="math display">\[
\mbox{MSE}(\lambda) = \frac{1}{B} \sum_{b=1}^B \frac{1}{N}\sum_{i=1}^N \left(\hat{y}_i^b(\lambda) - y_i^b\right)^2
\]</span></p>
<p>we want to consider datasets that can be thought of as an independent random sample and we want to do this several times. With K-fold cross validation, we do it <span class="math inline">\(K\)</span> times. In the cartoons, we are showing an example that uses <span class="math inline">\(K=5\)</span>.</p>
<p>We will eventually end up with <span class="math inline">\(K\)</span> samples, but letâ€™s start by describing how to construct the first: we simply pick <span class="math inline">\(M=N/K\)</span> observations at random (we round if <span class="math inline">\(M\)</span> is not a round number) and think of these as a random sample <span class="math inline">\(y_1^b, \dots, y_M^b\)</span>, with <span class="math inline">\(b=1\)</span>. We call this the validation set:</p>
<p><img src="ml/img/cv-4.png" width="500px" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" style="display: block; margin: auto;" /></p>
<p>Now we can fit the model in the training set, then compute the apparent error on the independent set:</p>
<p><span class="math display">\[
\hat{\mbox{MSE}}_b(\lambda) = \frac{1}{M}\sum_{i=1}^M \left(\hat{y}_i^b(\lambda) - y_i^b\right)^2
\]</span></p>
<p>Note that this is just one sample and will therefore return a noisy estimate of the true error. This is why we take <span class="math inline">\(K\)</span> samples, not just one. In K-cross validation, we randomly split the observations into <span class="math inline">\(K\)</span> non-overlapping sets:</p>
<p><img src="ml/img/cv-5.png" width="500px" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" style="display: block; margin: auto;" /></p>
<p>Now we repeat the calculation above for each of these sets <span class="math inline">\(b=1,\dots,K\)</span> and obtain <span class="math inline">\(\hat{\mbox{MSE}}_1(\lambda),\dots, \hat{\mbox{MSE}}_K(\lambda)\)</span>. Then, for our final estimate, we compute the average:</p>
<p><span class="math display">\[
\hat{\mbox{MSE}}(\lambda) = \frac{1}{B} \sum_{b=1}^K \hat{\mbox{MSE}}_b(\lambda)
\]</span></p>
<p>and obtain an estimate of our loss. A final step would be to select the <span class="math inline">\(\lambda\)</span> that minimizes the MSE.</p>
<p>We have described how to use cross validation to optimize parameters. However, we now have to take into account the fact that the optimization occurred on the training data and therefore we need an estimate of our final algorithm based on data that was not used to optimize the choice. Here is where we use the test set we separated early on:</p>
<p><img src="ml/img/cv-6.png" width="500px" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" style="display: block; margin: auto;" /></p>
<p>We can do cross validation again:</p>
<p><img src="ml/img/cv-7.png" width="500px" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" style="display: block; margin: auto;" /></p>
<p>and obtain a final estimate of our expected loss. However, note that this means that our entire compute time gets multiplied by <span class="math inline">\(K\)</span>. You will soon learn that performing this task takes time because we are performing many complex computations. As a result, we are always looking for ways to reduce this time. For the final evaluation, we often just use the one test set.</p>
<p>Once we are satisfied with this model and want to make it available to others, we could refit the model on the entire dataset, without changing the optimized parameters.</p>
<p><img src="ml/img/cv-8.png" width="500px" style="display: block; margin-left: auto; margin-right: auto; background-color: #000; padding:3px;" style="display: block; margin: auto;" /></p>
<p>Now how do we pick the cross validation <span class="math inline">\(K\)</span>? Large values of <span class="math inline">\(K\)</span> are preferable because the training data better imitates the original dataset. However, larger values of <span class="math inline">\(K\)</span> will have much slower computation time: for example, 100-fold cross validation will be 10 times slower than 10-fold cross validation. For this reason, the choices of <span class="math inline">\(K=5\)</span> and <span class="math inline">\(K=10\)</span> are popular.</p>
<p>One way we can improve the variance of our final estimate is to take more samples. To do this, we would no longer require the training set to be partitioned into non-overlapping sets. Instead, we would just pick <span class="math inline">\(K\)</span> sets of some size at random.</p>
<p>One popular version of this technique, at each fold, picks observations at random with replacement (which means the same observation can appear twice). This approach has some advantages (not discussed here) and is generally referred to as the <em>bootstrap</em>. In fact, this is the default approach in the <strong>caret</strong> package. We describe how to implement cross validation with the <strong>caret</strong> package in the next chapter. In the next section, we include an explanation of how the bootstrap works in general.</p>
</div>
<div id="exercises-50" class="section level2 hasAnchor" number="30.4">
<h2><span class="header-section-number">30.4</span> Exercises<a href="cross-validation.html#exercises-50" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Generate a set of random predictors and outcomes like this:</p>
<div class="sourceCode" id="cb1073"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1073-1"><a href="cross-validation.html#cb1073-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1996</span>)</span>
<span id="cb1073-2"><a href="cross-validation.html#cb1073-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb1073-3"><a href="cross-validation.html#cb1073-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb1073-4"><a href="cross-validation.html#cb1073-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> p), n, p)</span>
<span id="cb1073-5"><a href="cross-validation.html#cb1073-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(x) <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&quot;x&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="fu">ncol</span>(x), <span class="at">sep =</span> <span class="st">&quot;_&quot;</span>)</span>
<span id="cb1073-6"><a href="cross-validation.html#cb1073-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fl">0.5</span>) <span class="sc">%&gt;%</span> <span class="fu">factor</span>()</span>
<span id="cb1073-7"><a href="cross-validation.html#cb1073-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1073-8"><a href="cross-validation.html#cb1073-8" aria-hidden="true" tabindex="-1"></a>x_subset <span class="ot">&lt;-</span> x[ ,<span class="fu">sample</span>(p, <span class="dv">100</span>)]</span></code></pre></div>
<p>1. Because <code>x</code> and <code>y</code> are completely independent, you should not be able to predict <code>y</code> using <code>x</code> with accuracy larger than 0.5. Confirm this by running cross validation using logistic regression to fit the model. Because we have so many predictors, we selected a random sample <code>x_subset</code>. Use the subset when training the model. Hint: use the caret <code>train</code> function. The <code>results</code> component of the output of <code>train</code> shows you the accuracy. Ignore the warnings.</p>
<p>2. Now, instead of a random selection of predictors, we are going to search for those that are most predictive of the outcome. We can do this by comparing the values for the <span class="math inline">\(y=1\)</span> group to those in the <span class="math inline">\(y=0\)</span> group, for each predictor, using a t-test. You can perform this step like this:</p>
<div class="sourceCode" id="cb1074"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1074-1"><a href="cross-validation.html#cb1074-1" aria-hidden="true" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_bioc</span>(<span class="st">&quot;genefilter&quot;</span>)</span>
<span id="cb1074-2"><a href="cross-validation.html#cb1074-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;genefilter&quot;</span>)</span>
<span id="cb1074-3"><a href="cross-validation.html#cb1074-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(genefilter)</span>
<span id="cb1074-4"><a href="cross-validation.html#cb1074-4" aria-hidden="true" tabindex="-1"></a>tt <span class="ot">&lt;-</span> <span class="fu">colttests</span>(x, y)</span></code></pre></div>
<p>Create a vector of the p-values and call it <code>pvals</code>.</p>
<p>3. Create an index <code>ind</code> with the column numbers of the predictors that were â€œstatistically significantlyâ€ associated with <code>y</code>. Use a p-value cutoff of 0.01 to define â€œstatistically significantâ€. How many predictors survive this cutoff?</p>
<p>4. Re-run the cross validation but after redefining <code>x_subset</code> to be the subset of <code>x</code> defined by the columns showing â€œstatistically significantâ€ association with <code>y</code>. What is the accuracy now?</p>
<p>5. Re-run the cross validation again, but this time using kNN. Try out the following grid of tuning parameters: <code>k = seq(101, 301, 25)</code>. Make a plot of the resulting accuracy.</p>
<p>6. In exercises 3 and 4, we see that despite the fact that <code>x</code> and <code>y</code> are completely independent, we were able to predict <code>y</code> with accuracy higher than 70%. We must be doing something wrong then. What is it?</p>
<ol style="list-style-type: lower-alpha">
<li>The function <code>train</code> estimates accuracy on the same data it uses to train the algorithm.</li>
<li>We are over-fitting the model by including 100 predictors.</li>
<li>We used the entire dataset to select the columns used in the model. This step needs to be included as part of the algorithm. The cross validation was done <strong>after</strong> this selection.</li>
<li>The high accuracy is just due to random variability.</li>
</ol>
<p>7. Advanced. Re-do the cross validation but this time include the selection step in the cross validation. The accuracy should now be close to 50%.</p>
<p>8. Load the <code>tissue_gene_expression</code> dataset. Use the <code>train</code> function to predict tissue from gene expression. Use kNN. What <code>k</code> works best?</p>
</div>
<div id="bootstrap" class="section level2 hasAnchor" number="30.5">
<h2><span class="header-section-number">30.5</span> Bootstrap<a href="cross-validation.html#bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose the income distribution of your population is as follows:</p>
<div class="sourceCode" id="cb1075"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1075-1"><a href="cross-validation.html#cb1075-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1995</span>)</span>
<span id="cb1075-2"><a href="cross-validation.html#cb1075-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">6</span></span>
<span id="cb1075-3"><a href="cross-validation.html#cb1075-3" aria-hidden="true" tabindex="-1"></a>income <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span>(<span class="fu">rnorm</span>(n, <span class="fu">log10</span>(<span class="dv">45000</span>), <span class="fu">log10</span>(<span class="dv">3</span>)))</span>
<span id="cb1075-4"><a href="cross-validation.html#cb1075-4" aria-hidden="true" tabindex="-1"></a><span class="fu">qplot</span>(<span class="fu">log10</span>(income), <span class="at">bins =</span> <span class="dv">30</span>, <span class="at">color =</span> <span class="fu">I</span>(<span class="st">&quot;black&quot;</span>))</span></code></pre></div>
<p><img src="book_files/figure-html/income-distribution-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The population median is:</p>
<div class="sourceCode" id="cb1076"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1076-1"><a href="cross-validation.html#cb1076-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">median</span>(income)</span>
<span id="cb1076-2"><a href="cross-validation.html#cb1076-2" aria-hidden="true" tabindex="-1"></a>m</span>
<span id="cb1076-3"><a href="cross-validation.html#cb1076-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 44939</span></span></code></pre></div>
<p>Suppose we donâ€™t have access to the entire population, but want to estimate the median <span class="math inline">\(m\)</span>. We take a sample of 100 and estimate the population median <span class="math inline">\(m\)</span> with the sample median <span class="math inline">\(M\)</span>:</p>
<div class="sourceCode" id="cb1077"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1077-1"><a href="cross-validation.html#cb1077-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb1077-2"><a href="cross-validation.html#cb1077-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">sample</span>(income, N)</span>
<span id="cb1077-3"><a href="cross-validation.html#cb1077-3" aria-hidden="true" tabindex="-1"></a><span class="fu">median</span>(X)</span>
<span id="cb1077-4"><a href="cross-validation.html#cb1077-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 38461</span></span></code></pre></div>
<p>Can we construct a confidence interval? What is the distribution of <span class="math inline">\(M\)</span> ?</p>
<p>Because we are simulating the data, we can use a Monte Carlo simulation to learn the distribution of <span class="math inline">\(M\)</span>.</p>
<div class="sourceCode" id="cb1078"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1078-1"><a href="cross-validation.html#cb1078-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb1078-2"><a href="cross-validation.html#cb1078-2" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">4</span></span>
<span id="cb1078-3"><a href="cross-validation.html#cb1078-3" aria-hidden="true" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="fu">replicate</span>(B, {</span>
<span id="cb1078-4"><a href="cross-validation.html#cb1078-4" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">sample</span>(income, N)</span>
<span id="cb1078-5"><a href="cross-validation.html#cb1078-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">median</span>(X)</span>
<span id="cb1078-6"><a href="cross-validation.html#cb1078-6" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb1078-7"><a href="cross-validation.html#cb1078-7" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">qplot</span>(M, <span class="at">bins =</span> <span class="dv">30</span>, <span class="at">color =</span> <span class="fu">I</span>(<span class="st">&quot;black&quot;</span>))</span>
<span id="cb1078-8"><a href="cross-validation.html#cb1078-8" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">qplot</span>(<span class="at">sample =</span> <span class="fu">scale</span>(M), <span class="at">xlab =</span> <span class="st">&quot;theoretical&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;sample&quot;</span>) <span class="sc">+</span> </span>
<span id="cb1078-9"><a href="cross-validation.html#cb1078-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>()</span>
<span id="cb1078-10"><a href="cross-validation.html#cb1078-10" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="book_files/figure-html/median-is-normal-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>If we know this distribution, we can construct a confidence interval. The problem here is that, as we have already described, in practice we do not have access to the distribution. In the past, we have used the Central Limit Theorem, but the CLT we studied applies to averages and here we are interested in the median. We can see that the 95% confidence interval based on CLT</p>
<div class="sourceCode" id="cb1079"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1079-1"><a href="cross-validation.html#cb1079-1" aria-hidden="true" tabindex="-1"></a><span class="fu">median</span>(X) <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> <span class="fu">sd</span>(X) <span class="sc">/</span> <span class="fu">sqrt</span>(N) <span class="sc">*</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb1079-2"><a href="cross-validation.html#cb1079-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 21018 55905</span></span></code></pre></div>
<p>is quite different from the confidence interval we would generate if we know the actual distribution of <span class="math inline">\(M\)</span>:</p>
<div class="sourceCode" id="cb1080"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1080-1"><a href="cross-validation.html#cb1080-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(M, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb1080-2"><a href="cross-validation.html#cb1080-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  2.5% 97.5% </span></span>
<span id="cb1080-3"><a href="cross-validation.html#cb1080-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 34438 59050</span></span></code></pre></div>
<p>The bootstrap permits us to approximate a Monte Carlo simulation without access to the entire distribution. The general idea is relatively simple. We act as if the observed sample is the population. We then sample (with replacement) datasets, of the same sample size as the original dataset. Then we compute the summary statistic, in this case the median, on these <em>bootstrap samples</em>.</p>
<p>Theory tells us that, in many situations, the distribution of the statistics obtained with bootstrap samples approximate the distribution of our actual statistic. This is how we construct bootstrap samples and an approximate distribution:</p>
<div class="sourceCode" id="cb1081"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1081-1"><a href="cross-validation.html#cb1081-1" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="dv">4</span></span>
<span id="cb1081-2"><a href="cross-validation.html#cb1081-2" aria-hidden="true" tabindex="-1"></a>M_star <span class="ot">&lt;-</span> <span class="fu">replicate</span>(B, {</span>
<span id="cb1081-3"><a href="cross-validation.html#cb1081-3" aria-hidden="true" tabindex="-1"></a>  X_star <span class="ot">&lt;-</span> <span class="fu">sample</span>(X, N, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1081-4"><a href="cross-validation.html#cb1081-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">median</span>(X_star)</span>
<span id="cb1081-5"><a href="cross-validation.html#cb1081-5" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
<p>Note a confidence interval constructed with the bootstrap is much closer to one constructed with the theoretical distribution:</p>
<div class="sourceCode" id="cb1082"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1082-1"><a href="cross-validation.html#cb1082-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(M_star, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb1082-2"><a href="cross-validation.html#cb1082-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  2.5% 97.5% </span></span>
<span id="cb1082-3"><a href="cross-validation.html#cb1082-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 30253 56909</span></span></code></pre></div>
<p>For more on the Bootstrap, including corrections one can apply to improve these confidence intervals, please consult the book <em>An introduction to the bootstrap</em> by Efron, B., &amp; Tibshirani, R. J.</p>
<p><em>Note that we can use ideas similar to those used in the bootstrap in cross validation: instead of dividing the data into equal partitions, we simply bootstrap many times.</em></p>
</div>
<div id="exercises-51" class="section level2 hasAnchor" number="30.6">
<h2><span class="header-section-number">30.6</span> Exercises<a href="cross-validation.html#exercises-51" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>1. The <code>createResample</code> function can be used to create bootstrap samples. For example, we can create 10 bootstrap samples for the <code>mnist_27</code> dataset like this:</p>
<div class="sourceCode" id="cb1083"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1083-1"><a href="cross-validation.html#cb1083-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1995</span>)</span>
<span id="cb1083-2"><a href="cross-validation.html#cb1083-2" aria-hidden="true" tabindex="-1"></a>indexes <span class="ot">&lt;-</span> <span class="fu">createResample</span>(mnist_27<span class="sc">$</span>train<span class="sc">$</span>y, <span class="dv">10</span>)</span></code></pre></div>
<p>How many times do <code>3</code>, <code>4</code>, and <code>7</code> appear in the first re-sampled index?</p>
<p>2. We see that some numbers appear more than once and others appear no times. This has to be this way for each dataset to be independent. Repeat the exercise for all the re-sampled indexes.</p>
<p>3. Generate a random dataset like this:</p>
<div class="sourceCode" id="cb1084"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1084-1"><a href="cross-validation.html#cb1084-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span></code></pre></div>
<p>Estimate the 75th quantile, which we know is:</p>
<div class="sourceCode" id="cb1085"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1085-1"><a href="cross-validation.html#cb1085-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.75</span>)</span></code></pre></div>
<p>with the sample quantile:</p>
<div class="sourceCode" id="cb1086"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1086-1"><a href="cross-validation.html#cb1086-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(y, <span class="fl">0.75</span>)</span></code></pre></div>
<p>Run a Monte Carlo simulation to learn the expected value and standard error of this random variable.</p>
<p>4. In practice, we canâ€™t run a Monte Carlo simulation because we donâ€™t know if <code>rnorm</code> is being used to simulate the data. Use the bootstrap to estimate the standard error using just the initial sample <code>y</code>. Use 10 bootstrap samples.</p>
<p>5. Redo exercise 4, but with 10,000 bootstrap samples.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="smoothing.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="caret.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rafalab/dsbook/edit/master/ml/cross-validation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
